SYSTEMATIC REVIEW Open Access
The sustainability of new programs and
innovations: a review of the empirical literatureand recommendations for future research
Shannon Wiltsey Stirman1,2,3*, John Kimberly4, Natasha Cook1,2, Amber Calloway1,2,3, Frank Castro1,2,3and
Martin Charns2,5,6
Abstract
Background: The introduction of evidence-based programs and practices into healthcare settings has been the
subject of an increasing amount of research in recent years. While a number of studies have examined initial
implementation efforts, less research has been conducted to determine what happens beyond that point. There isincreasing recognition that the extent to which new programs are sustained is influenced by many different factorsand that more needs to be known about just what these factors are and how they interact. To understand thecurrent state of the research literature on sustainability, our team took stock of what is currently known in this area
and identified areas in which further research would be particularly helpful. This paper reviews the methods that
have been used, the types of outcomes that have been measured and reported, findings from studies thatreported long-term implementation outcomes, and factors that have been identified as potential influences on thesustained use of new practices, programs, or interventions. We conclude with recommendations andconsiderations for future research.
Methods: Two coders identified 125 studies on sustainability that met eligibility criteria. An initial coding scheme
was developed based on constructs identified in previous literature on implementation. Additional codes were
generated deductively. Related constructs among factors were identified by consensus and collapsed under thegeneral categories. Studies that described the extent to which programs or innovations were sustained were alsocategorized and summarized.
Results: Although “sustainability” was the term most commonly used in the literature to refer to what happened
after initial implementation, not all the studies that were reviewed actually presented working definitions of the
term. Most study designs were retrospective and naturalistic. Approximately half of the studies relied on self-reports
to assess sustainability or elements that influence sustainability. Approximately half employed quantitativemethodologies, and the remainder employed qualitative or mixed methodologies. Few studies that investigatedsustainability outcomes employed rigorous methods of evaluation (e.g., objective evaluation, judgement ofimplementation quality or fidelity). Among those that did, a small number reported full sustainment or highfidelity. Very little research has examined the extent, nature, or impact of adaptations to the interventions orprograms once implemented. Influences on sustainability included organizational context, capacity, processes, andfactors related to the new program or practice themselves.
Conclusions: Clearer definitions and research that is guided by the conceptual literature on sustainability are
critical to the development of the research in the area. Further efforts to characterize the phenomenon and the
* Correspondence: Shannon.wiltsey-stirman@va.gov
1Women ’s Health Sciences Division, National Center for PTSD, Boston, MA,
USA
Full list of author information is available at the end of the articleWiltsey Stirman et al .Implementation Science 2012, 7:17
http://www.implementationscience.com/content/7/1/17
Implementation
Science
© 2012 Stirman et al; licensee BioMed Central Ltd. This is an Open Access article distributed under the terms of the Creative Commons
Attribution License (http://creativecommons.org/licenses/by/2.0), which permits unrestricted use, distribution, and reproduction in
any medium, provided the original work is properly cited.
factors that influence it will enhance the quality of future research. Careful consideration must also be given to
interactions among influences at multiple levels, as well as issues such as fidelity, modification, and changes inimplementation over time. While prospective and experimental designs are needed, there is also an important rolefor qualitative research in efforts to understand the phenomenon, refine hypotheses, and develop strategies to
promote sustainment.
Background
All systems and organizations are faced with the chal-
lenge of implementing new practices at one time oranother, yet many of the innovations that are initiallysuccessful fail to become part of the habits and routinesof the host organizations and communities. Why do
some take root and flourish while others languish?
Recognizing the need to promote the use of best prac-tices to achieve better outcomes in healthcare, manygovernment agencies and community organizations havedevoted significant resour ces to promoting research on
evidence-based practices (E BPs), clinical guideline
implementation, and qualit y-improvement programs
[1,2]. The National Institutes of Health, for example,
have given priority to research on the implementation
of best practices and evidence-based interventions, andmany systems and communi ties have endeavored to
implement specific healthcare interventions or programsto promote improved health outcomes. One conse-quence of these emerging priorities is the rapid develop-ment of the field of implementation science. Moststudies in this field thus far have focused on identifying
the factors that are critical to the success of initial
implementation efforts. While this is a promising start,policy makers and other stak eholders are increasingly
concerned with the long-term impact of their invest-ment. However, as Greenhalgh and her colleagues(2004) pointed out in their review of the disseminationand implementation literature, there is a “near absence
of studies focusing primarily on the sustainability of
complex service innovations ”[3].
The results of program evaluation and research to
date suggest that sustainability must be studied as a dis-
tinct and dynamic phenomenon [4,5]. Although a varietyof factors may create conditions that facilitate initialimplementation, their presence or influence may dimin-ish over time [6-8]. Even when initial implementationefforts are successful, interventions or programs do not
necessarily continue as originally implemented. At
times, discontinuation of a particular intervention maybe the result of development or discovery of more effec-tive, efficient, or compatible practices [9]. Adaptations,partial continuation of a program or intervention, orintegration of new practices may occur in response tonew evidence, changes in priorities or resource availabil-ity, or other contextual influences. At other times,however, failure to maintain an effective program orintervention at a sufficient l evel of quality, intensity, or
comprehensiveness once implemented is at odds withthe original goals and intentions of the host systems ororganizations [10-12]. New practices may simply beadded on top of existing on es rather than becoming
fully integrated [13], which may make them particularlyvulnerable to erosion over t ime [14]. Unintentional
“slippage ”can occur as a result of factors such as local
staffing conditions, lack of resources, or competingdemands [4]. If these processes result in failure toachieve desired outcomes, negative appraisals of thevalue of the interventions themselves [15] can in turnmake discontinuation more likely. Understanding these
processes and determining h ow to foster the continua-
tion of effective practices at a level that is sufficient to
yield desired health outcomes is at least as important asunderstanding how to implement them in the first place[16].
Many factors make it difficult to study sustainability
and draw conclusions in the current literature. A funda-mental challenge is the tension that exists between the
continuation of interventions as originally designed and
the need to adapt them for use in contexts that may dif-fer in important ways from those in which they wereoriginally developed and tested [5,16,17]. A number ofconceptualizations of sust ainability have been proposed
that reflect differing priorities and perspectives on thisissue [18]. In some models, the intervention, rather thanthe system into which it is introduced, is the focal point
of interest. Such models tend to identify a set of factors
or conditions that increase the likelihood of sustainabil-ity of a specific intervention [17]. This approach is verydifferent from models and studies that examine sustain-ability from an ecological or complex-systems perspec-tive. These models emphasize the interconnectionbetween broader environmental forces, contextual influ-ences, and the program or intervention itself [19,20].
The differing approaches have important implications
for the way that research is conducted and the conclu-sions that can be drawn. For example, the former per-spective may reflect an emphasis on determinants of thepreservation, fidelity to, or discontinuation of a programor intervention. In contrast, research conducted from anecological perspective would seek to understand theways in which the intervention and the local contextWiltsey Stirman et al .Implementation Science 2012, 7:17
http://www.implementationscience.com/content/7/1/17Page 2 of 19
mutually adapt and evolve [21] and how this process
impacts sustainability. Additional challenges to the studyof sustainability and interpretation of the literatureinclude the numerous definitions and related but notentirely equivalent terms that have been used in differ-ing fields, and variation in the timing and method of
assessment employed across studies. Furthermore, the
assessment of programs, practices, and interventions asvaried as community-level prevention programs, medicalrecords systems, psychothera pies, and quality-improve-
ment programs will necessarily limit the extent to whichassessment can be standardized.
To better understand the state of research on sustain-
ability to date, we reviewed studies that investigated
whether or to what extent programs or interventions
that had previously been implemented were sustained,and those that sought to understand factors that influ-ence their sustainment. We present an overview of theways that some key research considerations have beenaddressed from this perspective in a variety of fields,a n dw ea l l o ww h a tw ef o u n du s i n gt h i sa p p r o a c ht oguide our synthesis of the results and recommendations.
For the purposes of this review, we consider relevant
studies to be those that identified interventions, proce-dures, or programs that were implemented to achievespecific program-, patient-, or population-level benefits.We reviewed studies that exa mined (1) sustainability
outcomes [22] (such as the continuation of some or allcomponents [23] or the desired recipient-level outcomesthat occurred after initial efforts to implement, fund, or
study a new practice were complete) or (2) influences
on the sustainment of these programs or innovations.This review included studies that used a variety of termsto describe sustainability (e.g., “maintenance, ”“durabil-
ity,”“institutionalization, ”and “routinization ”[9,24,25])
and the decision to discontinue or the failure to sustainprograms or interventions (e.g., “de-adoption, ”“divest-
ment, ”“exnovation, ”and “discontinuation ”[6,26,27]).
However, for the purpose of consistency in the currentreview, we will primarily use the terms “sustainability ”
(or “sustainment ”)a n d“ discontinuation, ”respectively.
Specific questions that guid ed our review include the
following:
How has sustainability been defined?
At what levels and units of analysis has it been
studied?
What research methods have been used?
Over what time periods?
What outcomes have been reported in the empirical
literature?
What were the findings?
What has research told us to date about influences
on sustainment?Our findings provide an overview of the current state
of the research literature on the sustainment of specificinterventions and programs that were implemented toachieve particular goals or benefits. By looking broadlyat efforts to study the phenomenon, it may be possibleto distill those considerations that should be integral to
programs of research that examine the sustainability of
specific interventions, programs, and practices [23].B a s e do nt h e s ef i n d i n g s ,w ew i l lm a k ean u m b e ro frecommendations for defining, assessing, and studyingthis topic in future research.
Methods
Search method
We searched the MEDLINE, ISI, PsycINFO, AcademicSearch Premier, Health Source, ERIC, and Google Scho-lar databases using the terms “sustainability, ”“imple-
mentation, ”“long-term implementation, ”“routinization, ”
“discontinuation, ”“de-adoption, ”“durability, ”“institutio-
nalization, ”“maintenance, ”“capacity building, ”and
“knowledge utilization. ”Truncated forms of these terms
(e.g., “sustai* ”,“routini*” ,“institutionali* ”) and alternative
spellings were included in the search. We also employeda snowballing strategy, in which we searched the refer-ence sections of reviews and theoretical papers onimplementation and sustainability [2-4,19,23,25,28,29]and those found in our review. We searched the tablesof contents of key journals a nd journals that had pub-
lished more than one relevan t study on sustainability.
These journals included the following: Academy of Man-
agement Review, Academy of Management Journal,Administrative Science Quarterly, American Journal ofPublic Health, Administration and Policy in MentalHealth and Mental Health Services Research, AmericanJournal of Evaluation, Implementation Science, HealthServices Management Research, Health Services Research,Healthcare Management Review, Journal of HealthcareManagement, The Journal of Nursing Administration,
The Journal of General Internal Medicine, Medical Care
Research and Review, Millbank Quarterly ,a n d Psychia-
tric Services . Additionally, we examined papers that had
cited influential models or reviews of implementation orsustainability [2,3,5,19,25,30 - 3 2 ] .F i n a l l y ,w ep r o v i d e d
the list of articles that were found using these strategiesto four individuals known to the investigators who studyimplementation or sustai nability and asked them to
share additional articles that they were aware of thathad not been included. This yielded nine additionalstudies.
Inclusion and exclusion criteria
Our inclusion criteria included peer-reviewed studiesthat addressed sustainabilit y of specific interventions orWiltsey Stirman et al .Implementation Science 2012, 7:17
http://www.implementationscience.com/content/7/1/17Page 3 of 19
programs, were written in English, and were published
or in press by July 2011. Because sustainability has beendefined in numerous ways, we included all studies inwhich the authors used one of the terms describedabove or in which an effort was made to determine theextent to which a program or intervention continued
after an initial period of training, implementation, or
study. Studies were coded only if they included a metho-dology or procedure designed to identify (1) the statusof the program after the initial implementation effort orfunding has ended (e.g., fidelity, percent implemented,presence or absence of key components, or discontinua-tion); (2) the program-, service-, or recipient-level out-comes measured after external support or funding was
withdrawn; or (3) the influences on the persistence of
the implementation, whether or not the primary focusof the article was sustainability. Articles were excluded ifthey (1) reported only on initial implementation efforts,(2) were purely narrative accounts or papers on “lessons
learned ”that did not examine sustainability using quali-
tative or quantitative research methodologies, (3)reported only long-term follow-up of individuals after a
clinical trial or intervention study, or (4) contained
insufficient information to determine whether inclusionor exclusion criteria were met (e.g., ambiguity or failureto report the timeframe during which measures werecollected). Studies were con sidered to focus on initial
implementation efforts if the original training, supervi-
sion, monitoring, or funding support was ongoingthroughout the time period of the research (unless mon-
itoring was considered a central element of the program
or conducted strictly to assess sustainability, with mini-mal or no feedback provided).
Review methods
All titles and abstracts retrieved by electronic searchingwere reviewed by one reviewer, who screened out papersthat were not related to implementation (e.g., articles
related to sustainable agriculture or discontinuation of
medications in the context of clinical interventions).Where it was not possible to exclude articles based ontitle and abstract, full text versions were obtained andtheir eligibility was assessed. Full text versions of allpotentially relevant articles identified from the referencelists of included articles were obtained. Papers related toimplementation were screened independently by two
reviewers, and those studies that did not meet the inclu-
sion criteria were excluded. Raters agreed on 95% of thepapers that were excluded and agreed on the reasonsfor exclusion for 91% of the articles. Disagreementswere resolved through discussion and consensus.
Figure 1 is a modified PRISMA (which stands for Pre-
ferred Reporting Items for Systematic Reviews andMeta-Analyses [33]) diagram summarizing the selectionprocess, which includes reasons that potentially relevantpapers were excluded. A total of 460 published articleswere found and considered; 125 were determined to berelevant for coding (An additional file lists studiesincluded in the review [see Additional file 1]). Of thepapers included, 100 focuse d on or explicitly addressed
sustainability. The remaind er of the papers contained
follow-up data on implementation from an interventionor training study, or focused primarily on disseminationor implementation but included information aboutsustainability.
Coding
An initial coding scheme was developed based on con-
structs identified in previous conceptualizations of
implementation [2-4,9,3 4,35] and sustainability
[4,5,17,20,36-44]. Additional codes were generateddeductively by the raters if a construct or process identi-fied in the literature was not represented in the codingscheme. Related constructs among potential influenceson sustainability were identified by consensus and col-lapsed under the general categories described in the
findings. Thirty percent of the papers included in the
review were coded by two raters and rater agreementwas assessed. Agreement (Cohen ’s kappa) ranged from
.85 to 1 ("substantial ”to“almost perfect ”[45]) on the
broad categories and from .61 to 1 ("moderate ”to
“almost perfect ”[45]) on more specific categories, which
were later collapsed into the three broad categories.Additionally, disagreements on four items that were
coded at lower frequencies with moderate agreement
(.61-.80) were resolved by discussion and consultation ifnecessary with co-authors, resulting in consensus rat-ings. Two coders also rated 40% of the health-related(medical, public health/h ealth promotion, or mental
health) studies that reported sustainability outcomes forassessment method and the presence or absence of anindication of the level of quality or fidelity. Raters agreed
on 93% of the ratings for assessment method and 90%
for indication of quality or fidelity. The few disagree-ments were resolved through discussion.
Results
Characteristics of included studies
Area of study
Our search procedure identi fied studies from a variety
of fields. Forty-one (33%) of the studies reported on
medical interventions or healthcare programs, 42 (34%)on public health or health promotion programs, 33(27%) on mental or behavioral health interventions, and9 (7%) on educational interventions. Eighty-eight (72%)of the studies examined either programs or multicompo-nent interventions as opposed to a single procedure orintervention, such as a discrete medical procedure.Wiltsey Stirman et al .Implementation Science 2012, 7:17
http://www.implementationscience.com/content/7/1/17Page 4 of 19
Unit of analysis
The majority of the studies ( 67; 54%) reported on sus-
tainability at multiple implementation sites or settings,
followed by studies that reported on sustainability at theindividual or provider level (15; 12%). The remainder ofthe studies reported on sustainability within single sys-tems or communities (20; 16%), at a single site (11; 9%),among individual providers within sites (7; 6%), or atthe team level (5; 4%).
Timeframe examined
Studies were coded for the last post-implementationtimeframe reported. Most studies (80; 64%) occurredtwo years or more past the initial implementation.Seven (6%) reported outcomes at less than 12 monthspost-implementation, 20 (16%) at 12 months, and 15(12%) between 12 and 24 months post-implementation.
Terms and definitions
Sustainability was defined in a number of ways, and
different terms were used to refer to the continuationof an innovation within an organization or community.
Table 1 includes a listing of authors whose definitionswere cited in the literature as working definitions ofsustainability, as well as the frequency with whichterms related to sustainability were used. Sixty-five
p e r c e n to ft h es t u d i e se x a m i n e dd i dn o tp r e s e n tad e f i -
nition. Among the studies that did present definitions,definitions were most commonly generated by theinvestigator. The most commonly used term in thestudies examined was “sustainability, ”which was used
in 62% of the articles. Those who cited a specific, pub-lished definition as their operational definition mostfrequently cited Scheirer ’s definition [25], which was
based on the framework set forth by Shediac-Rizkallahand Bone [5], whose review was the second most com-monly cited. Both identified multiple aspects of sus-tainability: continued benefit s, continued activities, and
continued capacity. 
 
     
 
    
 
    460 potentially relevant studies 
identified 
426 studies selected for full text evaluation
301 excluded articles
xReport or description of initial implementation (128)
xReports on initial outcomes only (73)
xInsufficient information provided (31)
xNarrative/lessons learned (17)
xInsufficient information on implementation (16)
xLong-term follow-up from clinical trial (13)
xTimeframe/timeline unclear (12)
xOriginal funding present (6)
xNot on implementation or sustainability (4) 
xDevelopment of measures (1)34 articles presented conceptualizations 
or reviews of sustainability 
125 studies selected for evaluation
Figure 1 Diagram of Study Selection and Exclusion Process .Wiltsey Stirman et al .Implementation Science 2012, 7:17
http://www.implementationscience.com/content/7/1/17Page 5 of 19
Methods used
Almost half of the studies reviewed employed self-report
measures (54; 43%; nearly all were developed specificallyfor the project or study) or interviews (50; 40%) to assesssustainability or its influences. Fifty-four (43%) includedsome form of observation, 35 (28%) involved recordreview, and 23 (19%) included assessment of the fidelity/integrity of an intervention or practice. Eight (7%) of thestudies reported on sustainability after an intervention had
been implemented in a clinical trial. Solely quantitative
approaches were used in 68 (54%) of the studies, qualita-
tive approaches alone were used in 27 (22%), and 28 (23%)of the studies employed both qualitative and quantitativestrategies. Nearly all examinations of sustainability werenaturalistic rather than experimental. However, seven stu-dies (6%) involved experimental manipulation of trainingor implementation strategies and assessed self-reported
use, skill, or fidelity at a follow-up.
Outcomes reported
Studies discussed or reported on a variety of outcomes,
and some reported multiple outcomes. Fifty-sevenhealth-related studies (45% of the studies reviewed)reported outcomes such as the proportion of sites orproviders sustaining, or the proportion of eligiblepatients receiving an intervention. The remaining stu-dies did not report sustainability outcomes or reporteddata in such a way that it was not possible to determine
the extent to which an intervention or practice was con-
tinued. For example, some reported on factors related tosustainability, without describing sustainability out-comes. Among the 57 studies that reported outcomes,51 reported the proportion of sites or providers sustain-ing or discontinuing an intervention or program. Theremaining studies reported the percent of patients orcommunities that received an intervention during a fol-
low-up period. Seventy-fiv e (60%) of the reviewed stu-
dies reported changes in the rate of program
implementation and/or recipient outcomes, and two stu-dies reported changes in both. Twenty-seven (22%) ofthe studies reported some form of health outcome (sus-tained impact or increases/decreases in desired out-comes), 14 of which were published in or after 2010.
Summary of findings
Figure 2 contains a summary of the sustainability out-
comes reported for medical, public health/health pro-motion, and mental health studies. In general, a widerange of outcomes was report ed. Rates of continuation
of some, but not all, program or intervention elements("partial sustainability ”) were relatively high across fields
and units of analysis. Sixteen studies employed a formof independent observation and/or fidelity assessment to
evaluate sustainability outcomes. In light of the litera-
ture that self-report assessments are often inaccurate[59], the figure distinguishes studies that employedobservation from those that solely employed self-reports.Few studies that included independent observation orvalidation reported high rates of continuation at the siteor setting level. The studies that reported on full sus-tainability or high fidelity at the provider level indicated
that fewer than half of the observed providers sustained
the practices at a high level of skill, intensity, or fidelity.
Of the 75 studies that reported on changes in imple-
mentation or recipient-level outcomes after initial imple-mentation efforts or funding had ended, 56 studiesreported on the intervention or program implementa-tion. Of these, 19 reported lower levels of implementa-tion after initial implementation efforts had ended, 17
reported an increase, and 3 reported no change or a
similar level of implementation. Seventeen studiesreported varying changes in rates across different inter-vention or program components. Twenty-one studiesassessed changes in outcome s: 5 reported a decrease in
desired outcomes, 10 reported an increase, and 1reported no change. The remaining five studies reportedTable 1 Definitions of sustainability in reviewed studies
Focused on sustainability N
Yes 102
No 23
Defined sustainability N
Yes 36
No 80
Cited multiple definitions; didn’ t specify an operational
definition9
Term useda:
Sustainability 77
Long-term/follow-up implementation 12
Institutionalization 6Durability 3Discontinuation 1De-adoption 1Maintenance 1
Sustained/continued implementation 1
Routinization 0
Definition cited N
Other [9,32,46-56]
b12
Created definitions 8Scheirer [25] 6Shediac-Rizkallah and Bone [5] 4
Glasgow et al. [24] 2
Pluye et al. [57] 2Goodman and Steckler [58] 2
aSome studies (e.g., follow-up studies from clinical trials) did not refer to
sustainability or a related term;bEach cited in one paper.Wiltsey Stirman et al .Implementation Science 2012, 7:17
http://www.implementationscience.com/content/7/1/17Page 6 of 19
multiple outcomes or indicators that varied in the extent
to which they sustained.
Associated elements and influences
Thirty studies employed quantitative methodologies toidentify predictors, correla tes, or associated factors of
sustainability. Thirty-six studies employed qualitative ormixed methodologies to identify influences on or pro-cesses associated with sustainability. Twenty of thesestudies specified that they were guided by a conceptualframework. Four broad categories of potential influences
emerged in our coding process: influences related to the
innovation, organizational context, capacity (internaland external), and processes. These four categories werecommon among each of the health-related fields weexamined. However, only eight of the quantitative stu-dies that examined elements related to sustainabilityincluded all four areas in their analyses, and 12 exam-ined factors related to both the organization and capa-
city (typically, characteristics or attitudes of the
workforce). Twelve of the studies, all of which employedqualitative or mixed methodologies, found that elementsin all four categories were associated with sustainability.
Table 2 summarizes the findings, which are organized by
study method (qualitative o r quantitative) and health-
related field (medicine/healt h care, public health/health
promotion, and mental health). Findings regarding specificinnovation characteristics and contextual factors werefairly consistent across medical/health care, public health/
health promotion, and mental health studies. Findings
related to capacity varied somewhat across fields. The pre-sence of a champion was a less frequent finding for publichealth studies; funding was a much more common findingin this area. Workforce-related findings (e.g., adequatestaffing, attributes of personnel) were less frequent find-ings in health care, and community support was less fre-quently identified as associated with the sustainment of
mental health programs or interventions. Findings related
to processes emerged most commonly in qualitative stu-dies and were identified most commonly in public healthprograms. Perhaps due to the nature of the instruments orassessment procedures used in quantitative studies, pro-cesses were rarely identified. Engagement of stakeholderswas more frequently associated with sustainability for pub-lic health studies, and adaptation of the intervention and
alignment between the innovation and the setting were
less frequently found in mental health studies.
Discussion
We examined 125 published papers to identify the dif-ferent methodologies, types of innovations studied, time-frames examined, definitions used, outcomes examined,and factors examined in research on sustainability to                                                                                                                                     
                          
  
 
 
 
    
 
    
 
  More 
Rigorous 
Methods 
(N =1) Less 
Rigorous 
Methods 
(N=14) 
Providers 
(N=1) Site 
(N=8) Providers 
(N=3) Patients 
(N=3) 
Partial 
(N=1) 
80% Unspecified 
(N=3) Unspecified  
(N=3) 
Unspecified 
(N=6) 
60%-87% 39%- 98% 11.2%-68% Public Health/Health Promotion 
(N=25) Mental Health 
(N=20) 
More 
Rigorous 
Methods 
(N=10) Less 
Rigorous 
Methods 
(N=10) 
Site 
(N=6) Provider  
(N=3) 
Low 
(N=1) 
44% Partial 
(N=4)  
11% -94% Full  
(N=2)  
42%, 45% Site 
(N=8) Patient 
(N=1) 
Unspecified 
21-50% More 
Rigorous 
Methods 
(N=5) Less 
Rigorous 
Methods 
(N=21) 
Patient  
Partial  
96% Site 
(N=17) Provider  
(N=3) Patient  
(N=1) 
Full 
(N=4 ) 
7%, 88% Unspecified 
(N=8)  
44-88% Unspecified 
(N = 3)  
32%-86%  
 Unspecified
(N = 1) 
11.6% Medical 
(N= 15) 
Full 
(N = 1) 
21%  Full 
(N = 2)  
11%, 20% Site 
(N = 4) 
Low 
(N=1) 
64% Partial 
(N=2) 
90, 100% Full  
(N=2) 
79, 100% 
Full 
(N = 1) 
80% Site 
within 
system  
(N = 1) 
Partial 
79%Partial 
(N=1) 
48% 
Low 
(N=1) 
91% 
Full  
(N=2) 
11.6% Partial 
(N=1) 
60.4%  
Partial 
(N=2) 
68% -97% Unspecified  
(N=3) 
11%-94%  Provider  
(N=1) 
Partial  
100%
Low  
60% Partial  
100%  Full    
6.7%  Low  
(N=2)  
34%, 53% Partial  
(N=4)  
0-81% 
Figure 2 Sustainability Outcomes By Field . Note: More rigorous studies are defined as having included independent or objective observation
and a judgment of fidelity, quality, or level of implementation. Ranges are provided when multiple studies reported these rates.Wiltsey Stirman et al .Implementation Science 2012, 7:17
http://www.implementationscience.com/content/7/1/17Page 7 of 19
date. Discussions in the literature over the past two dec-
ades [5,25,32] regarding the importance of sustainability
appear to have resulted in an increase in research onthis topic. However, our review found relatively fewcomprehensive or methodolo gically rigorous studies.
The majority of the studies were retrospective. Most didnot provide an operational definition of sustainability,and fewer than half appeared to be guided by a pub-lished definition or model of the concept. Few employed
independent evaluation or observation.
Sustainability outcomes
Because of the variety of results reported in the studies
we reviewed, it is difficult to quantify or generalizeabout the extent to which new programs and practices
are sustained. However, three findings are notable. First,
similar to findings from a previous review [10], wefound that those studies t h a tp r o v i d e di n f o r m a t i o n
about levels or extent of implementation generally indi-cated that partial sustainability was more common thancontinuation of the entire program or intervention, evenwhen full implementation was initially achieved. Mostprojects did not maintain all aspects as originally
designed or implemented. Ho wever, in the studies that
we reviewed, it was not possible to determine the
impact of partially sustaining interventions on recipient-level outcomes. Further, virtually no studies revealed thenature of the changes made, the reasons for the changes,Table 2 Influences on sustainability
Overall Health-related field-specific findings
Number of
quantitative
findings
(n = 30 studies)Number of
qualitative
findings
(n = 36 studies)Number of
medical intervention
findings
(n = 19)Number of
public health/health-
promotion
findings
(n = 27)Number of
mental health
findings
(n = 22)
Innovation characteristics 11 18 7 12 10
Fit 5 5 2 3 5
Ability to be modified/
modifications made47 2 5 4
Effectiveness or benefit 4 5 3 4 2
Ability to maintain fidelity/integrity20 0 1 1
Context 14 13 7 10 10
Climate 0 2 1 0 1
Culture 2 1 2 1 0
Leadership 5 12 3 8 6
Setting characteristics (structure;policies)11 2 4 4 5
System/policy change 2 5 3 3 1
Capacity 15 23 11 14 12
Champions (internal or external) 5 6 4 3 4
Funding 5 8 3 8 2
Workforce (staffing, attributes) 10 12 4 10 7
Resources 2 7 4 3 3
Community/stakeholder support/
involvement61 0 5 9 2
Processes and interactions 8 27 10 16 8
Engagement/relationship building 2 7 0 7 2
Shared decision making among
stakeholders32 2 2 1
Adaptation/alignment 2 5 2 5 0
Integration of rules/policies 3 10 4 6 2
Evaluation and feedback 2 6 1 4 2
Training and education 4 8 3 3 5
Collaboration/partnership 1 11 3 7 2
Navigating competing demands 0 4 1 2 1
Ongoing support 4 11 4 4 6
Planning 0 1 0 1 0Wiltsey Stirman et al .Implementation Science 2012, 7:17
http://www.implementationscience.com/content/7/1/17Page 8 of 19
or the process by which adaptations or decisions to dis-
continue elements of the program or intervention weremade. A second key finding is that in the past five years,there has been an increase in the number of studies thatreported data on the sustainability of patient- or recipi-ent-level benefits. Future st udies that further examine
these outcomes will be critical to understandingwhether, and to what extent, the health-related benefitsof implementation efforts can be sustained over time.Finally, the studies that empl oyed independent fidelity
ratings to assess sustainability at the provider level indi-cated that fewer than half of the providers sampled con-tinued the practice or intervention at high levels offidelity. These findings suggest that the development
and study of fidelity-maintenance strategies, such as
training and supervision, audit and feedback, buildingtriggers into the process of care, checklists, or remin-ders, may be particularly important for the sustainmentof interventions that require a high degree of fidelity toproduce the intended health benefits [60-62].
Influences on sustainability
Our review found that although terminologies and areasof emphasis differ somewhat across fields, influences onsustainability relate to the context (both outer, e.g., poli-cies, legislation; and inner, e. g., culture, structure), the
innovation itself (e.g., fit, adaptability, and effectiveness),processes (e.g., fidelity monitoring, evaluation, efforts toalign the intervention and the setting), and the capacityto sustain (e.g., funding, resources, workforce character-
istics and stability, interpersonal processes). Some quali-
tative findings also supporte d the conceptual literature
that suggests an interrelation and interaction betweenthese factors [63]. The broad categories of influencesthat our findings appeared to fit overlap most closelywith the components of Shediac-Rizkallah and Bone ’s
(1998) and Scheirers’ (2005) conceptual izations, which
were some of the more commonly cited definitions in
the studies that we reviewed [5]. Within these broad
categorizations, however, the key elements that wereidentified varied considerably.
Findings related to capacity were relatively common in
both quantitative and qualitative research. For example,both qualitative and quantitative methodologies identi-fied influences related to the workforce as associatedwith sustainability. These included the stability of the
workforce and attributes of the workforce, such as their
skills and attitudes. Additionally, qualitative studiesidentified the support or pa rticipation of key stake-
holders and funding as important influences. Fundingwas rarely measured or included in the analyses, perhapsbecause studies took place after the initially allocatedfunding and resources had been removed. While somestudies explicitly assessed or discussed the availability ofnew funds to support the programs that were being stu-died, most did not indicate whether additional fundinghad been obtained or allocated. However, influencessuch as sufficient resources and staffing that were iden-tified in qualitative studies may be indicators of the ade-quacy of funds.
Other elements that are included in conceptualizations
of sustainability [18] rarely emerged in the hypothesesor findings of the studies that we reviewed. Evaluation,feedback, and other quality-improvement processes werealso less well represented than expected. Program orintervention effectivenes s was identified in only nine
studies, despite a fairly common emphasis on the impor-tance of observable benefit s within the implementation
literature. In contrast to the relatively consistent empha-sis on characteristics of the innovation within concep-tualizations of sustainability and the broaderimplementation literature, fewer studies than expectedfound that characteristics of the innovation were asso-ciated with sustainability [3,9,64]. The dearth of findingsrelated to innovation characteristics may be due to thelack of influence of the innovation on sustainability, but
it may also be due to researchers ’lack of attention to
these constructs. Some researchers may have viewed
innovation characteristics as more central to adoption
decisions than to sustainment. Others may have over-looked innovation characteristics because they wereexamining a single innovation or organization and thuslacked sufficient variability to study the relative impactof factors such as fit or the intervention’ sc o m p l e x i t y .
Not surprisingly, among the i nnovation characteristics
that were identified, the fit of the program or interven-tion with the system or organization and the degree towhich the intervention or program could be modified
were most common. Finally , given the amount of dis-
cussion on leadership, organizational climate, and cul-ture in the literature on implementation andsustainability [5, 20,35,39,65,66], we expected greater
representation of these constructs in the studies thatwere reviewed.
Processes and interactions were associated with sus-
tainability in nearly three-quarters of the qualitative stu-dies. Integration of the program into policies,collaboration among stakeholders, and ongoing supportwere commonly identified processes. Findings related toprocesses that emerged in qualitative studies may
explain why factors such a s culture and climate were
rarely identified in the studies we reviewed, despite their
prominence in the implementation literature. Thosewho were interviewed in qualitative studies may havebeen more likely to describe noticeable processes andinteractions that are evidence of a particular culture orleadership style than to characterize the culture of anorganization. For example, some processes identified inWiltsey Stirman et al .Implementation Science 2012, 7:17
http://www.implementationscience.com/content/7/1/17Page 9 of 19
our review, such as integration into policies or stan-
dards, may serve as “culture-embedding mechanisms ”
[67,68]. Similarly, negotiation, relationships, and shareddecision making may be fostered by effective leadersand found more commonly in contexts that are pre-pared to nurture and sustain new practices. Studies with
quantitative designs were less likely to identify processes
and interactions of this nature, perhaps due to theirdesign and research questions, as well as the modelsand measures that were employed. Important processesmay have been subsumed, identified, or obscured underrelated and more readily measured constructs. The pro-cess-related findings highlight the importance of investi-gating the ways in which influences at multiple levels
may interact to impact sustai nability [19]. For example,
some processes that were identified in our review sug-
gest mutual adaptation betw een the intervention and
the organization or system (e.g., adaptation of the inter-vention to improve fit, alignment of the organizationalprocedures with the intervention), or important interac-tions between stakeholders in various roles (e.g., nego-tiation, navigating competing demands). Such findings
suggest that interplay between contextual factors and
the innovation itself is to be expected given the dynamicnature of the complex systems into which innovationsare introduced [19,69].
In summary, the findings that we presented above
illustrate the variability in methods, outcomes, andpotential influences that have been studied to date.Based on the empirical literature that we reviewed, it is
difficult to generalize about influences on sustainability
and the long-term impact of implementation efforts. Asresearch develops further, refinements in conceptualiza-tions and study designs w ill lead to results that are
more easily interpreted. Below, we discuss some consid-erations and recommendations for such research.
Recommendations for advancing the empirical literature
Defining sustainability
An important limitation to the body of research on sus-
tainability that we reviewed is the high proportion of stu-dies that did not present a working definition ordemonstrate evidence of guidance by a model of sustain-ability. The way that the concept is defined and concep-tualized has important implications for how it isinvestigated. At a basic level, the studies that we reviewed
focused on the continuation of the programs and prac-
tices that were implemented within organizations, sys-tems, or communities after initial implementation effortsor funding ended [70]. While such a broad definitiona p p l i e sa c r o s san u m b e ro fdisciplines and contexts,research based on such a definition can yield results thatare difficult to interpret, particularly when the studiesconclude that some aspects of a program or innovationcontinued while others did not. Thus, we recommendthat both a definition and a conceptual framework becarefully chosen to guide research in this area.
In light of our review, we suggest that investigators
consider several factors in choosing a definition to guidetheir research on the sustainment of interventions or
programs and that they clearly specify their research
questions regarding each factor. These factors are (1)whether, and to what extent, the core elements (the ele-ments most closely associated with desired health bene-fits) [23,32,64] are maintained; (2) the extent to whichdesired health benefits a re maintained or improved
upon over time after initial funding or supports havebeen withdrawn; (3) the extent, nature, and impact of
modifications to the core and adaptable/peripheral ele-
ments of the program or innovation [23,32]; and (4)continued capacity to function at the required level tomaintain the desired benefits. A program or interven-tion ’simpact may be considered sustained if desired
health benefits remain at or above the level achievedduring implementation and this increase can be attribu-ted to continuation of the program. A program or inter-
vention may be considered to be sustained at a given
point in time if, after initial implementation support hasbeen withdrawn, core elements are maintained (e.g.,remain recognizable [13] or delivered at a sufficientlevel of fidelity or intensity to yield desired health out-comes [59,62,71]) and adequate capacity for continua-tion of these elements is maintained.
Defining outcomes or desired benefits
As our discussion of elements of sustainability aboveindicates, the desired impact and benefits of the programor intervention should be identified. Additionally, stake-holder goals for sustainability (e.g., Must the program besustained at the same level, or improved upon? To whatextent is a lower level of implementation fidelity or a par-tially sustained program consistent with stakeholders ’
goals for the project? At what point, and under what cir-
cumstances, is discontinuation, modification, or imple-
mentation of a more effective, efficient, or better-fitting
intervention advisable?) should be considered in theinterpretation of findings . The type of innovation and
setting will drive some of these considerations. For speci-fic interventions identified to improve patient-level out-comes (e.g., reduce rates of infection, relieve symptoms),these health benefits may be considered to be the “bot-
tom line. ”For programs formed to identify and imple-
ment multiple intervention s to achieve health-related
goals, outcomes such as indicators that programs arebeing implemented, the existence and functioning of adecision-making body, and coordination between multi-ple agencies or stakeholders may be critical outcomes inaddition to population-level outcomes such as reducedrates of disease or infection.Wiltsey Stirman et al .Implementation Science 2012, 7:17
http://www.implementationscience.com/content/7/1/17Page 10 of 19
Choosing an appropriate timeframe
When studying the sustainment of a program or inter-
vention, a timeframe that is sufficiently beyond an initialimplementation effort to provide meaningful informa-
tion must be chosen. Although there may be no obvious
indicator for determining when initial implementationefforts have “ended, ”it can be useful conceptually to
separate the period of initial implementation from apost-implementation phase. Most of the studies wereviewed examined sustainability two or more yearsafter implementation, consistent with suggestions in theliterature [24]. Although m any existing conceptualiza-
tions imply that sustainability cannot be studied untilfull implementation is achieved [31] and funding iswithdrawn [4], some programs may never be fullyimplemented due to a variety of forces within or exter-nal to systems and organizations. For example, somemay have funding withdrawn before full implementationis achieved [5], yet these programs may achieve successin maintaining some components of the programs over
time. Additionally, as most studies that we reviewed
measured sustainability at a single time point, they mayhave masked what several conceptualizations present asa dynamic phenomenon. To advance what is currentlyknown about sustainability over time and to capturevariations over time, we suggest that researchers assesssustainability over several years rather than at a singletime.
Studying fidelity and adaptation
Consistent with discussions of sustainability that suggestthat adaptation and evolution of the practices and inno-vations are to be expected [25,32,72,73], a number ofstudies that we reviewed indicated that some form ofmodification had occurred. While such changes may bemade to interventions or programs in response to con-textual influences, such as shifting priorities or availabil-
ity of resources, the process and nature of adaptations
m a yv a r yc o n s i d e r a b l yb e t w e e np r o j e c t s .M o s ts t u d i e sthat we reviewed did not describe adaptations or exam-ine their impact on health-related outcomes. To facili-tate a greater understanding through future research,some clarity regarding adaptation and fidelity is neces-sary. Additional research is needed to assess the condi-tions under which fidelity, or different types and degrees
of adaptations, are important for the achievement of
specific health benefits. While it is important to differ-entiate sustainment from entrenchment, which may pre-
vent further innovation or adoption of more effective
practices [16,31,32], it is also critical to understandwhen, and to what components of a particular programor intervention, fidelity is n ecessary. Fidelity has been
conceptualized in the mental health literature as a com-
bination of adherence to a prescribed set of practices at
adequate dose or intensity, competence in delivery, anddifferentiation from other interventions [59,74], withjudgments of competence taking response to certaincontextual factors into acco unt [23]. In the medical lit-
erature, it has been defined as “the extent to which the
system provides patients the precise interventions theyneed, delivered properly, precisely when they need
them ”[71]. Evidence has emerged that for some inter-
ventions, a higher level of fidelity or intensity may be
required to produce desired health benefits [11,62,74].In these cases, insufficient levels of fidelity may in factindicate that a program was not sustained at the levelnecessary to promote these outcomes. On the otherhand, the success of some programs (e.g., community-based health promotion programs) may be less depen-
dent on the implementation of a set of procedures with
fidelity than on the flexibility and adaptive capacity ofthe system or organization that implements the pro-gram. In such cases, the range of possible or even neces-sary adaptations within the program might be quitebroad [75,76] and may reflect new priorities or responseto local conditions [77]. This type of ongoing evaluation,modification, and replacement of elements or proce-
dures as necessary is an approach advocated in organi-
zational learning and conti nuous quality-improvement
literatures [78-80]. Theory in this area suggests that anappropriate balance between exploration of new meth-ods while exploiting existing knowledge regarding effec-tive strategies may in fact result in more sustainable andsuccessful programs [81,82].
Simply measuring fidelity and characterizing modifica-
tions as deviations may obscure the very refinementsthat facilitate the continued use of some innovations. Aperiod of mutual adaptation [83] is probably commonbetween initial implementatio n and institutionalization,
and some innovations may continually evolve [76]. Toadvance the field, subsequent research should includefurther attention to the nature of the modifications thatoccur and the process by which modifications are made
[84,85]. Even for those interventions for which there is
evidence that fidelity is important, there may be aspectsthat can be adapted and modified, while preservingdesired outcomes [23,86,87] , provided that the critical
elements are conducted or delivered at adequate levelsof fidelity. Several types of modification, at either amolecular or molar level [74,88], may occur as practi-tioners, communities, and s ystems implement specific
programs and interventions. For example, tailored adap-tation may be guided by available evidence and remainfaithful to identified core elements [23], with an eyetowards facilitating desired health benefits. Evolutionmay occur if procedures are modified in light of theemergence of new evidence [89]. Replacement mayoccur if more compatible or effective interventions orprocedures are identified [9] . Adaptations that result inWiltsey Stirman et al .Implementation Science 2012, 7:17
http://www.implementationscience.com/content/7/1/17Page 11 of 19
reversion or erosion fail to preserve the core elements of
an intervention, which may in turn result in a failure topreserve desired health outcomes. In such cases, if theintervention that was originally introduced becomesunrecognizable [13], it may be considered to have beendiscontinued. We therefore recommend that when the
intervention is the focal unit of interest, in addition to
identifying methods of asse ssing fidelity, researchers
study periods of adaptation [90] and characterize thenature of modifications made to interventions. It willalso be important to understand more about the natureof possible trade-offs that are made between fidelity andsustainability and how stakeholders make suchdecisions.
Identifying core elements, or components that are cri-
tical for the achievement of desired outcomes, is also acritical area for future study. Developers of many com-plex interventions have not yet pursued these questions.Isolating elements of innovative practices and examiningtheir relative contributions to the overall impact of thepractice can be challenging and may not be feasible ordesirable in some situation s. However, when available,
this information can facilitate a streamlined or prag-matic implementation effort that retains the aspectsfound to be most effective and successful in everydaypractice [16]. As a positive impact on intended recipi-ents is the ultimate goal of implementation, we recom-mend that researchers include a consideration of theseimportant matters in their efforts to study sustainability.
Conceptualization, measurement, and assessment of
influences on sustainability
Findings from our review suggest that the study of influ-
ences on sustainability is nascent. Fewer studies than weexpected identified influences that are found in existingconceptualizations of sustainability. It is possible thatthese findings result from a lack of guidance by a theo-retical framework, given that fewer than one-third of thes t u d i e st h a tw er e v i e w e dw e r eg u i d e db ya ne x p l i c i t
model. To advance research in this area, we recommend
that researchers identify models or frameworks of sus-tainability [91] that are most appropriate for their pro-jects and research questions. In doing so, considerationshould be given to the issues regarding fidelity, the
potential for adaptation, and the nature of the systemthat will be studied. As many models of sustainabilityhave not been evaluated [19,20,92], we do not yet know
enough about which models are valid and appropriate
[93] for differing programs and circumstances [16].Thus, efforts to evaluate con ceptualizations of sustain-
ability can further advance the field.
There is also room for improvement in methods
employed to characterize intervention sustainability andits influences. Beyond fidelity measures used in clinicaltrials, there are few procedures or benchmarks to guideresearchers in efforts to identify the extent to whichinterventions and programs were continued as imple-mented. Pluye and colleagues operationalized definitionsof three degrees of sustainabi lity for public health pro-
grams (weak, moderate, and high) but did not develop aformal assessment instrument. However, they did
develop a 15-question interview to assess degrees of sus-
tainability [41]. The Level of Institutionalization scale
has been developed to gauge the extent to which keyactivities for a health-promotion program have occurred[94,95], and the authors suggest that the measure can bemodified easily for a variety of health-promotion pro-grams and settings. When fidelity is necessary to sustainoutcomes, observation using a set of criteria for ade-
quate skill, adherence, or intensity will improve the pre-
cision with which results are reported. As in other areas,self-reports of fidelity are likely to be imprecise [59].The development of valid, yet low time- and cost-inten-sive, observation or monitoring strategies would repre-sent a significant advance [59]. Triangulation ofinformation gathered thr ough multiple methods may
ultimately be most informative. As fidelity measures are
generally not designed to as sess, describe, or elucidate
the nature and consequences of adaptations, methods of
assessment in this area must also be advanced [72].
Typically, in research that employs surveys to measure
influences on sustainment, the instruments were devel-
oped for the specific projects or implementation efforts[40], and psychometric properties were almost neverreported. The development of a wholly unique proce-
dure for assessing the sustainability of each intervention
or program limits the conclusions that can be drawnfrom the literature as a whole. In lieu of specific mea-sures, other studies employed survey results or informa-tion about setting characteristics collected during theimplementation process to identify predictors [c.f.96].Thus, assessment and analytic strategies employed todate may not have captured the appropriate influences
and their interactions. Multilevel measurement of sus-
tainability [20,29], based on sound conceptualization, isnecessary to allow for greater methodological rigor andinterpretability of findin gs [91], and some measures
have been developed for this purpose. Mancini andMarek developed a 29-item Program Sustainability
Index to assess six factors related to the sustainability ofcommunity-based programs [40]. An instrument was
also developed based on the National Health ServiceInstitute for Innovation and Improvement ’s Health Ser-
vice Sustainability model. While the model was intendedto be used in the planning and early stages of imple-mentation to evaluate the likelihood that an innovationwill be sustained, the authors suggest that it can be usedat any phase of a project [13]. Both of these surveysassess factors and processes at multiple levels and canWiltsey Stirman et al .Implementation Science 2012, 7:17
http://www.implementationscience.com/content/7/1/17Page 12 of 19
be used to examine the relationship and interactions
among differing elements and levels, although furtherresearch on their validity and applicability to a broadrange of programs or interventions is warranted.
Qualitative and mixed methodologies that assess
potential influences across multiple levels will continue
to be necessary to refine hypotheses, explore results,
understand the relationships between sustainability dri-vers, and facilitate the development of interventions topromote the sustainability of effective programs andpractices. Our review indicates that qualitative studiesyielded a wider variety of findings and have highlightedprocesses and constructs that warrant further study.However, the vast majority did not provide interview
guides to clarify how they assessed activities, processes,
or influences associated with sustainability. This stepwill improve the interpretability and replicability offuture research. Furthermore, prospective research onsustainability and efforts to identify influences and inter-ventions that lead to sustainable implementation effortswill be of critical importance [23]. Elucidating the waysin which influences interact to enhance or challenge
sustainability will ultimately facilitate an understanding
from a complex-systems perspective and may also lead
to the development of strategies to promote sustainabil-ity in contexts and circumstances in which certain fac-tors are absent or less than optimal. For example,whether specific influences (e.g., leadership, culture) orprocesses can serve as protective or compensatory fac-tors in the absence of other elements (e.g., funding)
remains to be determined. Findings in this area can ulti-
mately lead to the development and improvement ofstrategies that promote the continuation of effectiveprograms and interventions.
Limitations
Some limitations to our review are important to acknowl-edge. In this project, we reviewed studies that identified
specific programs or interventions and investigated either
the extent to which those interventions and/or thedesired benefits were sustained or factors that influencedtheir sustainability. Info rmation generated from this
review can inform researchers about what has not yetbeen sufficiently explored and stakeholders about whatmay be important to consider w hen monitoring specific
programs or interventions that they have chosen to
implement. We did not specifically seek studies that
examined the adaptive capa city of systems, and we did
not take an ecological or developmental perspective inour review [19,97]. Such perspectives are valuable forfuture research and much can be learned by broadeningthe research questions beyond whether or not an inter-vention continued as origin ally implemented. However,
from a number of stakeholder perspectives, and given thesubstantial resources that have been devoted to imple-menting effective practices to date, there is also value tounderstanding the findings and limitations of the existingbody of research that has investigated whether and howinterventions and their health benefits have been sus-tained [16]. Thus, in this review, the ways in which we
presented our findings, conclusions that we drew, and
recommendations that we made were shaped by an effortto understand more about sustainment or discontinua-tion from this perspective and by the state of the existingliterature that has addressed sustainability in this manner.
Although we attempted to identify studies from a vari-
ety of fields using a number of search strategies, the dif-fuse nature of the literature on sustainability and the
variety of terms used may have limited our ability to
complete an exhaustive revi ew. Additionally, we sought
to look broadly across literatures from a number offields, but the applicability of some findings to any onei n n o v a t i o nm a yb es o m e w h a tl i m i t e d .W es o u g h tt olearn what the available findings could tell us about theextent to which specific practices or programs havebecome rooted and sustained within organizations and
communities, in order to conduct the most comprehen-
sive review possible. By “casting a broad net ”in terms of
the fields and methodologies that were represented inour review, we intended to identify methods, strategies,constructs, and findings that may not have been consid-ered within some individual fields. In these studies, theextent to which a program or intervention had contin-ued was generally assessed at a single point in time, lim-
iting conclusions that could be drawn about changes
over time. Thus, we chose to present ranges of sustain-ment that had been found within particular fields in lieuof a definitive statement about whether or to what
extent sustainment could be expected for particularinnovations.
Conclusions
In the early efforts to study the sustainability of specificprograms and interventions that we reviewed, we haveidentified a body of literature that is fragmented andunderdeveloped. In addition to previously noted chal-lenges, limited funding for monitoring programs afterinitial implementation, challenges to observation in real-time, and the lack of validated measures have compli-cated the study of sustainability, and much of what is
known to date has been determined through post hoc
research [4]. The current paper contributes to the litera-
ture by reviewing the research on sustainability that hasbeen conducted to date. Our goals in this review wereto examine the ways that researchers have approachedthis challenging topic thus far and to contribute to thedevelopment of an agenda for future, high-qualityresearch.Wiltsey Stirman et al .Implementation Science 2012, 7:17
http://www.implementationscience.com/content/7/1/17Page 13 of 19
Each of our recommendations to advance what is
known about sustainability will require time, resources,
and funding, all of which have been relatively limitedacross the fields that we reviewed. With prospective stu-dies of implementation efforts underway, investigatorscould make a substantial contribution to the field by
planning follow-up studies that assess the degree to
which the programs or practices are maintained and thenature and implications of changes that are made onceimplemented. Furthermor e, researchers and policy
makers should be encouraged to consider the questionof sustainability when devel oping implementation pro-
grams and research. Appropriate planning, assessment,and allocation of funds wou ld result in much better
understanding of why and how some interventions andprograms last and others do not. In an era of increasingbudget pressures and greater scrutiny of new invest-ments, nothing could be more desirable as a practicalmatter as well.
Additional material
Additional file 1: Articles Included in the Review [37,54,98-220].
Acknowledgements
We wish to thank the implementation researchers who suggested additional
studies for inclusion in our review, our reviewers, and Dr. Sarah Beehler fortheir comments on previous drafts.The preparation of this article was supported through funding from theNational Institute of Mental Health (R00 MH 01800 [Dr. Stirman] and T32 MH019836 [Dr. Castro; PI: Keane]); through the Implementation ResearchInstitute (IRI), at the George Warren Brown School of Social Work,
Washington University in St. Louis, which is funded through an award from
the National Institute of Mental Health (R25 MH080916-01A2) and theDepartment of Veterans Affairs, Health Services Research & DevelopmentService, Quality Enhancement Research Initiative (QUERI). The content issolely the responsibility of the authors and does not necessarily representthe official views of the National Institute of Mental Health, the National
Institutes of Health, or the Department of Veterans Affairs.
Dr. Castro is now affiliated with the VA Maryland Healthcare System
Author details
1Women ’s Health Sciences Division, National Center for PTSD, Boston, MA,
USA.2VA Boston Healthcare System, Boston, MA, USA.3Department of
Psychiatry, Boston University, Boston, MA, USA.4Department of Healthcare
Management, The Wharton School of the University of Pennsylvania,
Philadelphia, PA, USA.5VA Center for Organization, Leadership, and
Management Research, Boston, MA, USA.6Department of Health Policy and
Management, Boston University School of Public Health, Boston, MA, USA.
Authors ’contributions
SWS conceptualized the study, contributed to the data collection and
coding, and was the predominant contributor to this article. NC and ACassisted with the coding of articles and compilation and interpretation ofresults. MC, JK, and FC made significant contributions to the conceptualframework and the interpretation of results. All authors read and modifieddrafts and approved the final manuscript.
Competing interests
The authors declare that they have no competing interests.Received: 22 April 2011 Accepted: 14 March 2012Published: 14 March 2012
References
1. McHugh RK, Barlow DH: The dissemination and implementation of
evidence-based psychological treatments. A review of current efforts.
American Psychology 2010, 65(2) :73-84.
2. Proctor EK, et al:Implementation research in mental health services: An
emerging science with conceptual, methodological, and trainingchallenges. Adm Policy Ment Health Ment Health Serv Res 2009, 36(1) :24-35.
3. Greenhalgh T, et al:How to Spread Good Ideas: A systematic review of the
literature on diffusion, dissemination, and sustainability of innovations inhealth service delivery and organization, in Report for the National Co-ordinating Centre for NHS Service Delivery and Organisation R & D (NCCSDO)London: University College; 2004, 362.
4. Bowman C, et al:Measuring persistence of implementation: QUERI Series.
Implement Sci 2008, 3(1):21.
5. Shediac-Rizkallah MC, Bone LR: Planning for the sustainability of
community-based health programs: conceptual frameworks and futuredirections for research, practice and policy. Health Educ Res 1998,
13(1) :87-108.
6. Massatti RR, et al:The de-adoption of innovative mental health practices
(IMHP): why organizations choose not to sustain an IMHP. Adm Policy
Ment Health 2008, 35(1-2) :50-65.
7. Scheirer MA: The life cycle of an innovation: adoption versus
discontinuation of the fluoride mouth rinse program in schools. J Health
Soc Behav 1990, 31(2) :203-215.
8. Seffrin B, Panzano PC, Roth D: What Gets Noticed: How Barrier and
Facilitator Perceptions Relate to the Adoption and Implementation ofInnovative Mental Health Practices. Community Ment Health J 2008,
44(6) :475.
9. Rogers EM: Diffusion of Innovations New York: The Free Press, A Division of
Simon & Schuster, Inc; 2003, 1-551.
10. McHugo GJ, et al:Fidelity to assertive community treatment and client
outcomes in the New Hampshire dual disorders study. Psychiatr Serv
1999, 50(6) :818.
11. McGlynn EA, et al:The quality of health care delivered to adults in the
United States. N Engl J Med 2003, 348:2635-2645.
12. Jerrell JM, Ridgely MS: The relative impact of treatment program []
robustness ’and [] dosage ’on client outcomes. Eval Program Plann 1999,
22(3) :323-330.
13. Maher L, Gustafson DA: Sustainability Model and Guide: Evans;. 2007.
14. von Krogh G, Roos J: A perspective on knowledge, competence and
strategy. Pers Rev 1995, 24(3) :56.
15.
Aarons GA, Palinkas LA: Implementation of evidence, evidence-based
practice in child welfare: service provider perspective. Adm Policy Ment
Health Serv Res 2007, 34:411-419.
16. Scheirer MA, Dearing JW: An agenda for research on the sustainability of
public health programs. Am J Public Health 2011, 101(11) :2059-2067.
17. Racine DP: Reliable effectiveness: a theory on sustaining and replicating
worthwhile innovations. Adm Policy Ment Health 2006, 33(3) :356-387.
18. Stirman SW, et al:Sustainability: A systematic review of methods and
conceptualizations. in Fourth Annual NIH Conference on the Science ofDissemination and Implementation Bethesda, MD; 2011.
19. Gruen RL, et al:Sustainability science: an integrated approach for health-
programme planning. Lancet 2008, 372(9649) :1579.
20. Aarons G, Hurlburt M, Horwitz S: Advancing a Conceptual Model of
Evidence-Based Practice Implementation in Public Service Sectors. Adm
Policy Ment Health Ment Health Serv Res 2011, 38(1) :4-23.
21. Kirsh SR, Lawrence RH, Aron DC: Tailoring an intervention to the context
and system redesign related to the intervention: A case study ofimplementing shared medical appointments for diabetes. Implement Sci
2008, 3(1):34.
22. Scheirer MA, Hartling G, Hagerman D: Defining sustainability outcomes of
health programs: Illustrations from an on-line survey. Eval Program Plann
2008, 31(4) :335-346.
23. Scheirer MA, J Dearing: An Agenda for Research on the Sustainability of
Public Health Programs American Journal of Public Health; 2011.
24. Glasgow RE, Vogt TM, Boles SM: Evaluating the public health impact of
health promotion interventions: the RE-AIM framework. Am J Public
Health 1999, 89:1322-1327.Wiltsey Stirman et al .Implementation Science 2012, 7:17
http://www.implementationscience.com/content/7/1/17Page 14 of 19
25. Scheirer MA: Is sustainability possible? A review and commentary on
empirical studies of program sustainability. Am J Eval 2005, 23:320-347.
26. Kimberly JR, Evanisko MJ: Organizational innovation: The influence of
individual, organizational, and contextual factors on hospital adoption of
technological and administrative innovations. Acad Manage J 1981,
24(4) :689-713.
27. Kimberly JR, Starbuck WH: In Managerial Innovation, in Handbook of
Organizational Design. Edited by: Nystrom PC. New York: Oxford University
Press; 1981:84-104.
28. Durlak J, DuPre E: Implementation Matters: A Review of Research on the
Influence of Implementation on Program Outcomes and the Factors
Affecting Implementation. Am J Community Psychol 2008, 41:327-350.
29. Swerissen H, Crisp BR: The sustainability of health promotion
interventions for different levels of social organization. Health Promot Int
2004, 19(1) :123-130.
30. Pettigrew A: On studying organizational cultures. Adm Sci Q 1979,
24:570-581.
31. Fixsen D, et al:Implementation Research: A Synthesis of the Literature 2005.
32. Greenhalgh T, et al:Diffusion of innovations in service organizations:
Systematic review and recommendations. Milbank Q 2004, 82(4) :581-629.
33. Moher D, et al:Preferred reporting items for systematic reviews and
meta-analyses: the PRISMA statement. PLoS Med 2009, 6(7):e1000097.
34. Marty D, et al:Factors influencing consumer outcome monitoring in
implementation of evidence-based practices: results from the NationalEBP Implementation Project. Adm Policy Ment Health Ment Health Serv Res
2008, 35(3) :204.
35. Glisson C, et al:Assessing the organizational social context (OSC) of
mental health services: Implications for research and practice. Adm Policy
Ment Health Ment Health Serv Res 2008, 35(1-2) :98.
36. Feldstein AC, Glasgow RE, Smith DH: A practical, robust implementation
and sustainability model (PRISM) for integrating research findings into
practice. Jt Comm J Qual Patient Saf 2008, 34(4) :228-243.
37. Glaser EM: Durability of Innovations in Human Service Organizations. Sci
Commun 1981, 3(2):167-185.
38. Goodman RM, et al:Development of level of institutionalization scales
for 
health promotion programs. Health Educ Q 1993, 20:161-178.
39. Johnson K, et al:Building capacity and sustainable prevention
innovations: a sustainability planning model. Eval Program Plann 2004,
27:135-149.
40. Mancini JA, Marek LI: Sustaining community-based programs for families:
Conceptualization and measurement. Fam Relat 2004, 53(4) :339-347.
41. Pluye P, et al:Program sustainability: focus on organizational routines.
Health Promot Int 2004, 19(4) :489-500.
42. Sarriot EG, et al:A methodological approach and framework for
sustainability assessment in NGO-implemented primary health careprograms. Int J Health Plann Manage 2004, 19(1) :23-41.
43. Silimperi DR, et al:A framework for institutionalizing quality assurance.
Int J Qual Health Care 2002, 14(suppl 1):67-073.
44. Yin RK, Quick SK, Bateman PM, Marks EL: Changing Urban Bureaucracies:
How New Practices Become Routinized Santa Monica: Rand Corp; 1978,
1-155.
45. Landis JR, Koch GG: The measurement of observer agreement for
categorical data. Biometrics 1977, 33(1) :159-174.
46. Bossert TJ: Can they get along without us? Sustainability of donor-
supported health projects in Central America and Africa. Soc Sci Med
1990, 30(9) :1015-1023.
47. Bartholomew L, et al:Planning Health Promotion Programs: An Intervention
Mapping Approach San Francisco: Jossey-Bass; 2006.
48. Botvin GJ, et al:Preventing adolescent drug abuse through a multimodal
cognitive-behavioral approach: results of a 3-year study. J Consult Clin
Psychol 1990, 58(4) :437.
49. Rohrbach LA, Graham JW, Hansen WB: Diffusion of a school-based
substance abuse prevention program: predictors of program
implementation. Prev Med 1993, 22(2) :237-260.
50. Claquin P: Sustainability of EPI: Utopia or Sine Qua Non Condition of Child
Survival, in Resources for Child Health Project Arlington; REACH; 1989.
51. Rabin B, et al:Individual and setting level predictors of the
implementation of a skin cancer prevention program: a multilevel
analysis. Implement Sci 2010, 5:40-53.
52. 
Stetler CB, et al:Improving quality of care through routine, successful
implementation of evidence-based practice at the bedside: anorganizational case study protocol using the Pettigrew and Whippmodel of strategic change. Implement Sci 2007, 2:3-15.
53. Sibthorpe BM, Glasgow NJ, Wells RW: Emergent themes in tlie
sustainability of primary health care innovation. Med J Aust 2005,
183(Suppl 10) :S77-S80.
54. Lafond AK: Improving the quality of investment in health: lessons on
sustainability. Health Policy Plan 1995, 10:63-76.
55. Ovretveit J: Making temporary quality improvement continuous Stockholm:
Swedish Association of County Councils; 2003.
56. Winett RA, King AC, Altman DG: Health Psychology and Public Health: An
Integrative Approach Pergamon Press; 1989.
57. Pluye P, Potvin L, Denis J-L: Making public health programs last:
conceptualizing sustainability. Eval Program Plann 2004, 27(2) :121-133.
58. Goodman RM, Steckler AB: A model for the institutionalization of health
promotion programs. Fam Community Health 1987, 11:63-78.
59. Schoenwald SK, et al:Toward the Effective and Efficient Measurement of
Implementation Fidelity Administration and Policy in Mental Health and
Mental Health Services Research; 2011, 38.
60. Dusenbury L, et al:A review of research on fidelity of implementation:
implications for drug abuse prevention in school settings. Health Educ
Res2003, 18(2) :237-256.
61. Henggeler SW, et al:Multisystemic therapy with violent and chronic
juvenile offenders and their families: The role of treatment fidelity insuccessful dissemination. J Consult Clin Psychol 1997, 65(5) :821-833.
62. Woolf SH, Johnson RE: Inattention to the fidelity of health care delivery is
costing lives. Am J Public Health 2007, 97(10) :1732-1733, author reply 1733.
63. Nilsen P, et al:Towards improved understanding of injury prevention
program sustainability. Saf Sci 2005, 43(10) :815.
64. Damschroder LJ, et al:Fostering implementation of health services
research findings into practice: a consolidated framework for advancing
implementation science. Implement Sci 2009, 4:50.
65. Hemmelgarn AL, Glisson C, James LR: Organizational
 culture and climate:
implications for services and interventions research. Clin Psychol Sci Pract
2006, 13(1) :73.
66. VanDeusen Lukas C, et al:Strengthening organizations to implement
evidence-based clinical practice. Health Care Manage Rev 2010,
35(3) :235-245.
67. Aarons G, Hurlburt M, Horwitz S: Advancing a Conceptual Model of Evidence-
Based Practice Implementation in Public Service Sectors Administration and
Policy in Mental Health and Mental Health Services Research;.
68. Schein E: Organizational Culture and Leadership San Francisco: Jossey-Bass;
2004.
69. Clarke GN, Kazdin AE: Improving the transition from basic efficacy
research to effectiveness studies: Methodological issues and procedures.
Methodological issues & strategies in clinical research (3rd ed.). 3 edition.
Washington: American Psychological Association; 2003, 569.
70. Blasinsky M, Goldman HH, Unutzer J: Project IMPACT: a report on barriers
and facilitators to sustainability. Adm Policy Ment Health Ment Health Serv
Res2006, 33(6) :718-729.
71. Woolf SH, Johnson RE: The break-even point: when medical advances are
less important than improving the fidelity with which they aredelivered. Ann Fam Med 2005, 3(6):545-552.
72. Kimberly J, Rye CB: In The Morphology of Innovation, in Handbook of Culture,
Organization, and Work. Edited by: Bhagat RS, Steers RM. London:
Cambridge University Press; 2009:197-218.
73. Kimberly JR, de Pouvourville G, D ’Aunno T: The Globalization of Managerial
Innovation in Health Care London: Cambridge University Press; 2008.
74. Waltz J, et al:Testing the integrity of a psychotherapy protocol:
assessment of adherence and competence. J Consult Clin Psychol 1993,
61(4) :620-630.
75. Jana S, et al:The Sonagachi Project: a sustainable community
intervention program. AIDS Educ Prev 2004, 16(5) :405-414.
76. Plochg T, et al:Collaborating while competing? The sustainability of
community-based integrated care initiatives through a healthpartnership. BMC Health Serv Res 2006, 20:6-37.
77. Blakely CH, et al:The fidelity-adaptation debate: implications for the
implementation of public sector social programs. Am J Community
Psychol 1987, 15(3) :253-268.
78. Langley GJ, et al:The improvement guide: a practical approach to enhancing
organizational performance New York: Jossey-Bass; 2009.Wiltsey Stirman et al .Implementation Science 2012, 7:17
http://www.implementationscience.com/content/7/1/17Page 15 of 19
79. Spencer BA: Models of organization and total quality management: a
comparison and critical evaluation. Academy of Management Review 1994,
19(3) :446-471.
80. Weiss CH: Have we learned anything new about the use of evaluation?
Am J Eval 1998, 19(1) :21.
81. Crossan MM, Lane HW, White RE: An organizational learning framework:
From intuition to institution 1999, 24(3) :522-537, Academy of Management
Review.
82. March JG: In Exploration and exploitation in organizational learning. Volume
2.Organization Science; 1991:(1):71-87.
83. Berman P: The study of macro and micro implementation of social policy
Santa Monica: Rand Corporation; 1978.
84. Hill LG, Maucione K, Hood BK: A focused approach to assessing program
fidelity. Prev Sci 2007, 8:25-34.
85. Lundgren L, et al:Modifications of evidence-based practices in
community-based addiction treatment organizations: A qualitative
research study addictive behaviors. Addict Behav 2011, 36(6) :630-635.
86. Levitt JT, et al:The flexible application of a manualized treatment for
PTSD symptoms and functional impairment related to the 9/11 WorldTrade Center attack. Behav Res Ther 2007, 45(7) :1419.
87. SW S, CF : In Moving From the Laboratory to the Real World: Implementation
Science and Effectiveness in Practice Settings, in Toward an IntegratedApproach to Trauma Focused Therapy: Placing Evidence-Based Interventions inan Expanded Psychological Context. Edited by: R McMackin, et al. American
Psychological Association: Washington, D.C; .
88. Perepletchikova F, Treat TA, Kazdin AE: Treatment integrity in
psychotherapy research: Analysis of the studies and examination of theassociated factors. J Consult Clin Psychol 2007, 75(6) :829-841.
89. Davies B, Tremblay D, Edwards N: In Sustaining evidence-based practice
systems and measuring the impacts, in Evaluating the Impact of
Implementing Evidence-Based Practice. Edited by: Bick D, Ingram ID. Oxford:
Wiley Blackwell; 2010:.
90. Tyre M, Orlikowski W: Windows of opportunity: temporal patterns in
technical adaptation in organizations. Organ Sci 1994, 5(1):98-105.
91. Charns MP, et al:Multilevel Interventions: Measurement and Measures. J Natl
Cancer Inst .
92. Glanz K, Bishop DB: The role of behavioral science theory in
development and implementation of public health interventions. Annu
Rev Public Health 2010, 31:399-418.
93. Edward JR Jr: Testing ecological models: the meaning of validation. Ecol
Model 1996, 90(3) :229-244.
94. Steckler AB, Goodman RM, McLeory KR, Davis S, Koch G: Measuring the
diffusion of innovative health promotion programs. Am J Health Promot
1992, 6(3):214-224.
95.
Barab SA, Redman BK, Froman RD: Measurement characteristics of the
levels of institutionalization scales: examining reliability and validity. J
Nurs Meas 1998, 6:19-33.
96. Ruch-Ross H, et al:Evaluation of community-based health projects: the
healthy tomorrows experience. Pediatrics 2008, 122(3) :e564-e572.
97. Patton MQ: Developmental Evaluation: Applying Complexity Concepts to
Enhance Innovation and Use New York: The Guilford Press; 2010.
98. Abraham AJ, Knudsen HK, Roman PM: A longitudinal examination of
alcohol pharmacotherapy adoption in substance use disorder treatment
programs: patterns of sustainability and discontinuation. J Stud Alcohol
Drugs 2011, 72(4) :669-677.
99. Ahluwalia IB, Robinson D, Vallely L, Gieseker KE, Kabakama A: Sustainability
of community-capacity to promote safer motherhood in northwesternTanzania: what remains? Glob Health Promot 2010, 17(1) :39-49.
100. Aitaoto N, Tsark J, Braun KL: Sustainability of the pacific diabetes today
coalitions. Prev Chronic Dis 2009, 6(4):A130-A138.
101. Amazigo U, Okeibunor J, Matovu V, Zouré H, Bump J, Seketeli A:
Performance of predictors: evaluating sustainability in community-directed treatment projects of the African programme for onchocerciasis
control. Soc Sci Med 2007, 64(10) :2070-2082.
102. August GJ, Bloomquist ML, Lee SS, Realmuto GM, Hektner JM: Can
evidence-based prevention programs be sustained in community
practice settings? The early risers ’advanced-stage effectiveness trial.
Prev Sci 2006, 7(2):151-165.
103. Austin G, Bell T, Caperchione C, Mummery WK: Translating research to
practice: using the RE-AIM framework to examine an evidence-basedphysical activity intervention in primary school settings. Health Promot
Pract 2011, 12(6) :932-941.
104. Babl FE, Krieser D, Belousoff J, Theophilos T: Evaluation of a paediatric
procedural sedation training and credentialing programme:sustainability of change. Emerg Med J 2010, 27(8) :577-581.
105. Baer JS, Ball SA, Campbell BK, Miele GM, Schoener EP, Tracy K: Training and
fidelity monitoring of behavioral interventions in multi-site addictionsresearch. Drug Alcohol Depend 2007, 87(2) :107-118.
106. Bailie RS, Robinson G, Kondalsamy-Chennakesavan SN, Halpin S, Wang Z:
Investigating the sustainability of outcomes in a chronic diseasetreatment programme. Soc Sci Med 2006, 63(6) :1661-1670.
107. Barnett LM, Van Beurden E, Eakin EG, Beard J, Dietrich U, Newman B:
Program sustainability of a community-based intervention to preventfalls among older Australians. Health Promot Int 2004, 19(3) :281-288.
108. Baum F, Jolley G, Hicks R, Saint K, Parker S: What makes for sustainable
Healthy Cities initiatives?-a review of the evidence from Noarlunga,Australia
after 18 years. Health Promot Int 2006, 21(4) :259-265.
109. Beery WL, Senter S, Cheadle A, Greenwald HP, Pearson D, Brousseau R,
Nelson GD: Evaluating the legacy of community health initiatives: a
conceptual framework and example from the California WellnessFoundation ’s health improvement initiative. Am J Evaluation 2005,
26:150-165.
110. Bere E, Veierod MB, Bjelland M, Klepp KI: Free school fruit-sustained effect
1 year later. Health Educ Res 2006, 21(2) :268-275.
111. Bisset S, Potvin L: Expanding our conceptualization of program
implementation: lessons from the genealogy of a school-based nutritionprogram. Health Educ Res 2006, 22(5) :737-746.
112. Blasinsky M, Goldman HH, Unutzer J: Project IMPACT: a report on barriers
and facilitators to sustainability. Adm Policy Ment Health 2006,
33(6) :718-729.
113. Bowman C, Sobo E, Asch S, Gifford A: The H. I. V. Hepatitis Quality
Enhancement Research Initiative: Measuring persistence ofimplementation: QUERI series. Implement Sci 2008, 3(1):21.
114. Bratcht NF, Finnegan JR, Rissel C, Weisbrod R, Gleason J, Corbett J,
Mortenson S: Community ownership and program coninuation following
a health demonstration program. Health Educ Res 1994, 9:243-255.
115. Brand C, Landgren F, Hutchinson A, Jones C, MacGregor L, Campbell D:
Clinical practice guidelines: barriers to durability after effective earlyimplementation. Intern Med J 2005, 35(3) :162-169.
116. Bunik M, Federico MJ, Beaty B, Rannie M, Olin JT, Kempe A: Quality
improvement for asthma care within a hospital-based teaching clinic.Acad Pediatr 2011, 11(1) :58-65.
117. Cherry RA, West CE, Hamilton MC, Rafferty CM, Hollenbeak CS, Caputo GM:
Reduction of central venous catheter associated blood stream infectionsfollowing implementation of a resident oversight and credentialingpolicy. Patient Saf Surg 2011, 5:15.
118. DeWein M, Miller L: The effects of a classroom-based intervention on
aggression-related injuries. Child and Youth Care Forum 2009,
38(4) :201-218.
119. Dückers MLA, Wagner C, Vos L, Groenewegen PP: Understanding
organisational development, sustainability, and diffusion of innovationswithin hospitals participating in a multilevel quality collaborative.Implement Sci 2011, 6(1):18.
120. Ebert-May D, Derting TL, Hodder J, Momsen JL, Long TM, Jardeleza SE:
What we say is not what we do: effective evaluation of facultyprofessional development programs. Bioscience 2011, 61(7) :550-558.
121. Edvarsson K, Garvare R, Ivarsson A, Eurenius E, Morgen I, Nystrom M:
Sustainable practice change: professionals ’experiences with a
multisectoral child health promotion programme in Sweden. BMC Health
Serv Res 2011, 11:61.
122.
Eliason RN: Towards sustainability in village health care in rural
Cameroon. Health Promot Int 1999, 14:301-306.
123. Ellingson K, Muder RR, Jain R, Kleinbaum D, Feng PJ, Cunningham C,
Squier C, Lloyd J, Edwards J, Gebski V, Jernigan J: Sustained reduction in
the clinical incidence of methicillin-resistant Staphylococcus aureu
colonization or infection associated with a multifaceted infection controlintervention. Infect Control Hosp Epidemiol 2011, 32(1) :1-8.
124. Epstein JN, Langberg JM, Lichtenstein PK, Kolb RC, Stark LJ: Sustained
improvement in pediatricians ’ADHD practice behaviors in the context
of a community-based quality improvement initiative. Child Health Care
2010, 39(4) :296-311.Wiltsey Stirman et al .Implementation Science 2012, 7:17
http://www.implementationscience.com/content/7/1/17Page 16 of 19
125. Escoffery C, Glanz K, Hall D, Elliott T: A multi-method process evaluation
for a skin cancer prevention diffusion trial. Eval Health Prof 2009,
32(2) :184-203.
126. Evashwick C, Ory M: Organizational characteristics of successful
innovative health care programs sustained over time. Fam Community
Health 2003, 26(3) :177-193.
127. Feinberg ME, Bontempo DE, Greenberg MT: Predictors and level of
sustainability of community prevention coalitions. Am J Prev Med 2008,
34(6) :495-501.
128. Fonck K, Claeys P, Bashir F, Bwayo J, Fransen L, Temmerman M: Syphilis
control during pregnancy: effectiveness and sustainability of a
decentralized program. Am J Public Health 2001, 91(5) :705-707.
129. Glaser EM, Backer TE: Durability of innovations: how goal attainment
scaling programs fare over time. Community Ment Health J 1980,
16(2) :130-143.
130. Glisson C, Schoenwald SK, Kelleher K, Landsverk J, Hoagwood KE,
Mayberg S, Green P: Therapist turnover and new program sustainability
in mental health clinics as a function of organizational culture, climate,
and service structure. Adm Policy Ment Health 2008, 35(1-2) :124-133.
131. Godley SH, Garner BR, Smith JE, Meyers RJ, Godley MD: A large scale
dissemination and implementation model for evidence based treatmentand continuing care. Clin Psychol Sci Pract 2011, 18(1) :67-83.
132. Goetz MB, Hoang T, Henry SR, Knapp H, Anaya HD, Gifford AL, Asch SM:
Evaluation of the sustainability of an intervention to increase HIV
testing. J Gen Intern Med 2009, 24(12) :1275-1280.
133. Goodson P, Murphy Smith M, Evans A, Meyer B, Gottlieb NH: Maintaining
prevention in practice: survival of PPIP in primary care settings. Am J
Prev Med 2001, 20(3) :184-189.
134. Greenwood CR, Tapia Y, Abbott M, Walton C: A building-based case study
of evidence-based literacy practices: implementation, reading behavior,and growth in reading fluency, K-4. J Spec Educ 2003, 37(2) :95-110.
135. Gruen RL, Elliott JH, Nolan ML, Lawton PD, Parkhill A, McLaren CJ, Lavis JN:
Sustainability science: an integrated approach for health-programme
planning. Lancet 2008, 372(9649) :1579-1589.
136. Gurtler RE, Kitron U, Cecere MC, Segura EL, Cohen JE: Sustainable vector
control and management of Chagas disease in the Gran Chaco,Argentina. Proc Natl Acad Sci USA 2007, 104(41) :16194-16199.
137. Harris DL, Henry RC, Bland CJ, Starnaman SM, Voytek KL: Lessons learned
from implementing multidisciplinary health professions educationalmodels in community settings. J Interprof Care 2003, 17(1) :7-20.
138. Helfrich CD, Damschroder LJ, Hagedorn HJ, Daggett GS, Sahay A, Ritchie M,
Damush T, Guihan M, Ullrich PM, Stetler CB: A critical synthesis of
literature on the promoting action on research implementation in
health services (PARIHS) framework. Implement Sci 2010, 5:82.
139.
Henggeler SW, Sheidow AJ, Cunningham PB, Donohue BC, Ford JD:
Promoting the implementation of an evidence-based intervention for
adolescent marijuana abuse in community settings: testing the use ofintensive quality assurance. J Clin Child Adolesc Psychol 2008,
37(3) :682-689.
140. Higuchi KS, Davies BL, Edwards N, Ploeg J, Virani T: Implementation of
clinical guidelines for adults with asthma and diabetes: a three-yearfollow-up evaluation of nursing care. J Clin Nurs 2011, 20(9-10) :1329-1338.
141. Hii JL, Chee KC, Vun YS, Awang J, Chin KH, Kan SK: Sustainability of a
successful malaria surveillance and treatment program in a Rungguscommunity in Sabah, east Malaysia. Southeast Asian J Trop Med Public
Health 1996, 27(3) :512-521.
142. Hoelscher DM, Feldman HA, Johnson CC, Lytle LA, Osganian SK, Parcel GS,
Kelder SH, Stone EJ, Nader PR: School-based health education programs
can be maintained over time: results from the CATCH Institutionalizationstudy. Prev Med 2004, 38(5) :594-606.
143. Hoffman KA, Ford II, James H, Choi D, Gustafson DH, McCarty D:
Replication and sustainability of improved access and retention withinthe Network for the Improvement of Addiction Treatment. Drug Alcohol
Depend 2008, 98(1-2) :63-69.
144. Hogg W, Baskerville N, Nykiforuk C, Mallen D: Improved preventive care in
family practices with outreach facilitation: understanding success andfailure. J Health Serv Res Policy 2002, 7(4):195-201.
145. Hoque BA, Juncker T, Sack RB, Ali M, Aziz KM: Sustainability of a water,
sanitation and hygiene education project in rural Bangladesh: a 5-year
follow-up. Bulletin WHO 1996, 74(4) :431-437.146. Jansen M, Harting J, Ebben N, Kroon B, Stappers J, VanEngelshoven E:
deVries, N: The concept of sustainability and the use of outcome
indicators: a case study to continue a successful health counsellingintervention. Fam Pract 2008, 25:i32-i37.
147. Johnson C, Fargo J, Kahle JB: The cumulative and residual impact of a
systemic reform program on teacher change and student learning ofscience. Sch Sci Math 2010, 110(3) :144-159.
148. Kalafat J, Ryerson DM: The implementation and institutionalization of a
school-based youth suicide prevention program. J Prim Prev 1999,
19(3) :157-175.
149. Kay BH, Tuyet Hanh TT, Le NH, Quy TM, Nam VS, Hang PV, Yen NT, Hill PS,
Vos T, Ryan PA: Sustainability and cost of a community-based strategy
against Aedes aegypti in northern and central Vietnam. AmJTrop Med Hyg
2010, 82(5) :822.
150. Kellie SM, Timmins A, Brown C: A statewide collaborative to reduce
methicillin-resistant Staphylococcus aureu bacteremias in New Mexico. Jt
Comm J Qual Patient Saf 2011, 37:154-162.
151. Kennedy MT, Fiss PC: Institutionalization, framing, and diffusion: the logic
of TQM adoption and implementation decisions among U.S. hospitals.Acad Manage J 2009, 52(5) :897-918.
152.
Klingner J, Vaughn S: Tejero Hughes M, Arguelles ME: Sustaining
research-based practices in reading: a 3-year follow-up. Rem Spec Ed
1999, 20(5) :263-275.
153. Knapp H, Anaya HD, Goetz MB: Attributes of an independently self-
sustaining implementation: nurse-administered HIV rapid testing in VAprimary care. Qual Manag Health Care 2010, 19(4) :292-297.
154. Knippenberg R, Soucat A, Oyegbite K, Sene M, Bround D, Pangu K,
Hopwood I, Grandcourt R, Tinguiri KL, Fall I, Ammassari S, Alihonou E:Sustainability of primary health care including expanded program ofimmunizations in Bamako Initiative programs in West Africa: an
assessment of 5 years’ field experience in Benin and Guinea. Int J Health
Plann Manage 1997, 12:S9-S28.
155. Knudsen HK, Studts JL: Availability of nicotine replacement therapy in
substance use disorder treatment: longitudinal patterns of adoption,
sustainability, and discontinuation. Drug Alcohol Depend 2011, 118(2-
3):244-250.
156. Kolko DJ, Iselin A-MR, Gully KJ: Evaluation of the sustainability and clinical
outcome of Alternatives for Families: A Cognitive-Behavioral Therapy(AF-CBT) in a child protection center. Child Abuse Negl 2011,
35(2) :105-116.
157. LaPelle NR, Zapka J, Ockene JK: Sustainability of public health programs:
the example of tobacco treatment services in Massachusetts. Am J Public
Health 2006, 96:1363-1369.
158. Lee AJ, Bonson APV, Yarmirr D, O ’Dea K, Mathews JD: Sustainability of a
successful health and nutrition program in a remote Aboriginalcommunity. Med J Aust 1995, 162:632-635.
159. Lee PW, Dietrich AJ, Oxman TE, Williams JWJ, Barry SL: Sustainable impact
of a primary care depression intervention. J Am Board Fam Med 2007,
20(5) :427-433.
160. Lichtenstein E, Thompson B, Nettekoven L, Corbett K: Durability of tobacco
control activities in 11 North American communities: life after thecommunity intervention trial for smoking cessation (COMMIT). Health
Educ Res 1996, 11(4) :527-534.
161. Lieber J, Butera G, Hanson M, Palmer S, Horn E, Czaja C: Sustainability of a
preschool curriculum: what encourages continued use among teachers?NHSA Dialog 2010, 13(4) :225-242.
162. Lodl K, Stevens G: Coalition sustainability: long-term successes & lessons
learned. J Ext 2002, 40(1) :1-8.
163. Loman SL, Rodriguez BJ, Horner RH: Sustainability of a targeted
intervention package: first step to success in Oregon. J Emot Behav
Disord 2010, 18(3) :178-191.
164. Lyon AR, Stirman SW, Kerns SE, Bruns EJ: Developing the mental health
workforce: review and application of training approaches from multiple
disciplines. Adm Policy Ment Health 2011, 38(4) :238-253.
165.
Martin GW, Herie MA, Turner BJ, Cunningham JA: A social marketing
model for disseminating research-based treatments to addictions
treatment providers. Addiction 1998, 93(11) :1703-1715.
166. Massatti RR, Sweeney HA, Panzano PC, Roth D: The de-adoption of
innovative mental health practices (IMHP): why organizations choose
not to sustain an IMHP. Adm Policy Ment Health 2008, 35(1-2) :50-65.Wiltsey Stirman et al .Implementation Science 2012, 7:17
http://www.implementationscience.com/content/7/1/17Page 17 of 19
167. Maticka-Tyndale E, Wildish J, Gichuru M: Thirty-month quasi-experimental
evaluation follow-up of a national primary school HIV intervention in
Kenya. Sex Educ: Sex Soc Learn 2010, 10(2) :113-130.
168. Mayer J, Mooney B, Gundlapalli A, Harbarth S, Stoddard GJ, Rubin MA,
Eutropius L, Brinton B, Samore MH: Dissemination and sustainability of a
hospital-wide hand hygiene program emphasizing positivereinforcement. Infect Control Hosp Epidemiol 2011, 32(1) :59-66.
169. McCormick LK, Steckler AB, McLeroy KR: Diffusion of innovations in
schools: a study of adoption and implementation of school-basedtobacco prevention curricula. Am J Health Promot 1995, 9(3):210-219.
170. McDermott R, Tulip F, Schmidt B, Sinha A: Sustaining better diabetes care
in remote indigenous Australian communities. Qual Saf Health Care 2004,
13(4) :295-298.
171. McHugo GJ, Drake RE, Whitley R, Bond GR, Campbell K, Rapp CA,
Goldman HH, Lutz WJ, Finnerty MT: Fidelity outcomes in the national
implementing evidence-based practices project. Psychiatr Serv 2007,
58(10) :1279-1284.
172. Miller WR, Yahne CE, Moyers TB, Martinez J, Pirritano M: A randomized trial
of methods to help clinicians learn motivational interviewing. J Consult
Clin Psychol 2004, 72(6) :1050-1062.
173. Morgenstern LB, Bartholomew LK, Grotta JC, Staub L, King M, Chan W:
Sustained benefit of a community and professional intervention toincrease acute stroke therapy. Arch Intern Med 2003, 163(18) :2198-2202.
174. Nease DE Jr, Nutting PA, Graham DG, Dickinson WP, Gallagher KM, Jeffcott-
Pera M: Sustainability of depression care improvements: success of a
practice change improvement collaborative. J Am Board Fam Med 2010,
23(5) :598-605.
175. Nilsen P, Timpka T, Nordenfelt L, Lindqvist K: Towards improved
understanding of injury prevention program sustainability. Saf Sci 2005,
43(10) :815.
176. O ’Loughlin J, Renaud L, Richard L, Gomez LS, Paradis G: Correlates of the
sustainability of community-based heart health promotion interventions.Prev Med 1998, 27(5) :702-712.
177. Osganian SK, Hoelscher DM, Zive M, Mitchell PD, Snyder P, Webber LS:
Maintenance of effects of the Eat Smart School Food Service Program:results from the CATCH-ON study. Health Educ Behav 2003, 30(4) :418-433.
178. Paine-Andrews A, Fisher JL, Campuzano MK, Fawcett SB, Berkley-Patton J:
Promoting sustainability of community health initiatives: an empiricalcase study. Health Promot Pract 2000, 1:248-258.
179. Perlstein PH, Kotagal UR, Schoettker PJ, HD , Farrell MK, Gerhardt WE,
Alfaro MP: Sustaining the implementation of an evidence-based
guideline for bronchiolitis. Arch Pediatr Adolesc Med 2000,
154(10) :1001-1007.
180. Plochg T, Delnoij DM, Hoogedoorn NP, Klazinga NS: Collaborating while
competing? The sustainability of community-based integrated careinitiatives through a health partnership. BMC Health Serv Res 2006,
20:6-37.
181.
Pronovost PJ, Goeschel CA, Colantuoni E, Watson S, Lubomski LH,
Berenholtz SM, Thompson DA, Sinopoli DJ, Cosgrove S, Sexton JB,Marsteller JA, Hyzy RC, Welsh R, Posa P, Schumacher K, Needham D:
Sustaining reductions in catheter related bloodstream infections in
Michigan intensive care units: observational study. BMJ 2010, 340:
c309-c313.
182. Rabin B, Nehl E, Elliott T, Deshpande A, Brownson R, Glanz K: Individual
and setting level predictors of the implementation of a skin cancerprevention program: a multilevel analysis. Implement Sci 2010, 5:40-53.
183. Rapoport A: Sustainability of teachers ’international experiences:
conditions for institutionalization of international program outcomes.Educ Res Int 2011, 2011 :1-9.
184. Rau R, Rumpeltin C, Hoop R, Pfeiffer H, Drees J, Paas B, Schmitz-Buhl G,
Geraedts M: Five years “Healthy Lower Rhine...Against Stroke":
implementation of a regional, intersectoral and sustainable public healthprogram. J Public Health 2010, 18(1) :29-34.
185. Rog D, Boback N, Barton-Villagrana H, Marrone-Bennett P, Cardwell J,
Hawdon J, Diaz J, Jenkins P, Kridler J, Reischl T: Sustaining collaboratives: a
cross-site analysis of the National Funding Collaborative on ViolencePrevention. Eval Program Plann 2004, 27(3) :249-261.
186. Rohrbach LA, Graham JW, Hansen WB: Diffusion of a school-based
substance abuse prevention program: predictors of program
implementation. Prev Med 1993, 22(2) :237-260.187. Rollins A, Salyers M, Tsai J, Lydick J: Staff turnover in statewide
implementation of ACT: relationship with ACT fidelity and other team
characteristics. Adm Policy Ment Health 2009, 37(5) :417-426.
188. Rosenberg A, Hartwig K, Merson M: Government-NGO collaboration and
sustainability of orphans and vulnerable children projects in southern
Africa. Eval Program Plann 2008, 31(1) :51-60.
189. Rubin FH, Neal K, Fenlon K, Hassan S, Inouye SK: Sustainability and
scalability of the hospital elder life program at a community hospital. J
Am Geriatr Soc 2011, 59(2) :359-365.
190. Ruch-Ross H, Keller D, Miller N, Bassewitz J, Melinkovich P: Evaluation of
community-based health projects: the healthy tomorrows experience.Pediatrics 2008, 122(3) :e564-e572.
191. Sadof MD, Boschert KA, Brandt SJ, Motyl AP: An analysis of predictors of
sustainability efforts at the Inner-City Asthma Intervention sites: after
the funding is gone. Ann Allergy Asthma Immunol 2006, 97(S1) :S31-S35.
192. Sanci L, Coffey C, Patton G, Bowes G: Sustainability of change with quality
general practitioner education in adolescent health: a 5-year follow-up.
Med Educ 2005, 39:557-560.
193. Sanci LA, Coffey CM, Veit FC, Carr-Gregg M, Patton GC, Day N, Bowes G:
Evaluation of the effectiveness of an educational intervention for
general practitioners in adolescent health care: randomised controlledtrial. BMJ 2000, 320(7229) :224-230.
194.
Scheirer MA: The life cycle of an innovation: adoption versus
discontinuation of the fluoride mouth rinse program in schools. J Health
Soc Behav 1990, 31(2) :203-215.
195. Scheirer MA, Hartling G, Hagerman D: Defining sustainability outcomes of
health programs: Illustrations from an on-line survey. Eval Program Plann
2008, 31(4) :335-346.
196. Schetzina KE, Dalton WT III, Pfortmiller DT, Robinson HF, Lowe EF, Stern HP:
The Winning With Wellness pilot project: rural Appalachian elementary
student physical activity and eating behaviors and program
implementation 4 years later. Fam Community Health 2011, 34(2) :154-162.
197. Schoenwald SK, Carter RE, Chapman JE, Sheidow AJ: Therapist adherence
and organizational effects on change in youth behavior problems oneyear after multisystemic therapy. Adm Policy Ment Health 2008,
35(5) :379-394.
198. Sebotsa MLD, Dannhauser A, Jooste PL, Joubert G: Assessment of the
sustainability of the iodine-deficiency disorders control program inLesotho. Food and Nutrition Bulletin 2007, 28(3) :337-347.
199. Simonsen B, Eber L, Black AC, Sugai G, Lewandowski H, Sims B, Myers D:
Illinois statewide positive behavioral interventions and supports:evolution and impact on student outcomes across years. J Posit Behav
Interv 2012, 14:5-16.
200. Stange KC, Goodwin MA, Zyzanski SJ, Dietrich AJ: Sustainability of a
practice-individualized preventive service delivery intervention. Am J Prev
Med 2003, 25(4) :296-300.
201. Steadman HJ, Cocozza JJ, Dennis DL, Lassiter MG, Randolph FL, Goldman H,
Blasinsky M: Successful program maintenance when federal
demonstration dollars stop: the ACCESS program for homeless mentallyill persons. Adm Policy Ment Health 2002, 29(6) :481-493.
202. Stetler CB, Ritchie JA, Rycroft-Malone J, Schultz AA, Charns MP:
Institutionalizing evidence-based practice: an organizational case studyusing a model of strategic change. Implement Sci 2009, 4:78.
203. Stevens B, Peikes D: When the funding stops: do grantees of the Local
Initiative Funding Partners Program sustain themselves? Eval Program
Plann 2006, 29(2) :153-161.
204. Stroul BA, Manteuffel BA: The sustainability of systems of care for
children ’s mental health: lessons learned. J Behav Health Serv Res 2007,
34(3) :237-259.
205. Swain K, Whitley R, McHugo GJ, Drake RE: The sustainability of evidence-
based practices in routine mental health agencies. Community Ment
Health J 2009, 46(2) :119-129.
206. Thompson B, Lichtenstein E, Corbett K, Nettekoven L, Feng Z: Durability of
tobacco control efforts in the 22 Community Intervention Trial forSmoking Cessation (COMMIT) communities 2 years after the end ofintervention. Health Educ Res 2000, 15(3) :353-366.
207. Thorsen AV, Lassen AD, Tetens I, Hels O, Mikkelsen BE: Long-term
sustainability
of a worksite canteen intervention of serving more fruit
and vegetables. Public Health Nutr 2010, 13(10) :1647-1652.Wiltsey Stirman et al .Implementation Science 2012, 7:17
http://www.implementationscience.com/content/7/1/17Page 18 of 19
208. Tibbits M, Bumbarger B, Kyler S, Perkins D: Sustaining evidence-based
interventions under real-world conditions: results from a large-scale
diffusion project. Prev Sci 2010, 11(3) :252-262.
209. Toledo Romani ME, Vanlerberghe V, Perez D, Lefevre P, Ceballos E,
Bandera D, Baly Gil A, Van der Stuyft P: Achieving sustainability of
community-based dengue control in Santiago de Cuba. Soc Sci Med
2007, 64(4) :976.
210. Ullrich S, McCutcheon H, Parker B: Reclaiming time for nursing practice in
nutritional care: outcomes of implementing Protected Mealtimes in aresidential aged care setting. J Clin Nurs 2010, 20(9-10) :1339-1348.
211. Visrutaratna S, Lindan CP, Sirhorachai A, Mandel JS: “Superstar ”and"model
brothel": developing and evaluating a condom promotion program forsex establishments in Chiang Mai, Thailand. AIDS 1995, 9(1):S69-S75.
212. Wallin L, Bostrom A, Wikblad K, Ewald U: Sustainability in changing clinical
practice promotes evidence-based nursing care. J Adv Nurs 2003,
41(5) :509-518.
213. Westrick SC, Breland ML: Sustainability of pharmacy-based innovations:
the case of in-house immunization services. J Am Pharm Assoc 2009,
49(4) :500-508.
214. Whitford DL, Roberts SH, Griffin S: Sustainability and effectiveness of
comprehensive diabetes care to a district population. Diabet Med 2004,
21(11) :1221-1228.
215. Woltmann EM, Whitley R, McHugo GJ, Brunette M, Torrey WC, Coots L,
Lynde D, Drake RE: The role of staff turnover in the implementation of
evidence-based practices in mental health care. Psychiatr Serv 2008,
59(7) :732-737.
216. Wong LC, Amega B, Barker R, Connors C, Dulla ME, Ninnal A, Cumaiyi MM,
Kolumboort L, Currie BJ: Factors supporting sustainability of a
community-based scabies control program. Australas J Dermatol 2002,
43(4) :274-277.
217. Wong ML, Chan KW, Koh D: A sustainable behavioral intervention to
increase condom use and reduce gonorrhea among sex workers inSingapore: 2-year follow-up. Prev Med 1998, 27:891-900.
218. Wright C, Catty J, Watt H, Burns T: A systematic review of home treatment
services: classification and sustainability. Soc Psychiatry Psychiatr Epidemiol
2004, 39(10) :789-796.
219. Wright DB: Care in the country: a historical case study of long-term
sustainability in 4 rural health centers. Am J Public Health 2009,
99(9) :1612-1618.
220. Xian Y, Pan W, Peterson ED, Heidenreich PA, Cannon CP, Hernandez AF,
Friedman B, Holloway RG, Fonarow GC: Are quality improvements
associated with the Get With the Guidelines-Coronary Artery Disease(GWTG-CAD) program sustained over time?: A longitudinal comparison
of GWTG-CAD hospitals versus non-GWTG-CAD hospitals. Am Heart J
2010, 159(2) :207-214.
doi:10.1186/1748-5908-7-17
Cite this article as: Wiltsey Stirman et al .:The sustainability of new
programs and innovations: a review of the empirical literature and
recommendations for future research. Implementation Science 2012 7:17.
Submit your next manuscript to BioMed Central
and take full advantage of: 
• Convenient online submission
• Thorough peer review
• No space constraints or color ﬁgure charges
• Immediate publication on acceptance
• Inclusion in PubMed, CAS, Scopus and Google Scholar
• Research which is freely available for redistribution
Submit your manuscript at 
www.biomedcentral.com/submitWiltsey Stirman et al .Implementation Science 2012, 7:17
http://www.implementationscience.com/content/7/1/17Page 19 of 19
