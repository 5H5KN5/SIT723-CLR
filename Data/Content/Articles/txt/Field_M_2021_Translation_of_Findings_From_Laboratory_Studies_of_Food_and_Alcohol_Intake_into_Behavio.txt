Translation of findings from laboratory studies of food and alcohol intake into behavior change interventions: The experimental medicine approach  Matt Field University of Sheffield  Paul Christiansen and Charlotte A. Hardman University of Liverpool  Ashleigh Haynes Cancer Council Victoria   Andrew Jones University of Liverpool  Allecia Reid University of Massachusetts Amherst  Eric Robinson University of Liverpool  Health Psychology, in press 21st September 2020, doi: 10.1037/hea0001022.   © 2020, American Psychological Association. This paper is not the copy of record and may not exactly replicate the final, authoritative version of the article. Please do not copy or cite without authors' permission. The final article will be available, upon publication, via its DOI: 10.1037/hea0001022   
	2	Author for correspondence: Matt Field, Department of Psychology, Cathedral Court, 1 Vicar Lane, University of Sheffield, Sheffield, S1 2LT, United Kingdom.  Email: matt.field@sheffield.ac.uk Telephone: +44 (0) 114 2226510  Author note Matt Field, Department of Psychology, University of Sheffield, Sheffield, United Kingdom; Paul Christiansen, Charlotte A. Hardman, Andrew Jones and Eric Robinson, Department of Psychological Sciences, University of Liverpool, Liverpool, United Kingdom; Ashleigh Haynes, Centre for Behavioural Research in Cancer, Cancer Council Victoria, Melbourne, Australia; Allecia Reid, Psychological and Brain Sciences, University of Massachusetts Amherst, Amherst, MA, USA.  Acknowledgments  We thank Richard Cooke for his helpful feedback on a draft of the manuscript.  Declaration of interest statement Preparation of this manuscript was not supported by any external funding. PC, CAH and ER have received research funding the American Beverage Association. ER has received research funding from Unilever. CAH has received speaker fees from the International Sweeteners Association. Those authors do not consider this funding as a conflict of interest. All other authors have no conflicts of interest to declare.  
	3	Abstract Objectives: Laboratory studies have contributed important information about the determinants of food and alcohol intake, and they have prompted the development of behavior change interventions that have been evaluated in randomized controlled trials conducted in the field. In this paper we apply a recent experimental medicine (EM) framework to this body of research. Methods: A conceptual review and focused discussion of the relevant literature is presented. Results: We illustrate how it is possible to translate findings from studies of food and alcohol intake in the laboratory into interventions that are effective for changing behavior in the real world. We go on to demonstrate how systematic failures can occur at different stages within the EM framework, and how these failures ultimately result in interventions that are ineffective for changing behavior. We also consider methodological issues that may constrain the external validity of findings from laboratory studies including demand effects, participant characteristics, and the timing and dose of behavioral interventions. Throughout, we make recommendations to improve the translation of findings from laboratory studies into behavior change interventions that are effective in the field. Conclusions: Consideration of the EM framework will help to ensure that promising candidate interventions for eating and drinking that are identified in laboratory studies can fulfill their translational promise.   Key words: behavior change, experimental medicine, laboratory.      
	4	 Obesity and excessive alcohol consumption make substantial contributions to morbidity and premature mortality (Bauer, Briss, Goodman, & Bowman, 2014). Many behavioral interventions have been developed to reduce intake of alcohol and unhealthy food, but their effect sizes tend to be small and changes in behavior are often short-lived. Furthermore, complex interventions contain multiple components, and it can be unclear which components are efficacious and which are ineffective or detrimental (Michie, West, Sheals, & Godinho, 2017; Peters, de Bruin, & Crutzen, 2015). One approach for addressing this need is the experimental medicine framework (Nielsen et al., 2018; Sheeran, Klein, & Rothman, 2017). This can involve testing the effects of component(s) of a potential intervention on food or alcohol intake in laboratory settings, as a precursor to evaluating the effect of that intervention on intake in real-world settings by conducting a randomized controlled trial (RCT).   In this paper we provide a critical conceptual overview of the contribution that laboratory research with healthy volunteers has made to the development and refinement of behavior change interventions to change diet and reduce alcohol consumption, with a focus on studies that measured the effects of candidate interventions on food and alcohol intake in the laboratory. We focus on food and alcohol intake because both are appetitive behaviors that contribute significantly to the burden of disease, and their determinants are studied in the laboratory using similar methodology. The paper is structured as follows. First, we provide an overview of the experimental medicine (EM) framework and illustrate how laboratory studies of the determinants of food and alcohol intake have identified novel candidates for behavior change interventions. Next, we discuss instances in which promising findings from laboratory studies of food and alcohol intake failed to deliver the behavior change interventions that they promised, and we explain these translational failures through the lens of the EM framework. Finally, we consider methodological issues that could constrain the external validity of findings from laboratory studies of food and alcohol intake. Throughout, we offer practical recommendations to overcome those obstacles and ensure that promising candidate interventions that are identified in the laboratory can fulfill their translational promise 
	5	Overview of the experimental medicine approach and its application to laboratory studies of food and alcohol intake Experimental medicine approaches such as the NIH Science of Behavior Change Common Fund Program (Nielsen et al., 2018) focus on the precise specification and modification of core mechanisms that underlie undesirable behaviors. One EM framework for the development of behavior change interventions (Sheeran et al., 2017); see Figure 1) identified four distinct paths that characterize EM: use of theory to identify a potentially modifiable psychological process or environmental feature (hereafter: ‘target construct’) that is associated with the problem behavior (path A); experimental manipulation of the target construct in order to investigate its causal influence on the problem behavior (path B); development, evaluation and refinement of manipulations (candidate interventions) that lead to robust changes in the target construct (path C); finally, randomized controlled trials (RCTs) that investigate whether a behavior change intervention that incorporates those manipulations leads to behavior change among people who would benefit from that intervention (such as people whose alcohol consumption is harmful to their health), and if behavior change is mediated by changes in the target construct (path D). According to (Sheeran et al., 2017), this EM approach underpins innovative approaches to intervention development and testing, such as the multiphase optimization strategy (MOST; (Collins, Murphy, Nair, & Strecher, 2005; see also Peters et al., 2015). Interventions based on theory are more effective than interventions that are not based on theory (Glanz & Bishop, 2010), and the EM approach can provide a bridge between the initial design of theoretically-informed interventions, and the implementation and evaluation of those interventions in real-world settings. This paper is concerned with behavior change interventions that were developed and evaluated in accordance with the EM framework by conducting the initial test of a candidate intervention on food or alcohol intake in a laboratory setting, typically by using bogus “taste tests” in which participants’ ad libitum consumption of food or alcoholic beverages are measured after exposure to the intervention (Jones et al., 2016; Robinson et al., 2017). There are examples of 
	6	interventions that were initially tested in the laboratory, and promising findings from those laboratory studies provided the impetus for RCTs of those interventions that were conducted in the field. For instance, heavy drinkers have a tendency to automatically approach alcohol-related cues (Watson, de Wit, Hommel, & Wiers, 2012). This observation and the underpinning theory (Stacy & Wiers, 2010) establishes alcohol approach biases as a plausible candidate psychological construct that might be modifiable in order to influence drinking behavior (path A). In the first laboratory study to test the causal influence of alcohol approach biases on drinking behavior (Wiers, Rinck, Kordts, Houben, & Strack, 2010), non-dependent alcohol consumers were randomized to repeatedly avoid alcohol-related pictures (intended to strengthen alcohol-avoidance associations), or approach alcohol-related pictures (intended to strengthen alcohol-approach associations). Immediately after training, participants completed measures of the strength of alcohol approach biases, and they were given the opportunity to drink beer so that their voluntary drinking behavior could be measured.  Viewed from the perspective of the EM framework, laboratory studies such as this are able to answer two critical questions: does a candidate behavior change intervention (approach bias modification) cause a desirable change in the target construct (path C), and does this change in the target construct cause a change in the target behavior (path B)?  Findings from this initial laboratory study demonstrated that alcohol approach biases can be modified by training (path C), and that modification of alcohol approach biases exerts a causal influence on alcohol consumption (path B). These findings provided the rationale for conducting subsequent studies that evaluated the effectiveness of this intervention when it was administered as a component of a treatment package to alcohol-dependent patients in a clinical setting. Findings demonstrated that, relative to a control intervention, it reduced relapse to drinking after treatment, and these effects on behavioral outcomes were mediated by the magnitude of the reduction in alcohol approach biases, thereby fulfilling path D in the EM framework (Eberl et al., 2013; Gladwin et al., 2015; Wiers, Eberl, Rinck, Becker, & Lindenmeyer, 2011).   
	7	 The research on approach bias modification to reduce alcohol intake provides an exemplar of how laboratory research can be used to identify a novel behavior change intervention that can subsequently be evaluated in real world settings. The findings from the laboratory studies fulfilled paths B and C in the EM framework which provided a strong justification for evaluating the intervention in field settings. Findings from these RCTs confirmed the effectiveness of this intervention outside of the laboratory (path D). On the basis of this example, one might expect laboratory studies to be able to accurately and consistently identify interventions that are likely to be effective for changing behavior in real world settings. Unfortunately this is not always the case, as we discuss in the following sections.   Lost in translation: promising lab findings do not always yield effective interventions In this section we discuss some examples in which findings from laboratory studies of the determinants of food and alcohol intake were enthusiastically embraced and led to development and evaluation of behavior change interventions that yielded disappointing findings when RCTs were conducted in real-world settings. We illustrate how this situation might have been avoided if more rigorous experimental tests had been conducted to either specify the target construct (path A), confirm that the target construct has a causal influence on behavior (path B), or confirm that the intervention engages the target construct (path C). It is beyond the scope of the current paper to provide a systematic review of the evidence base for these different behavior change interventions, although we refer to relevant systematic reviews where they are available.   Ambiguous causal influence of the target construct on behavior (Path B Failure). A relevant case study is work on Attentional Bias Modification (ABM), the aim of which is to train people to direct their attention away from alcohol- or food-related cues in their environment in order to reduce subjective cravings and consumption (see Field et al., 2016). The initial ABM studies were conducted in laboratory settings and their primary goal was to test theoretical predictions that attentional bias 
	8	(AB) has a causal influence on alcohol or food consumption (path B). In these laboratory studies, participants completed computerized tasks that trained them to shift their attention toward or away from food- or alcohol-related stimuli before food or alcoholic drinks were offered so that their ad libitum intake could be measured. Such studies demonstrated that ‘attend alcohol’ or ‘attend food’ training groups tended to consume more alcohol or food, respectively, than the ‘avoid alcohol’ or ‘avoid food’ groups (Field & Eastwood, 2005; Kemps, Tiggemann, & Elford, 2015). These findings suggest a causal influence of AB on eating and drinking behavior, thereby establishing AB as a target construct for interventions, and ABM as an intervention that is able to modify the target construct (thereby fulfilling paths B and C, respectively). These promising laboratory findings motivated subsequent investigations of clinical applications of ABM which tended to yield null findings, i.e. no benefit of ‘avoid alcohol’ or ‘avoid food’ ABM over control interventions on weight loss or alcohol consumption, according to meta-analyses of this literature (Beard, Sawyer, & Hofmann, 2012; Cristea, Kok, & Cuijpers, 2016; Mogoaşe, David, & Koster, 2014; but see Rinck, Wiers, Becker, & Lindenmeyer, 2018).  Why did the seemingly robust and encouraging findings from laboratory studies fail to translate into an efficacious behaviour change intervention when delivered outside of the laboratory? The answer may lie in the observation that most of the laboratory studies did not include a ‘no training’ control group in whom AB was not manipulated. Consequentially, the nature of the causal influence is unclear: increased AB might increase consumption, reduced AB might reduce consumption, or both processes might be in operation. This is an important detail, because in order to fulfil path B in the EM framework, it is essential to establish that reduction of AB leads to a reduction in food or alcohol intake; this can only be established by comparing the intervention with a control intervention that produces no change in AB. Laboratory studies that contrasted ‘avoid alcohol’ interventions with a control failed to support the hypothesis that reduced AB would lead to reduced alcohol consumption or subjective craving (Schoenmakers, Wiers, Jones, Bruce, & Jansen, 2007). Similarly, in the food domain,  laboratory studies demonstrated no reduction in food intake in 
	9	‘avoid food’ groups compared to control groups (Hardman, Rogers, Etchells, Houstoun, & Munafò, 2013; Boutelle, Kuckertz, Carlson, & Amir, 2014; see Field et al., 2016, for a review).  In summary, promising findings from initial laboratory studies provided the initial justification to investigate the effectiveness of ABM as a behavioral intervention that might reduce alcohol or food intake outside of the lab, but findings from these RCTs have been inconsistent and unconvincing. Consideration of the findings from laboratory studies suggests that it may have been premature to develop ‘avoid ABM’ as a behavior change intervention without confirmation that the causal influence of (reduced) AB on food or alcohol intake was robust (path B). The lesson is that any attempt to translate laboratory findings into behavior change interventions for evaluation in RCTs (path D) would be premature until there is robust evidence for path B in the EM framework.   Ambiguity about the target construct (Path A failure), or how to influence it (Path C failure). Other examples of the risks inherent in evaluating a candidate behavior change intervention outside of the laboratory include ambiguity about what the target construct is (path A), and whether the candidate intervention influences the target construct (path C). A relevant case study is the development of interventions that are intended to encourage people to eat smaller portions of food. The rationale for these interventions stems from observations that people eat more from larger portions of food than from smaller portions (termed the ‘portion size effect’; Hollands et al., 2015; Zlatevska, Dubelaar, & Holden, 2014), and overcoming this effect may reduce overall food intake (Young & Nestle, 2002). This could be accomplished in two ways: (1) providing information about what constitutes a ‘standard’ portion size, and (2) directly manipulating the portion size.  Provision of information about what constitutes a standard portion size does not attenuate the effect of portion size on food intake (Reily & Vartanian, 2016; Ueland, Cardello, Merrill, & Lesher, 2009). Interpretation of these findings is ambiguous because these studies either did not specify a target psychological construct or they did not test the effect of the intervention on that construct. As a consequence, these findings could represent a failure at either path A or C in the EM framework: 
	10	uncertainty about what the target construct actually is (path A failure), which precludes identification of whether the intervention engaged the construct, or not (path C failure). Given that people consume more from larger portions than smaller portions because they perceive the portion size to indicate what is an appropriate amount to eat (Herman, Polivy, Pliner, & Vartanian, 2015), a plausible target construct for these interventions is the perceived ‘appropriateness’ of different portion sizes.  Some studies attempted to manipulate and measure changes in the perceived appropriateness of different portion sizes by directly manipulating the served portion size (as opposed to providing information). For example, participants who were served a small portion of cookies (or pasta) ate less than those served a large portion, and this difference was mediated by the amount of cookies (or pasta) that was perceived as a normal amount to eat (Kerameas, Vartanian, Herman, & Polivy, 2015; Reily & Vartanian, 2016). By demonstrating that the intervention (manipulating the portion size that was served) engaged the target construct (how much was perceived to be appropriate to eat), the findings from these laboratory studies fulfilled path C in the EM framework.  Although direct manipulation of portion sizes provides information about ‘appropriateness’ there may be boundary conditions to this effect, and failure to take these into consideration before conduction RCTs may reduce the likelihood that the intervention will have the desired effect on food intake (Haynes et al., 2019). This may explain why one of the few published RCTs of reduced portion sizes that was conducted outside of the laboratory failed to demonstrate a sustained effect on overall food intake or body weight. French et al. (2014) randomized participants to receive a daily lunchbox for six months that contained either standard-sized portions, or portion sizes reduced by 50%. Participants were able to eat whatever they wanted throughout the rest of the day. Unsurprisingly, lunchtime food intake was lower in the reduced compared to the standard serving size group. However, there were no group differences in overall daily food intake or body weight over the intervention period, which suggests that participants in the reduced serving size condition compensated for their small lunch by eating more throughout the rest of the day. Viewed through the lens of the EM framework, the researchers’ failure to measure changes in the perceived 
	11	appropriateness of the smaller portion sizes during and after the intervention means a failure at path C is a plausible explanation for the null effects of the intervention on overall food intake. In summary, interventions to attenuate or overcome the effect of large portion sizes on energy intake provide an example of where there is a need for further laboratory research to refine and optimize behavior change interventions by considering what the target construct is (path A) and how to engage it (path C). A further class of interventions are those that attempt to manipulate social norms. The rationale is that individual differences in alcohol and food intake are associated with individual differences in beliefs about the alcohol intake (Neighbors, Lee, Lewis, Fossos, & Larimer, 2007) and food intake (Stok, de Vet, de Ridder, & de Wit, 2016) of others. This establishes perceived norms as a plausible target construct for behavior change interventions (path A). Laboratory studies exposed participants to information about the eating behavior of other participants in that experiment either in written form (Roth, Herman, Polivy, & Pliner, 2001) or more subtly such as with exposure to empty food wrappers (Burger et al., 2010). Findings from these laboratory studies demonstrated that when participants were led to believe that others had been eating a small amount of food, this reduced their food intake relative to control conditions (see meta-analysis by Robinson, Thomas, Aveyard, & Higgs, 2014), confirming that social norms exert a causal influence on food intake (path B). They also imply that such ‘social norms marketing’ approaches are able to change norms about food intake in the intended direction (path C). However, this assumption was not empirically tested, because changes in normative beliefs after social marketing interventions were not measured in these studies.	Despite promising initial findings from laboratory studies, RCTs of social norms interventions that utilized posters or provided text information conveying social norms have often yielded null overall effects on food choice or intake (Mollen, Rimal, Ruiter, & Kok, 2013; Rosas et al., 2017; Stok, De Ridder, De Vet, & De Wit, 2012), as did a large RCT that tested the effects of personalized normative feedback on food choice (Thorndike, Riis, & Levy, 2016). However, it should be noted that findings from some observational studies suggest that displaying social norm messages about 
	12	diet is associated with small increases in choices of healthy food (Collins et al., 2019; Thomas et al., 2017). These interventions warrant further evaluation with RCTs that incorporate measurement of changes in normative beliefs after receiving the intervention.  Turning to the literature on personalized normative feedback alcohol interventions for young adults, it is customary to deliver the feedback in laboratory contexts, which makes it likely that participants will engage with that information.  For example, Neighbors et al. (2004) found that relative to an assessment only control, personalized normative feedback changed students’ perceptions of the descriptive norms for drinking at three-month follow-up (thereby fulfilling path C), which in, turn, predicted reductions in self-reported alcohol consumption a further three months later (thereby fulfilling path D).  This pattern of results, which satisfies paths B, C and D in the EM framework, has been replicated a number of times (see Reid & Carey, 2015). However, when administered via web, mail, or through mass marketing campaigns, during which attention to the normative feedback is less likely, meta-analyses confirm that social norms interventions do not have robust effects on alcohol consumption (Foxcroft, Moreira, Almeida-Santimano & Smith, 2015; Reid & Carey, 2015).  Combining the eating and alcohol literatures suggests that normative feedback about others’ behavior has a robust effect on food intake in laboratory studies because participants are likely to pay attention to that information in the context of a laboratory study and therefore change in the target construct is likely to occur (fulfilment of path C). However, when these interventions move to real-world settings, in which normative information is delivered remotely, it is probable that the normative information will not be attended to and therefore the underlying beliefs about the behavior of others will not change (path C failure). From the perspective of the EM framework these observations suggest the need for further research to develop normative feedback interventions that yield robust and sustained changes in normative beliefs in order to ensure that the intervention robustly engages the target construct (path C). Progression to RCTs (path D) would be premature without convincing evidence that path C has been fulfilled.   
	13	  The validity of findings from laboratory studies of food and alcohol intake, and other barriers to translatability          In the preceding sections we demonstrated why it is important to interpret findings from laboratory studies of food and alcohol intake in the context of the EM framework before attempting to conduct an RCT outside of the laboratory, because prematurely conducting an RCT before establishing that the candidate intervention robustly fulfils paths A, B and C in the EM framework is likely to lead to an intervention that is ineffective for changing behavior in the real world. In this section, we consider the internal and external validity of laboratory measurements of food and alcohol intake, and we suggest ways in which these might be improved in order to ensure that findings from laboratory studies are translatable to real world settings.   Internal validity: the importance of standardization of laboratory measures of food and alcohol intake. In laboratory studies that attempt to manipulate food or alcohol intake, participants are provided with food or drink and their consumption is monitored. Vague reporting of methods makes it unclear if participants are informed that their intake is being monitored, although approximately half of studies in the eating literature attempt to conceal this from participants (Robinson, Bevelander, Field, & Jones, 2018; Robinson, Hardman, Halford, & Jones, 2015). Awareness of being monitored is likely to influence food or alcohol intake (an example of the Hawthorne effect; see McCambridge, Witton, & Elbourne, 2014), and this has been demonstrated in laboratory settings (Robinson et al., 2015). Furthermore there is marked variability in the type, number and quantity of foods / drinks that are provided to participants, the use (or not) of a cover story to disguise the true purpose of the test meal / bogus taste test, and the amount of time that participants are given to consume the food or drink that is on offer (Jones et al., 2016; Robinson et al., 2018; Robinson et al., 2017). This lack of standardisation is likely to complicate comparison of 
	14	findings across laboratory studies, which makes it difficult to establish a clear signal in laboratory studies before confidently progressing to RCTs outside of the laboratory. A solution would be the development and validation of standardised laboratory measures of food and alcohol intake, initially by expert consensus and then followed by a programme of research to establish the reliability and validity of those measures, their sensitivity to interventions, and their acceptability to research participants (see Robinson et al., 2017).   Threats to external validity: Laboratory studies and RCTs are typically done for different reasons. When researchers conduct an RCT to test a behavior change intervention in the real-world, their primary objective is to investigate if that intervention leads to a desirable change in the target behavior (e.g., a reduction in alcohol consumption or overall calorie intake, reduction in body mass index) compared to a comparator intervention, and to quantify the magnitude of that effect. By contrast, the primary motivation for many laboratory experiments is to demonstrate causal influences by manipulating a target construct and testing the effect of this manipulation on a behavioral measure (path B). This is the case for many of the initial laboratory investigations of novel interventions, which deliberately attempted to manipulate the target construct in two different directions (for different groups of participants), with the goal of increasing food or alcohol intake in one group and reducing it in another (e.g., alcohol avoidance training: Wiers et al., 2010; inhibitory control training: Houben, 2011; attentional bias modification: Field & Eastwood, 2005; social norms interventions: Robinson, Benwell, & Higgs, 2013; portion size: Hollands et al., 2015; Rolls, Roe, Kral, Meengs, & Wall, 2004). These types of experimental designs serve their purpose in terms of demonstrating causality but they do not necessarily identify a behavioral intervention that could bring about a desirable change in behavior (e.g. a reduction in food or alcohol intake) relative to a true control group. Hasty progression from laboratory studies to RCTs in the absence of this information can lead to a waste of resources (see Becker, Jostmann, & Holland, 2017). These fundamental differences in the theoretical or practical impetus for research (laboratory experiment vs. RCT) directly or indirectly 
	15	impact other sources of variation between RCTs and laboratory studies, which in turn limit the external validity of findings from laboratory studies (see Loyka et al., 2019). Some examples that are particularly relevant to the external validity of laboratory studies of food and alcohol intake are discussed below.  First, participants who take part in laboratory studies are typically student volunteers who are not motivated to change their behavior, and they are not usually informed that their behavior will be manipulated or their food or alcohol intake will be monitored (although these procedural details are rarely reported adequately; Robinson et al., 2018). By contrast, participants who take part in RCTs generally do so because they are motivated to change the problem behavior and they would like help to do so. They also understand that they may receive an intervention, and that their alcohol or food intake is of primary interest to the researchers. These crucial differences raise the possibility that a behavioral intervention that reliably influences behavior in a laboratory experiment may fail to do so when that intervention is evaluated in the context of an RCT. For example, in RCTs, food and alcohol intake and body weight tend to decline in all participants, including those allocated to minimally active control groups. This can be attributed to non-specific features of the control intervention such as regular self-monitoring, placebo effects, and regression to the mean that would be expected in participants who eat or drink to excess and are motivated to change their behavior (Jenkins, McAlaney, & McCambridge, 2009; Johns, Hartmann-Boyce, Jebb, & Aveyard, 2016). Given that these non-specific effects are absent or minimized in laboratory studies, a behavioral intervention that has robust effects on eating or drinking behavior in a laboratory setting may be ineffective when assessed in the real world in the context of an RCT, because non-specific effects in RCTs may obscure the incremental benefit of the behavioral intervention. The reverse is also possible: A candidate behavioral intervention may be tested in the laboratory but prematurely abandoned because it appears to have no causal influence on the target behavior (path B failure), whereas that intervention might only be effective among people who are motivated to change, and / or who expect to receive an intervention (the attributes of people who volunteer for RCTs in the real world).  For example, 
	16	implementation intention interventions must be combined with a motivational intervention in order to influence food intake in real-world settings (Prestwich, Ayres, & Lawton, 2008). A second issue concerns the‘dose’ of the behavioral intervention that is administered in laboratory studies versus in RCTs. One might expect the behavioral impact of some interventions to be maximal after a single exposure, but recipients may subsequently habituate to the effects of that intervention, perhaps to the extent that, after a while, its effect on behavior is reduced to zero. For example, as reviewed in an earlier section of this paper, laboratory studies of social norm interventions typically reveal robust effects on dietary choices immediately after a single exposure to information about the eating habits of other people, whereas repeated exposure to similar social norm information in real-world settings does not reliably influence dietary choices. Other interventions may require repeated exposure, perhaps with optimal spacing between exposures, in order to alter the target construct and thereby influence food or alcohol intake. A case in point is most forms of cognitive bias modification (CBM), single sessions of which administered in the laboratory do not lead to robust, generalizable changes in the target constructs (cognitive biases), whereas multiple sessions of CBM administered outside of the laboratory have more robust effects (Wiers et al., 2018). Third, observation of hypothesized behavioral effects of interventions may be critically dependent on the delay between delivery of the intervention and measurement of the target behavior, and this systematically varies between laboratory studies and RCTs. In most laboratory studies, participants’ food or alcohol intake is measured directly (e.g., with a bogus taste test), typically immediately after exposure to the intervention. Whereas in RCTs, participants’ food or alcohol intake is typically assessed with self-report measures, often some time after repeated exposure to the intervention.  These differences could modify the observed effects of the intervention on target behavior depending on the time course or dose required for the intervention to take effect. For example, as discussed above, some interventions might be expected to have an immediate but short-lived effect on behavior (for example, social norm interventions for eating behavior) whereas other 
	17	interventions might require repeated exposure in order to influence the target construct and have a more enduring effect on the target behavior (for example, CBM).  Finally, researchers go to great lengths to control for and minimize competing influences on food and alcohol intake in laboratory settings. At the same time, interactions between researchers and participants mean that most psychology experiments are complex social environments in which participants are uncertain how to behave, and they may try to infer what the researcher wants them to do and act accordingly (Klein et al., 2012). It is widely acknowledged that this is likely to come at the cost of ‘naturalistic’ behavior: eating and drinking in a laboratory setting is inherently unnatural, and the experimental context itself is likely to have a number of influences on eating and drinking behavior, including the amount consumed. For this reason, the importance of studying the determinants of eating and drinking behavior in both laboratory and naturalistic settings is well known (Meiselman, 1992; Rolls & Shide, 1992). Differences between laboratory and naturalistic settings could feasibly determine whether a candidate behavior change intervention influences behavior in one setting but not the other. For example, participants in laboratory studies may be particularly sensitive to subtle influences on their behavior that are introduced by the experimenter. Whereas in more naturalistic settings, eating and drinking behavior are likely to be influenced by a plethora of internal (e.g., stress) and external (e.g., availability of food and drink, the eating and drinking behavior of others) sources, only a minority of which can realistically be measured by researchers.  The implication is that controlled laboratory tests of the efficacy of a candidate intervention are likely to obscure the likely effectiveness of that intervention when tested in RCTs. For example, provision of normative feedback about the eating behavior of other people might be expected to have a pronounced effect on food intake when measured immediately afterwards in a laboratory setting, because the act of eating in the lab is so unusual that the participant is particularly sensitive to that normative information (Robinson, Thomas, et al., 2014). By contrast, the effects of normative feedback information that is provided in more naturalistic settings may be obscured by competing influences on food intake, for example, the eating behavior of others in one’s immediate 
	18	peer group. This could partially explain why normative feedback interventions for food intake have generally yielded disappointing effects when administered in RCTs conducted in naturalistic settings (Thorndike et al., 2016).             Solutions for improving external validity without sacrificing internal validity: Laboratory studies of the determinants of food and alcohol intake can make important contributions to the identification of novel behavior change interventions, and we certainly do not advocate abandoning laboratory research. Instead, we suggest that some standardization of methodology (see Robinson et al., 2017) to maximize internal validity should be combined with a rigorous programme of laboratory research that gets progressively closer to real-world conditions, in order to maximize external validity (see Loyka et al., 2019). After running an initial laboratory study in tightly controlled conditions (which favors internal over external validity), researchers should run additional laboratory studies rather than progress straight to a real-world RCT. These additional laboratory studies might involve (i) testing participants who are motivated to change and who know that they may receive a behaviour change intervention, (ii) varying the dose of the intervention and the interval between delivery of the intervention and the measurement of behavior, such that they mimic the conditions under which the intervention would be delivered in real-world settings, and (iii) varying the environmental context so that it more closely mimics the real-world settings in which the target behavior occurs and in which the behavior change intervention might be delivered. Examples of the latter include some recent experimental investigations of novel alcohol interventions that were conducted in naturalistic settings, such as a real bar with peers present, (Field, Jones, Kersbergen, & Robinson, 2018; Kersbergen et al., 2018; Leeman et al., 2018).   Implications for evidence synthesis          In the previous section we described how laboratory experiments and RCTs differ in a number of important ways (population, expectation of receiving an intervention, the motivation for 
	19	conducting the research, and so on). We have also illustrated how these factors are likely to introduce systematic differences between findings obtained from the two types of research. The distinction between laboratory experiments and RCTs conducted in the field should be carefully delineated (cf. Riley, Riddle, & Lauer, 2018), because it has important implications in the context of frameworks for accumulating evidence regarding the mechanisms of action of behavior change interventions. For example, as advocated by Peters et al. (2015), findings from laboratory studies and RCTs should be considered in separate meta-analyses, with the findings from meta-analyses of laboratory studies used to inform modified interventions that are then evaluated in subsequent RCTs. This is important because some systematic reviews of behavioral interventions that are characterized by a mixture of laboratory studies and RCTs conducted in field settings have combined the two types of studies on the basis that there is no clear way to distinguish between the two (e.g. Cristea et al., 2016). This has led to misleading conclusions about the effectiveness of those interventions (Wiers et al., 2018).   Conclusion We have scrutinized the contribution of laboratory research into the determinants of food and alcohol intake to the development and refinement of behavior change interventions from the perspective of the EM framework. We have demonstrated that laboratory studies can play an important role in the translation from ideas to efficacy, but it is important to closely adhere to each step of the EM framework, and to be mindful of risks at each step, in order to maximize the value of laboratory research. We have also discussed threats to the external validity of studies that measure food or alcohol intake in the laboratory, and proposed solutions to improve the external validity of research without compromising internal validity. Consideration of the EM framework and how evidence should progress from initial laboratory studies to RCTs will help to ensure that promising candidate interventions that have the potential to improve health will fulfill their translational promise.  
	20	References Abraham,	C.,	&	Michie,	S.	(2008).	A	Taxonomy	of	Behavior	Change	Techniques	Used	in	Interventions.	Health	Psychology,	27(3),	379-387.	doi:10.1037/0278-6133.27.3.379	Bauer,	U.	E.,	Briss,	P.	A.,	Goodman,	R.	A.,	&	Bowman,	B.	A.	(2014).	Prevention	of	chronic	disease	in	the	21st	century:	Elimination	of	the	leading	preventable	causes	of	premature	death	and	disability	in	the	USA.	The	Lancet,	384(9937),	45-52.	doi:10.1016/S0140-6736(14)60648-6	Beard,	C.,	Sawyer,	A.	T.,	&	Hofmann,	S.	G.	(2012).	Efficacy	of	Attention	Bias	Modification	Using	Threat	and	Appetitive	Stimuli:	A	Meta-Analytic	Review.	Behavior	Therapy,	43(4),	724-740.	doi:10.1016/j.beth.2012.01.002	Becker,	D.,	Jostmann,	N.	B.,	&	Holland,	R.	W.	(2017).	Does	approach	bias	modification	really	work	in	the	eating	domain?	A	commentary	on	Kakoschke	et	al.	(2017).	Addictive	Behaviors.	doi:http://dx.doi.org/10.1016/j.addbeh.2017.02.025	Boutelle,	K.	N.,	Kuckertz,	J.	M.,	Carlson,	J.,	&	Amir,	N.	(2014).	A	pilot	study	evaluating	a	one-session	attention	modification	training	to	decrease	overeating	in	obese	children.	Appetite,	76,	180-185.	doi:10.1016/j.appet.2014.01.075	Burger,	J.	M.,	Bell,	H.,	Harvey,	K.,	Johnson,	J.,	Stewart,	C.,	Dorian,	K.,	&	Swedroe,	M.	(2010).	Nutritious	or	delicious?	The	effect	of	descriptive	norm	information	on	food	choice.	Journal	of	Social	and	Clinical	Psychology,	29(2),	228.		Collins,	L.	M.,	Murphy,	S.	A.,	Nair,	V.	N.,	&	Strecher,	V.	J.	(2005).	A	strategy	for	optimizing	and	evaluating	behavioral	interventions.	Annals	of	Behavioral	Medicine,	30(1),	65-73.	doi:10.1207/s15324796abm3001_8	Collins,	E.	I.	M.,	Thomas,	J.	M.,	Robinson,	E.,	Aveyard,	P.,	Jebb,	S.	A.,	Herman,	C.	P.,	&	Higgs,	S.	(2019).	Two	observational	studies	examining	the	effect	of	a	social	norm	and	a	health	
	21	message	on	the	purchase	of	vegetables	in	student	canteen	settings.	Appetite,	132,	122-130.	doi:10.1016/j.appet.2018.09.024	Cristea,	I.	A.,	Kok,	R.	N.,	&	Cuijpers,	P.	(2016).	The	effectiveness	of	cognitive	bias	modification	interventions	for	substance	addictions:	A	meta-analysis.	PLoS	ONE,	11(9).	doi:10.6084/m9.figshare.2059137	Eberl,	C.,	Wiers,	R.	W.,	Pawelczack,	S.,	Rinck,	M.,	Becker,	E.	S.,	&	Lindenmeyer,	J.	(2013).	Approach	bias	modification	in	alcohol	dependence:	Do	clinical	effects	replicate	and	for	whom	does	it	work	best?	Developmental	Cognitive	Neuroscience,	4,	38-51.	doi:10.1016/j.dcn.2012.11.002	Fadardi,	J.	S.,	&	Cox,	W.	M.	(2009).	Reversing	the	sequence:	Reducing	alcohol	consumption	by	overcoming	alcohol	attentional	bias.	Drug	and	Alcohol	Dependence,	101(3),	137-145.	doi:10.1016/j.drugalcdep.2008.11.015	Field,	M.,	&	Eastwood,	B.	(2005).	Experimental	manipulation	of	attentional	bias	increases	the	motivation	to	drink	alcohol.	Psychopharmacology,	183(3),	350-357.	doi:10.1007/s00213-005-0202-5	Field,	M.,	Jones,	A.,	Kersbergen,	I.,	&	Robinson,	E.	(2018).	Experimental	Research	Requires	Valid	and	Sensitive	Measures	of	Alcohol	Intake,	and	This	is	a	Step	in	the	Right	Direction:	Commentary	on	Leeman	and	Colleagues	(2018).	Alcoholism:	Clinical	and	Experimental	Research,	42(6),	1019-1021.	doi:10.1111/acer.13641	Field,	M.,	Werthmann,	J.,	Franken,	I.,	Hofmann,	W.,	Hogarth,	L.,	&	Roefs,	A.	(2016).	The	role	of	attentional	bias	in	obesity	and	addiction.	Health	Psychology,	35(8),	767.		Foxcroft,	D.	R.,	Moreira,	M.	T.,	Almeida	Santimano,	N.	M.	L.,	&	Smith,	L.	A.	(2015).	Social	norms	information	for	alcohol	misuse	in	university	and	college	students.	Cochrane	Database	of	Systematic	Reviews,	12,	article	CD006748.	doi:	10.1002/14651858.CD006748.pub4	
	22	French,	S.	A.,	Mitchell,	N.	R.,	Wolfson,	J.,	Harnack,	L.	J.,	Jeffery,	R.	W.,	Gerlach,	A.	F.,	.	.	.	Pentel,	P.	R.	(2014).	Portion	size	effects	on	weight	gain	in	a	free	living	setting.	Obesity,	22(6),	1400-1405.	doi:10.1002/oby.20720	Gladwin,	T.	E.,	Rinck,	M.,	Eberl,	C.,	Becker,	E.	S.,	Lindenmeyer,	J.,	&	Wiers,	R.	W.	(2015).	Mediation	of	Cognitive	Bias	Modification	for	Alcohol	Addiction	via	Stimulus-Specific	Alcohol	Avoidance	Association.	Alcoholism:	Clinical	and	Experimental	Research,	39(1),	101-107.	doi:10.1111/acer.12602	Glanz,	K.,	&	Bishop,	D.	B.	(2010)	The	role	of	behavioral	science	theory	in	development	and	implementation	of	public	health	interventions.	Annual	Review	of	Public	Health,	31,	399-418.	Hardman,	C.	A.,	Rogers,	P.	J.,	Etchells,	K.	A.,	Houstoun,	K.	V.	E.,	&	Munafò,	M.	R.	(2013).	The	effects	of	food-related	attentional	bias	training	on	appetite	and	food	intake.	Appetite,	71,	295-300.	doi:10.1016/j.appet.2013.08.021	Haynes,	A.,	Hardman,	C.	A.,	Makin,	A.	D.	J.,	Halford,	J.	C.	G.,	Jebb,	S.	A.,	&	Robinson,	E.	(2019).	Visual	perceptions	of	portion	size	normality	and	intended	food	consumption:	A	norm	range	model.	Food	quality	and	preference,	72,	77-85.	doi:10.1016/j.foodqual.2018.10.003	Herman,	C.	P.,	Polivy,	J.,	Pliner,	P.,	&	Vartanian,	L.	R.	(2015).	Mechanisms	underlying	the	portion-size	effect.	Physiology	&	Behavior,	144,	129-136.		Hollands,	G.	J.,	Shemilt,	I.,	Marteau,	T.	M.,	Jebb,	S.	A.,	Lewis,	H.	B.,	Wei,	Y.,	.	.	.	Ogilvie,	D.	(2015).	Portion,	package	or	tableware	size	for	changing	selection	and	consumption	of	food,	alcohol	and	tobacco.	Cochrane	Database	Syst	Rev(9),	Cd011045.	doi:10.1002/14651858.CD011045.pub2	Houben,	K.	(2011).	Overcoming	the	urge	to	splurge:	Influencing	eating	behavior	by	manipulating	inhibitory	control.	Journal	of	Behavior	Therapy	and	Experimental	Psychiatry,	42(3),	384-388.		
	23	Jenkins,	R.	J.,	McAlaney,	J.,	&	McCambridge,	J.	(2009).	Change	over	time	in	alcohol	consumption	in	control	groups	in	brief	intervention	studies:	systematic	review	and	meta-regression	study.	Drug	and	Alcohol	Dependence,	100(1-2),	107-114.	doi:10.1016/j.drugalcdep.2008.09.016	Johns,	D.	J.,	Hartmann-Boyce,	J.,	Jebb,	S.	A.,	&	Aveyard,	P.	(2016).	Weight	change	among	people	randomized	to	minimal	intervention	control	groups	in	weight	loss	trials.	Obesity,	24(4),	772-780.	doi:10.1002/oby.21255	Jones,	A.,	Button,	E.,	Rose,	A.	K.,	Robinson,	E.,	Christiansen,	P.,	Di	Lemma,	L.,	&	Field,	M.	(2016).	The	ad-libitum	alcohol	'taste	test':	Secondary	analyses	of	potential	confounds	and	construct	validity.	Psychopharmacology,	233(5),	917-924.	doi:10.1007/s00213-015-4171-z	Kemps,	E.,	Tiggemann,	M.,	&	Elford,	J.	(2015).	Sustained	effects	of	attentional	re-training	on	chocolate	consumption.	Journal	of	Behavior	Therapy	and	Experimental	Psychiatry,	49,	94-100.	doi:10.1016/j.jbtep.2014.12.001	Kerameas,	K.,	Vartanian,	L.	R.,	Herman,	C.	P.,	&	Polivy,	J.	(2015).	The	effect	of	portion	size	and	unit	size	on	food	intake:	Unit	bias	or	segmentation	effect?	Health	Psychology,	34(6),	670.		Kersbergen,	I.,	Oldham,	M.,	Jones,	A.,	Field,	M.,	Angus,	C.,	&	Robinson,	E.	(2018).	Reducing	the	standard	serving	size	of	alcoholic	beverages	prompts	reductions	in	alcohol	consumption.	Addiction,	113(9),	1598-1608.	doi:10.1111/add.14228	Klein,	O.,	Doyen,	S.,	Leys,	C.,	Magalhães	de	Saldanha	da	Gama,	P.	A.,	Miller,	S.,	Questienne,	L.,	&	Cleeremans,	A.	(2012).	Low	Hopes,	High	Expectations:	Expectancy	Effects	and	the	Replicability	of	Behavioral	Experiments.	Perspectives	on	Psychological	Science,	7(6),	572-584.	doi:10.1177/1745691612463704	Leeman,	R.	F.,	Nogueira,	C.,	Wiers,	R.	W.,	Cousijn,	J.,	Serafini,	K.,	DeMartini,	K.	S.,	.	.	.	O'Malley,	S.	S.	(2018).	A	Test	of	Multisession	Automatic	Action	Tendency	Retraining	to	Reduce	
	24	Alcohol	Consumption	Among	Young	Adults	in	the	Context	of	a	Human	Laboratory	Paradigm.	Alcoholism:	Clinical	and	Experimental	Research,	42(4),	803-814.	doi:10.1111/acer.13613	Lewis,	M.	A.,	&	Neighbors,	C.	(2006).	Social	norms	approaches	using	descriptive	drinking	norms	education:	A	review	of	the	research	on	personalized	normative	feedback.	Journal	of	American	College	Health,	54(4),	213-218.	doi:10.3200/JACH.54.4.213-218	Lewis,	M.	A.,	&	Neighbors,	C.	(2015).	An	examination	of	college	student	activities	and	attentiveness	during	a	web-delivered	personalized	normative	feedback	intervention.	Psychology	of	Addictive	Behaviors,	29,	162-167.	doi:10.1037/adb0000003	Loyka,	C.	M.,	Ruscio,	J.,	Edelblum,	A.	B.,	Hatch,	L.,	Wetreich,	B.,	&	Zabel,	A.	(2019).	Weighing	people	rather	than	food:	A	framework	for	examining	external	validity.	Perspectives	on	Psychological	Science,	in	press,	doi:	10.1177/1745691619876279	McCambridge,	J.,	Witton,	J.,	&	Elbourne,	D.	R.	(2014).	Systematic	review	of	the	Hawthorne	effect:	New	concepts	are	needed	to	study	research	participation	effects.	Journal	of	Clinical	Epidemiology,	67(3),	267-277.	doi:10.1016/j.jclinepi.2013.08.015	Meiselman,	H.	L.	(1992).	Methodology	and	theory	in	human	eating	research.	Appetite,	19(1),	49-55.	doi:10.1016/0195-6663(92)90235-X	Michie,	S.,	West,	R.,	Sheals,	K.,	&	Godinho,	C.	A.	(2017).	Evaluating	the	effectiveness	of	behaviour	change	techniques	in	health-related	behaviour:	a	scoping	review	of	methods	used.	Translational	Behavioral	Medicine,	8,	212-224.		Cox,	W.,	M.	Fadardi,	J.	S.,	Hosier,	S.	G.,	&	Pothos,	E.	M.	(2015).	Differential	effects	and	temporal	course	of	attentional	and	motivational	training	on	excessive	drinking.	Experimental	and	Clinical	Psychopharmacology,	23(6),	445-454.	doi:10.1037/pha0000038	Mogoaşe,	C.,	David,	D.,	&	Koster,	E.	H.	W.	(2014).	Clinical	efficacy	of	attentional	bias	modification	procedures:	An	updated	meta-analysis.	Journal	of	Clinical	Psychology,	70(12),	1133-1157.	doi:10.1002/jclp.22081	
	25	Neighbors,	C.,	Lee,	C.	M.,	Lewis,	M.	A.,	Fossos,	N.,	&	Larimer,	M.	E.	(2007).	Are	social	norms	the	best	predictor	of	outcomes	among	heavy-drinking	college	students?	Journal	of	Studies	on	Alcohol	and	Drugs,	68(4),	556-565.	doi:10.15288/jsad.2007.68.556	Nielsen,	L.,	Riddle,	M.,	King,	J.	W.,	NIH	Science	of	Behavior	Change	Implementation	Team,	Aklin,	W.	M.,	Chen,	W.,	Clark,	D.,	Collier,	E.,	Czajkowski,	S.,	Esposito,	L.,	Ferrer,	R.,	Green,	P.,	Hunter,	C.,	Kehl,	K.,	King,	R.,	Onken,	L.,	Simmons,	J.	M.,	Stoeckel,	L.,	Stoney,	C.,	Tully,	L.,	…	Weber,	W.	(2018).	The	NIH	Science	of	Behavior	Change	Program:	Transforming	the	science	through	a	focus	on	mechanisms	of	change.	Behaviour	Research	and	Therapy,	101,	3–11.	doi:	10.1016/j.brat.2017.07.002	Peters,	G.	J.	Y.,	de	Bruin,	M.,	&	Crutzen,	R.	(2015).	Everything	should	be	as	simple	as	possible,	but	no	simpler:	towards	a	protocol	for	accumulating	evidence	regarding	the	active	content	of	health	behaviour	change	interventions.	Health	Psychology	Review,	9(1),	1-14.	doi:10.1080/17437199.2013.848409	Prestwich,	A.,	Ayres,	K.,	&	Lawton,	R.	(2008).	Crossing	two	types	of	implementation	intentions	with	a	protection	motivation	intervention	for	the	reduction	of	saturated	fat	intake:	A	randomized	trial.	Social	Science	and	Medicine,	67(10),	1550-1558.	doi:10.1016/j.socscimed.2008.07.019	Reid,	A.	E.,	&	Carey,	K.	B.	(2015).	Interventions	to	reduce	college	student	drinking:	State	of	the	evidence	for	mechanisms	of	behavior	change.	Clin	Psychol	Rev,	40,	213-224.		Reily,	N.	M.,	&	Vartanian,	L.	R.	(2016).	The	portion	size	effect	on	food	intake	is	robust	to	contextual	size	information.	Appetite,	105,	439-448.	doi:http://dx.doi.org/10.1016/j.appet.2016.06.015	Riley,	W.	T.,	Riddle,	M.,	&	Lauer,	M.	(2018).	NIH	policies	on	experimental	studies	with	humans.	Nature	Human	Behaviour,	2(2),	103-106.	doi:10.1038/s41562-017-0265-4	Rinck,	M.,	Wiers,	R.	W.,	Becker,	E.	S.,	&	Lindenmeyer,	J.	(2018).	Relapse	Prevention	in	Abstinent	Alcoholics	by	Cognitive	Bias	Modification:	Clinical	Effects	of	Combining	
	26	Approach	Bias	Modification	and	Attention	Bias	Modification.	Journal	of	Consulting	and	Clinical	Psychology,	86(12),	1005-1016.	doi:10.1037/ccp0000321	Robinson,	E.,	Benwell,	H.,	&	Higgs,	S.	(2013).	Food	intake	norms	increase	and	decrease	snack	food	intake	in	a	remote	confederate	study.	Appetite,	65,	20-24.	doi:10.1016/j.appet.2013.01.010	Robinson,	E.,	Bevelander,	K.	E.,	Field,	M.,	&	Jones,	A.	(2018).	Methodological	and	reporting	quality	in	laboratory	studies	of	human	eating	behavior.	Appetite,	125,	486-491.		Robinson,	E.,	Hardman,	C.	A.,	Halford,	J.	C.,	&	Jones,	A.	(2015).	Eating	under	observation:	a	systematic	review	and	meta-analysis	of	the	effect	that	heightened	awareness	of	observation	has	on	laboratory	measured	energy	intake.	Am	J	Clin	Nutr,	102(2),	324-337.	doi:10.3945/ajcn.115.111195	Robinson,	E.,	Haynes,	A.,	Hardman,	C.	A.,	Kemps,	E.,	Higgs,	S.,	&	Jones,	A.	(2017).	The	bogus	taste	test:	Validity	as	a	measure	of	laboratory	food	intake.	Appetite,	116,	223-231.	doi:10.1016/j.appet.2017.05.002	Robinson,	E.,	Jones,	A.,	Christiansen,	P.,	&	Field,	M.	(2014).	Perceived	peer	drinking	norms	and	responsible	drinking	in	UK	university	settings.	Substance	Use	and	Misuse,	49(11),	1376-1384.	doi:10.3109/10826084.2014.901390	Robinson,	E.,	Thomas,	J.,	Aveyard,	P.,	&	Higgs,	S.	(2014).	What	everyone	else	is	eating:	a	systematic	review	and	meta-analysis	of	the	effect	of	informational	eating	norms	on	eating	behavior.	Journal	of	the	Academy	of	Nutrition	and	Dietetics,	114(3),	414-429.		Rodriguez,	L.	M.,	Neighbors,	C.,	Rinker,	D.	V.,	Lewis,	M.	A.,	Lazorwitz,	B.,	Gonzales,	R.	G.,	&	Larimer,	M.	E.	(2015).	Remote	versus	in-lab	computer-delivered	personalized	normative	feedback	interventions	for	college	student	drinking.	Journal	of	Consulting	and	Clinical	Psychology,	83(3),	455-463.	doi:10.1037/a0039030	
	27	Rolls,	B.	J.,	Roe,	L.	S.,	Kral,	T.	V.	E.,	Meengs,	J.	S.,	&	Wall,	D.	E.	(2004).	Increasing	the	portion	size	of	a	packaged	snack	increases	energy	intake	in	men	and	women.	Appetite,	42(1),	63-69.	doi:	10.1016/S0195-6663(03)00117-X	Rolls,	B.	J.,	&	Shide,	D.	J.	(1992).	Both	naturalistic	and	laboratory-based	studies	contribute	to	the	understanding	of	human	eating	behavior.	Appetite,	19(1),	76-77.	doi:10.1016/0195-6663(92)90240-7	Rosas,	C.	E.,	Gregorio-Pascual,	P.,	Driver,	R.,	Martinez,	A.,	Price,	S.	L.,	Lopez,	C.,	&	Mahler,	H.	I.	M.	(2017).	Effects	of	social	norms	information	and	self-affirmation	on	sugar-sweetened	beverage	consumption	interventions	and	behaviors.	Basic	and	Applied	Social	Psychology,	39(2),	112-126.	doi:	10.1080/01973533.2017.1283503	Roth,	D.	A.,	Herman,	C.	P.,	Polivy,	J.,	&	Pliner,	P.	(2001).	Self-presentational	conflict	in	social	eating	situations:	a	normative	perspective.	Appetite,	36(2),	165-171.	doi:10.1006/appe.2000.0388	Schoenmakers,	T.,	Wiers,	R.	W.,	Jones,	B.	T.,	Bruce,	G.,	&	Jansen,	A.	T.	M.	(2007).	Attentional	re-training	decreases	attentional	bias	in	heavy	drinkers	without	generalization.	Addiction,	102(3),	399-405.	doi:10.1111/j.1360-0443.2006.01718.x	Sheeran,	P.,	Klein,	W.	M.	P.,	&	Rothman,	A.	J.	(2017).	Health	Behavior	Change:	Moving	from	Observation	to	Intervention.	Annual	Review	of	Psychology.	doi:10.1146/annurev-psych-010416-044007	Stacy,	A.	W.,	&	Wiers,	R.	W.	(2010).	Implicit	cognition	and	addiction:	A	tool	for	explaining	paradoxical	behavior.	Annual	Review	of	Clinical	Psychology,		6,	551-575).	Stok,	F.	M.,	de	Ridder,	D.	T.,	de	Vet,	E.,	&	de	Wit,	J.	B.	(2012).	Minority	talks:	the	influence	of	descriptive	social	norms	on	fruit	intake.	Psychology	and	Health,	27)8),	956-970.	doi:	10.1080/08870446.2011.635303	
	28	Stok,	F.	M.,	de	Vet,	E.,	de	Ridder,	D.	T.,	&	de	Wit,	J.	B.	(2016).	The	potential	of	peer	social	norms	to	shape	food	intake	in	adolescents	and	young	adults:	a	systematic	review	of	effects	and	moderators.	Health	Psychology	Review,	10(3),	326-340.		Tapper,	K.	(2017).	Can	mindfulness	influence	weight	management	related	eating	behaviors?	If	so,	how?	Clinical	Psychology	Reiewv,	53,	122-134.	doi:10.1016/j.cpr.2017.03.003	Tapper,	K.	(2018).	Mindfulness	and	craving:	effects	and	mechanisms.	Clinical	Psychology	Review,	59(Supplement	C),	101-117.	doi:	10.1016/j.cpr.2017.11.003	Thomas,	J.	M.,	Ursell,	A.,	Robinson,	E.	L.,	Aveyard,	P.,	Jebb,	S.	A.,	Herman,	C.	P.,	&	Higgs,	S.	(2017).	Using	a	descriptive	social	norm	to	increase	vegetable	selection	in	workplace	restaurant	settings.	Health	Psychology,	36(11),	1026-1033.	doi:10.1037/hea0000478	Thorndike,	A.	N.,	Riis,	J.,	&	Levy,	D.	E.	(2016).	Social	norms	and	financial	incentives	to	promote	employees'	healthy	food	choices:	A	randomized	controlled	trial.	Preventive	Medicine,	86,	12-18.	doi:	10.1016/j.ypmed.2016.01.017	Ueland,	Ø.,	Cardello,	A.	V.,	Merrill,	E.	P.,	&	Lesher,	L.	L.	(2009).	Effect	of	Portion	Size	Information	on	Food	Intake.	Journal	of	the	American	Dietetic	Association,	109(1),	124-127.	doi:	10.1016/j.jada.2008.10.002	Watson,	P.,	de	Wit,	S.,	Hommel,	B.,	&	Wiers,	R.	W.	(2012).	Motivational	Mechanisms	and	Outcome	Expectancies	Underlying	the	Approach	Bias	toward	Addictive	Substances.	Frontiers	in	Psychology,	3,	440.	doi:10.3389/fpsyg.2012.00440	Wiers,	R.	W.,	Boffo,	M.,	&	Field,	M.	(2018).	What's	in	a	trial?	On	the	importance	of	distinguishing	between	experimental	lab	studies	and	randomized	controlled	trials:	the	case	of	Cognitive	Bias	Modification	and	Alcohol	Use	Disorders.	Journal	of	Studies	on	Alcohol	and	Drugs,	79(3),	333-343.		Wiers,	R.	W.,	Eberl,	C.,	Rinck,	M.,	Becker,	E.	S.,	&	Lindenmeyer,	J.	(2011).	Retraining	automatic	action	tendencies	changes	alcoholic	patients'	approach	bias	for	alcohol	and	improves	
	29	treatment	outcome.	Psychological	Science,	22(4),	490-497.	doi:10.1177/0956797611400615	Wiers,	R.	W.,	Rinck,	M.,	Kordts,	R.,	Houben,	K.,	&	Strack,	F.	(2010).	Retraining	automatic	action-tendencies	to	approach	alcohol	in	hazardous	drinkers.	Addiction,	105(2),	279-287.		Young,	L.	R.,	&	Nestle,	M.	(2002).	The	contribution	of	expanding	portion	sizes	to	the	US	obesity	epidemic.	American	Journal	of	Public	Health,	92(2),	246-249.	doi:10.2105/AJPH.92.2.246	Zlatevska,	N.,	Dubelaar,	C.,	&	Holden,	S.	S.	(2014).	Sizing	up	the	effect	of	portion	size	on	consumption:	A	meta-analytic	review.	Journal	of	Marketing,	78(3),	140-154.		         Figure 1: Sheeran et al.’s (2017) Experimental Medicine framework as applied to laboratory studies  of food and alcohol intake. Path A is supported if there is a theoretical rationale for a causal influence of the target construct on eating and / or drinking behavior, and if observational studies are consistent 
	30	with this. Path B is supported if experimental studies in which the target construct is experimentally manipulated demonstrate a causal effect of the target construct on eating and / or drinking behavior in the laboratory. Path C is supported if a candidate intervention has a robust effect on the target construct, again typically in the laboratory. Path D, which is typically investigated outside of the laboratory, is supported if the intervention has a beneficial effect on eating or drinking behaviour and if that effect is mediated by changes in the target construct. See text for details. Republished with permission of Annual Reviews Inc., from Sheeran, P., Klein, W. M. P., & Rothman, A. J. (2017). Health behavior change: Moving from observation to intervention. Annual Review of Psychology, 68, 573–600. Permission conveyed through Copyright Clearance Center, Inc. 
 

