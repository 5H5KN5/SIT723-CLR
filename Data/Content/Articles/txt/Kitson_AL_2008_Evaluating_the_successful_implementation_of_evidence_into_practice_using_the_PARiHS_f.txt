BioMed Central
Page 1 of 12
(page number not for citation purposes)Implementation Science
Open Access Debate
Evaluating the successful implementa tion of evidence into practice 
using the PARiHS framework: theo retical and practical challenges
Alison L Kitson*1, Jo Rycroft-Malone2, Gill Harvey3, Brendan McCormack4, 
Kate Seers5 and Angie Titchen6
Address: 1Green College, University of Oxford, Woodstock Road, Oxford OX2 6HG, UK, 2Centre for Health Related Re search, School for Health 
Care Sciences, College of Health & Behavioura l Sciences, University of Wales, Bangor, UK, 3Centre for Public Policy and Management, Manchester 
Business School, University of Manchester, Bo oth Street West, Manchester M15 6PB, UK, 4Institute of Nursing Research, University of Ulster, Shore 
Road, Newtownabbey, Co. Antrim, BT 37 0QB, Northern Ireland, UK, 5RCN Institute, School of Health and Social Studies, University of Warwick, 
Coventry CV4 7 AL, UK and 6Fontys University of Applied Scie nce, Eindhoven, The Netherlands
Email: Alison L Kitson* - alk23@btinternet.com ; Jo Rycroft-Malone - j.rycroft-malone@bangor.a c.uk; Gill Harvey - Gi ll.harvey@mbs.ac.uk; 
Brendan McCormack - bg.mccormack@ulster.ac.uk; Kate Seers - Ka te.seers@warwick.ac.uk; Angie Titchen - a.titchen@fontys.nl
* Corresponding author    
Abstract
Background: The PARiHS framework (Promoting Action on Research Implem entation in Health
Services) has proved to be a us eful practical and conceptual he uristic for many researchers and
practitioners in framing their research or kn owledge translation endeavours. However, as a
conceptual framework it still remains untested and therefore its contribution to the overall
development and testing of theory in the field of  implementation science is largely unquantified.
Discussion: This being the case, the paper provides an integrated summary of our conceptual and
theoretical thinking so far and introduces a typol ogy (derived from social  policy analysis) used to
distinguish between the terms conceptual framew ork, theory and model – important definitional
and conceptual issues in trying to refine theoretical and methodol ogical approaches to knowledge
translation.
Secondly, the paper describes the next phase of our work, in particular concentrating on the
conceptual thinking and mapping that has led to the generation of the hypothesis that the PARiHS
framework is best utilised as a two-stage proces s: as a preliminary (dia gnostic and evaluative)
measure of the elements and sub-elements of ev idence (E) and context (C), and then using the
aggregated data from these meas ures to determine the most appr opriate facilitation method. The
exact nature of the intervention is thus determined  by the specific actors in the specific context at
a specific time and place.
In the process of refining this next phase of ou r work, we have had to consider the wider issues
around the use of theories to inform and shape our research activity; th e ongoing challenges of
developing robust and sensitive meas ures; facilitation as an interv ention for getting research into
practice; and finally to note ho w the current debates around evid ence into practice are adopting
wider notions that fit innovations more generally.
Summary: The paper concludes by suggesting that th e future direction of the work on the
PARiHS framework is to develo p a two-stage diagnostic and ev aluative approach, where thePublished: 7 January 2008
Implementation Science  2008, 3:1 doi:10.1186/1748-5908-3-1Received: 2 March 2007
Accepted: 7 January 2008
This article is available from: http:// www.implementationscience.com/content/3/1/1
© 2008 Kitson et al; licensee BioMed Central Ltd. 
This is an Open Access article distributed under the terms of the Creative Commons Attribution License (http://creativecommons. org/licenses/by/2.0 ), 
which permits unrestricted use, distribution, and reproduction in any medium, provided the orig inal work is properly cited.
Implementation Science  2008, 3:1 http://www.implementatio nscience.com/content/3/1/1
Page 2 of 12
(page number not for citation purposes)intervention is shaped and moulded by the info rmation gathered about the specific situation and
from participating stakeholders. In order to expe dite the generation of new evidence and testing
of emerging theories, we suggest the formation of an international research implementation science
collaborative that can systematically collect an d analyse experiences of using and testing the
PARiHS framework and similar concep tual and theoretical approaches.
We also recommend furthe r refinement of the definitions aro und conceptual framework, theory, 
and model, suggesting a wider discussion that em braces multiple epistemological and ontological 
perspectives.
Background
The spread of best practice and the use of best evidence
remain sporadic. There continues to be a tension betweenpolicy imperatives and the ability to successfully supportand enable local developments. Arguably the debateabout how to implement evidence effectively reflects alack of a true appreciation or understanding of the multi-ple factors involved. However, there has been a shift away
from the traditional notion that getting evidence into
practice is straightforward. Until relatively recently thespread of evidence was seen as a linear and technical proc-ess at the level of the individual, and was described aschanges in clinicians' behaviour in line with evidence-based guidelines [1]. Now there is widespread recognition
that guideline implementation, and evidence implemen-
tation more generally, requires whole system changeimplicating both the individual and organisation ([2,3]).Despite a growing awareness that getting evidence intopractice is a complex, multi-faceted process, there remainsa lack of knowledge about what methods and approaches
are effective, with whom and in what contexts.
The PARiHS framework represents the complexities of
implementing evidence into practice. Previous papershave reported on the development of the framework overtime [4-9]. Other authors have also reported on their useof PARiHS as a theoretical and practical heuristic to guide
research and practice development work [10-14]. This
paper integrates our work to date and presents thehypothesis that the PARiHS framework could be appliedby practitioners as a diagnostic and evaluative tool to suc-cessfully implement evidence into practice, and by practi-tioners and researchers to evaluate such activity. In
addition, the current and future challenges in relation to
the PARiHS framework and to the field more generally areidentified and discussed.
The PARiHS framework – an overview
Within the PARiHS framework, successful implementa-
tion (SI) is represented as a function (f) of the nature and
type of evidence (E), the qualities of the context (C) inwhich the evidence is being introduced, and the way theprocess is facilitated (F); SI = f (E, C, F). Detailed descrip-tions exist in the literature on the development andempirical evaluation of the PARiHS framework [4-9]. The
framework has been refined through two phases of
research and development and is currently in its third orcurrent phase (see Table 1 for a comprehensive sum-mary). The unique characteristic of the PARiHS frame-work was that it proposed a three-dimensional frameworkwithin which to interpret successful implementation,arguing that elements could be located on a continuum of
"high" to "low" evidence and context
Summary of the development and refinement steps for 
PARiHS framework. (See Table 1)
The main features and assumptions of the framework are:
1. Evidence encompasses codified and non-codified
sources of knowledge, including research evidence, clini-cal experience including professional craft knowledge,patient preferences and experiences, and local informa-tion.
2. Melding and implementing such evidence in practice
involves negotiation and developing a shared understand-ing about the benefits, disbenefits, risks, and advantagesof the new over the old. This is a dialectical process thatrequires careful management and choreography, and onethat is not done in isolation; in other words, it is a teameffort.
3. Some contexts are more conducive to the successful
implementation of evidence into practice than others –these include contexts that have transformational leaders,features of learning organisations, and appropriate moni-toring, evaluative, and feedback mechanisms.
4. There is an emphasis on the need for appropriate facil-
itation to improve the likelihood of success. The type offacilitation, and the role and skill of the facilitator that isrequired is determined by the "state of preparedness" ofan individual or team, in terms of their acceptance and
understanding of evidence, the receptivity of their place of
work or context in terms of the resources, culture and val-ues, leadership style, and evaluation activity. Facilitatorswork with individuals and teams to enhance the processof implementation.
Implementation Science  2008, 3:1 http://www.implementatio nscience.com/content/3/1/1
Page 3 of 12
(page number not for citation purposes)The objective of the current phase of our work is to build
on the concept analysis and clarification undertaken inphases one and two, and to evaluate the current frame-work through the development and testing of diagnosticand evaluative instruments to assist in the process ofknowledge translation. Whilst conducting this phase, anumber of challenges have arisen, which, whilst reflecting
the particular complexities of the PARiHS framework's
development, are also relevant to current debates in thefield of knowledge translation. These include:
1. Understanding how the conceptual framework relates
to, and informs the development of, integrated theoretical
positions that are practically useful and theoretically
robust.2. Engaging in the challenges measurement presents and
particularly within a theoretical position which arguesthat the intervention (a precise and tailor-made type offacilitation constructed by a skilled facilitator and thoseinvolved in the implementation process) is contingentupon the diagnosis of the evidence and context elementsand clarifying facilitation as an intervention.
These issues will be considered in turn.
Discussion
Conceptual frameworks, theories, and models of 
knowledge translation: seeking greater clarity
There is a growing interest in the literature around clarifi-
cation of terminology used in implementation scienceand also around the use of such mental devices as concep-tual frameworks, theories, and models [15]. However,Table 1: Summary of development and refinement steps of PARiHS framework
Phase 1: Development and Concept Analysis 1998 – 2002
Origins - Emerged from working with clinicians in  helping them to  improve practice, introduc e new ideas and implement 
guidelines.
Main Attributes - Successful implementation of new idea s (evidence, guidelines, etc.) is a func tion of the interrelations between 
three key elements – evidence, con text, facilitation: SI = f (E, C, F)
Face Validity - 4 research studies were analysed retrospectively to test the hypothesis that SI = f (E, C, F).
- Strong face validity.
Construct Validity - Assumption that E vidence, Context and Facilitation  as described are discrete an d interdependent and can be 
manipulated in a purposeful way.
Refinement - Need to undertake detailed concept analysis of each of the elements and sub-elements (E, C, F).
Future Action - Concept analysis and empirical testing.
Publications - [4-7]
Phase 2: Empirical Case Studies 2001–2003
Main Research Questions - What factors do practitioners identify as the most important in enabling implementation of evidence into 
practice?- Do concepts of evidence, context and facilitation co nstitute the key elements of  a framework for getting 
research into practice?
Refinement - Important additions to evid ence – information from local context; resources, physical and political influences in 
context.- Experience of facilitators on the grou nd with very little, limited support.
Future Action - Further testing through larger scale empirical enquiry testing the checklist and developing an evaluation tool.
Publications - [5, 8]
Phase 3: Development of Diagnost ic/Evaluation Tool 2003 – Present
Main Research Questions - Is it possible to develop a diagnost ic and evaluative tool to measure the successful implementation of new ideas 
(evidence, innovation) into pract ice using the PARiHS framework?
Refinement - Pre-test diagnostic phase
• Summary scores for evid ence and context (E, C)
• Narrative summary• Information on prototypes  of facilitation approaches
- The facilitation process
- The post test evaluation
• Re-plot summary scores for E + C• Narrative summary• Evaluation of facilitation approach
Implementation Science  2008, 3:1 http://www.implementatio nscience.com/content/3/1/1
Page 4 of 12
(page number not for citation purposes)despite the debate there is little consistency in the way
these terms are used and in particular there is a tendency
to substitute one term for another without due considera-tion of the deeper meaning attributed to such terms. Forexample, one of the earliest conceptual frameworks devel-oped by Havelock and colleagues [16] was derived fromRoger's Diffusion of Innovation Theory [17]. Their
Research Dissemination Utilization Conceptual Frame-
work was built upon two key components – knowledgebuilding and institutionalizing. Knowledge building (orsynthesis) would integrate theories to replace fragmentedapproaches, and their concept of institutionalisation ena-bled the new knowledge to be transferred through inte-
grated, cross discipline, cross boundary programmes. Of
primary importance is the relationship of trust andmutual co-operation that needs to be built up betweenresearchers, policy makers, decision makers, and practi-tioners.
Greenhalgh et al. 's synthesis of the literature on diffusion
of innovations has also produced a conceptual map [18].
Described by the authors as a "conceptual model" it is notexpected to be used in any practical way to guide actions.Rather, it is a mental representation of the many elementsthat need to be considered. Each element was derivedfrom rigorous review of the literature, and the antecedent
theories informing (and shaping) the elements are
described. For example, one element of the model is dif-fusion, and within that element several approaches to dif-fusion are described – social networks, marketing, expertopinion – all aspects/actions of a wider theoretical per-spective.
In contrast, Graham et al. have offered their own concep-
tual framework to help elucidate what they believe to bethe key elements of the knowledge-to-action process [15].Essentially the framework is divided into two elements orconcepts: knowledge creation and action, with specific
steps within each element. (For a detailed explanation see
Graham et al. [15].) The framework also begins to articu-
late the embedded theoretical positions that determineaction. Graham and colleagues are particularly interestedin theories of planned action [19] and have identifiedover 60 theories or frameworks (although the authors donot distinguish between these terms in their paper).
The PARiHS framework shares similar characteristics to
the above conceptual frameworks – the identification ofelements and relationships, embedded (either explicit orimplicit) theoretical positions, and a way of trying toexplain a complex set of phenomena that enable action to
be taken. What distinguishes the PARiHS conceptual
framework from the others is that as well as mapping theinterrelationships, PARiHS has the potential to be used asa practical and pragmatic tool by practitioners andresearchers at the local level. This is the claim, and it is
also the hypothesis that we are continually testing.
In addition to the literature on conceptual frameworks,
there is an emerging debate about theory use and develop-ment in knowledge translation work [20-22]. Theory useis presented by its supporters as a promising approach to
better understanding the 'black box' of implementation
[23]. Estabrooks et al. 's description illustrates the vast
array of theories that could be used to determine orexplain the process of implementation, and also demon-strates the lack of agreement on terms – models, frame-works, and theories are used interchangeably [20]. What
seems to be emerging is that the term theory is used when
a set of relationships are explained and there is some pre-dictive capability: for example, the use of social influencestrategies to introduce clinical guidelines [24]. The use ofthe term model seems much more diffuse – ranging fromprescriptions on how to implement research into practice[25-27] to more specific descriptions of a theoretical per-
spective, e.g., Prochaska et al. 's transtheoretical model of
health behaviour change [28]. However, to date, the prev-alent view about theory and knowledge translation hastended to focus upon positivistic interpretations thatfavour deterministic explanations [23].
One typological definition
Therefore, one important question is whether it matterswhat we call these mental devices. Is there a differencebetween conceptual frameworks, theories, and models,and, if so, what and how would such differentiations helpour understanding of the complex world of research
implementation or knowledge translation? Identical
questions have been posed in the discipline of public pol-icy analysis and implementation, as well as theory devel-opment [29]. The policy world is complex, with multipleelements interacting over time. How can complex situa-tions be simplified in order to understand them, and how
can the tension be managed between the exploration of
specific interventions within a system and the overallappreciation of the impact of the intervention on thewhole system? In attempting to create a deeper under-standing, Sabatier and colleagues have described threedominant approaches to policy analysis and implementa-tion [29]. Within this analytic framework they have also
put forward a typology for understanding the different
'mental representations' we could use to hold onto thecomplex world. This analytic framework, first proposedby Ostrom [30,31], has been used as a way of trying tomake sense of the different ways that frameworks, theo-ries, and models could be used to inform our research
activity. Ostrom [31] argued that:
"...given the need for multiple disciplinary languages
and given the multiple levels of analysis involved in
Implementation Science  2008, 3:1 http://www.implementatio nscience.com/content/3/1/1
Page 5 of 12
(page number not for citation purposes)studying configural relationships between rules, rele-
vant aspects of the world and cultural phenomena, the
study of institutions does depend on theoretical workundertaken at three levels, namely frameworks, theo-ries and models"
Both Sabatier [30] and Ostrom [31] argue that for the
effective development of policy theory the following dis-
tinctions can be made. A conceptual framework identifiesa set of variables and relationships that should be exam-ined in order to explain the phenomena. Indeed, a frame-work can provide anything from a skeletal set of variablesto something as extensive as a paradigm, where a para-
digm is the notion which places emphasis on professional
consensus within a particular scientific community. Itstands for the entire constellation of beliefs, values, andtechniques shared by members of that community [32]. Aconceptual framework need not specify the direction ofrelationships or identify critical hypotheses. In contrast, atheory provides a denser and logically coherent set of rela-
tionships. Theories can offer views on the causal relation-
ships and seek to explain the phenomena, although froman interpretative perspective theories also play a vital rolein offering explanations rather than causal relationships[33]. Numerous theories may be consistent within thesame framework. Models, by contrast, represent a specific
situation, are narrower in scope, and are more precise in
their assumptions [29,31]This approach would seem tooffer one way of testing conceptual coherence between thetypological levels within the discourse of implementationscience.
For Ostrom [31], a conceptual framework helps to iden-
tify elements and relations among those elements thatone needs to consider for an analysis of organisations (atmultiple levels of operation – individual, team, unit, andwhole systems level) and their ability to absorb and adoptinnovations. Frameworks also organise diagnostic and
prescriptive enquiry and provide a more general list of var-
iables that can be used to analyse types of institutionalarrangements. Conceptual frameworks provide a meta-theoretical language that can be used to compare theories,and they attempt to identify universal elements of any the-ory relevant to the same kind of phenomena that wouldneed to be included in order to understand the "bigger
conceptual picture". Thus, for example, in Ostrom's anal-
ysis, the question would be whether the elements as iden-tified in the PARiHS framework survive continuousscrutiny and testing against multiple theories at multiplelevels within the organisation that have a relevance andcoherence to research implementation strategies. So long
as this is the case, the elements remain intact: once excep-
tions begin to emerge, the basic tenets of the conceptualframework are placed under further scrutiny.Whilst the PARiHS framework has been subject to an
ongoing development process, questions about it remain,
including:
1. How do the elements (evidence, context, and facilita-
tion) and sub-elements interrelate and interact with eachother and across the different layers of the organisation?
2. Do the elements and sub-elements have equal weight-
ing in getting evidence into practice?
3. Is the content of the framework comprehensive?
For the framework to usefully inform the development
and testing of current and emerging theories, these ques-tions need to be answered. Arguably, work to date hasprovided evidence of the framework's content and con-struct validity [6-8,11]; that is, we can be reasonably con-fident that PARIiHS is a conceptually robust framework.This is a sufficient basis upon which to begin testing a
range of theories and building new theories inductively
and deductively. The test of its effectiveness as a concep-tual framework is whether it can generate such diagnostic,analytic, prescriptive, interpretative, and evaluative dis-course.
According to Ostrom [31], key questions to test the coher-
ence of any conceptual framework, include:
1. Does the framework provide a coherent language for
identifying universal elements of theories attempting toexplain an important range of phenomena?
2. Does the framework help scholars to identify similari-
ties or differences of diverse theories as well as to analysethe relative strengths and weaknesses of theories inexplaining particular types of phenomena?
3. Does the framework stimulate new theoretical develop-
ments?
Questions used to test the usefulness of any conceptual
framework in empirical research include:
1. Does the framework help organise empirical research in
those areas where well-specified theories are not yet for-
mulated?
2. Does empirical research drawing in the framework lead
to new discoveries and better explanation of importantphenomena?
3. Can the framework be applied to multiple levels of
analysis in empirical research?
Implementation Science  2008, 3:1 http://www.implementatio nscience.com/content/3/1/1
Page 6 of 12
(page number not for citation purposes)And finally, in relation to conceptual frameworks,
Ostrom's typology includes questions about the ease by
which the framework aids the better understanding anddialogue across disciplinary boundaries:
1. Does the framework encourage integration across other
disciplines?
2. Is the framework consistent with other frameworks ini-
tially developed to focus on a particular level of analysis?
3. Does the framework perform better than others in a
similar stage of application?
These questions are helpful because they enable an assess-
ment to be made of the PARiHS framework's stage ofdevelopment and provide an agenda for further work. Forexample, there is evidence to indicate that PARiHS doeshelp organise empirical research where theories are yet tobe formulated [11,34], and that the framework has led to
better explanations of important phenomena [10,35].
However, consideration still needs to be given to theframework's capability for theory application and devel-opment. Questions about the range and diversity of appli-cable theories still need to be explicated. AdoptingOstrom's typology, which acknowledges multiplicity, it
could be argued that rather than placing PARiHS within
one particular theoretical perspective or offering a singletheory for research implementation, which could limit itsapplicability, the framework could be populated by mul-tiple theories, at multiple levels. From this perspective thePARiHS framework would operate similarly to other
frameworks outlined earlier, e.g., Graham et al. 's [15]
Knowledge to Action (KTA) framework that focuses onplanned action theories, or Greenhalgh et al. 's [18] con-
ceptual model summarising the range of theories thatinfluence diffusion of innovations.
Further consideration of these issues forms the basis of the
next phase of work/development of PARiHS and in partic-ular attempts to answer the key questions raised byOstrom. These include whether the framework can pro-vide a coherent language for identifying universal ele-ments of theories attempting to explain an importantrange of phenomena, or indeed whether PARiHS can be
applied to multiple levels of analysis – such as individual,
team, unit, and organisational-wide level?
Frameworks, theories and models in use: the chess game
How does this analysis help to guide users in successfullyimplementing evidence into practice? We could use the
analogy that the PARiHS framework is like a chess game.
There is a defined set of rules and an agreed number ofchess players. The pawns, knights, king, queen, bishops,etc. each have a set of rules to follow. Each chess piece hasits own provenance or theoretical background that would
explain the reason why different pieces move in certain
ways. Equally, in each game the unique configuration ofthe chess pieces creates an almost infinite number ofmoves that can test the boundaries of movement of eachpiece, and equally test the boundaries of the higher rulesof the game (framework) itself. Each new game could be
like a model that will test the theories of the chess pieces
within the boundaries of the chess game, i.e. the concep-
tual framework.
However, unlike the chess game, we still do not know the
rules (should there be any) of the knowledge translation
game and the movements of the different pieces are yet to
be fully understood. Of course, this analogy only works ifwe accept the prior assumption that implementationprocesses are predictable, and that there are certain causesand effects at work. The converse position is to assumethat all interactions are random, and that there is no pre-dictive capacity because of the complexity involved in
working with so many variables. Given that we do not
know which of these positions is the more accurate, and itis largely dependent on one's world view of how theseissues should be studied, we argue that it is legitimate toproceed with the "chess game analogy" until there is suf-ficient evidence amassed to disprove it. Taking such an a
priori position is consistent to Kuhn's notion that all good
scientific endeavours are about the business of empiricallyfalsifying propositions within a theoretical framework[29].
Thus, to conceptualise the process of introducing evidence
into practice, we are suggesting that to use the PARiHS
framework, practitioners and researchers contemplate theinterplay of evidence, context, and facilitation, as well astheir sub-elements. Each element and sub-element has aconceptual and theoretical order that determines itsintrinsic properties; the interaction of these elements is
conditional on their state, maturity, context, and many
other factors. The modelling or experimentation that canbe constructed is a way of tracking the nature of the differ-ent elements and beginning to map the processes bywhich change occurs through the interaction of these ele-ments.
Table 2 illustrates how the PARiHS framework elements
(evidence, context and facilitation) could draw on multi-ple theoretical perspectives. This, in turn, offers even moremodels that can then be used to explore systematically theconsequences of these propositions in a clearly definedand controlled set of outcomes. What begins to emerge
when looking at Table 2 is that, depending on the theoret-
ical approach taken, there is any number of entry pointsinto testing elements of the framework.
Implementation Science  2008, 3:1 http://www.implementatio nscience.com/content/3/1/1
Page 7 of 12
(page number not for citation purposes)How researchers and practitioners "make sense" of the
bigger conceptual framework is a fundamental questionand an on-going challenge reflecting the complexitiesinvolved. The choice of theoretical perspective will neces-sarily put a boundary around the area of investigation. Forexample, if we want to investigate the impact of opinion
leaders on research implementation using transforma-
tional leadership theory, then we will still be left with thejob of integrating these findings into the bigger concep-tual picture of how research findings get into practice.Holding one piece of the conceptual jigsaw without negat-
ing the possible impact of other factors is very importantbut very difficult to manage. The proposed links are hypo-thetical and illustrate the conceptual challenges of anynascent discipline.
Such an approach to framework and theory use and devel-
opment requires researchers to be flexible and holistic. Todate, the knowledge translation literature describes theoryuse and development as a linear and discrete process inTable 2: Conceptual frameworks, theories and models: Interrelat ionship between the elements of  the PARiHS framework and linked 
theories and models. (based  on Ostrom's typology).
Conceptual Framework Theory Model
Definition Identifies a set of variables and 
relationships that should be examined in order to understand the 
phenomenonProvides a more dense and logically 
coherent set of relationships and 
offers views (hypotheses) on the 
causal relationships and seeks to 
explain the phenomenaRepresents a specific situation; is 
narrower in scope and more precise in its assumptions
Dimensions EVIDENCE
Sub-elementsResearchClinical ExperiencePatientExperience
Routine DataEvidence
Evidence is a broad term comprising 4 key elements : research, clinical experience, patient preferences and routine informationMelding and implem enting evidence 
involves negotiating and developing 
shared understandings It is a dialectical processWhat theories would inform the way 
evidence has been conceptualised within the PARiHS framework? E.g. How would decision making theory or clinical reasoning or cognitive theory 
inform/influence/alter the way we 
would try to make sense of how 
practitioners at clinical level adopt and value a new innovation?Would we classify guideline 
implementation as one model to be tested within the wider clinical reasoning/knowledge generation theoretical tradition?Are the use of patient narratives, or 
audit and feedback more examples of 
models that can test the broader theoretical position s that inform the 
conceptual framework?
Context
Sub-elementsContextCulture
Leadership EvaluationContext
Comprises 4 broad areas:Context, culture, leadership and evaluation
Some contexts are more conducive to 
the introduction of new ideas/innovations.It is the interplay of the elements and sub-elements that make 
implementation easier or more 
difficultBig complex area operating at multiple levels.Important to be able to see the whole picture when changing practiceThe theoretical base of understanding 
organisations, contexts, cultures and innovation is diverse, multifaceted and very complex.
What criteria would you use to select 
the more appropriate theories that would elucidate how the elements of the PARiHS framework interact?How can theories be integrative in 
order to explain the realities of real 
world implementation?How wouldTesting different learning styles and 
experimenting with a variety of leadership roles and styles could be part of the range of interventions or 
models used.
Selecting one lead ership approach 
within leadership theory in general would be part of the multiple models and theories being tested within the 
framework
Facilitation
Sub-elements
Purpose,
RoleSkills and AttributesFacilitation
Broad term describing the human 
support, guidance, learning, coaching 
offered by a trained facilitator when initial diagnosis of the "readiness" of the individuals, team  and context for 
the introduction of the innovationThe purpose can be  technical e.g. 
introducing a discrete method or 
"holistic" sustaining and enabling personal developm ent and system 
transformationMethod contingent on diagnosis of individual/team understanding/
acceptance of evidence and 
receptiveness for change of contextFacilitation has a st rong theoretical 
base in humanistic psychology, 
psychoanalytic group theory and adult 
learning theory. Therapeutic client-
centred approaches, experiential learning and self-e fficacy theory also 
contribute to our overall understanding.
The question again remains how 
researchers and practitioners make sense of these underlying theories to help them construc t way of changing 
practice.Constructing a particular programme 
or mentoring experience, based on 
psychoanalytic theory will be different 
from an approach based on adult learning.Facilitation models can range from 
"doing for others" to "enabling 
others".
Doing for others covers episodic contact offering practical help using external change agents.Enabling others focuses more on sustaining partnersh ips, developing 
individual potential and encouraging 
self directed learningDoing for would use the following:Project management techniques, technical, marketing skillsEnabling others would select methods 
around co-couns elling, clinical 
reflection, action learning.
Implementation Science  2008, 3:1 http://www.implementatio nscience.com/content/3/1/1
Page 8 of 12
(page number not for citation purposes)line with more traditional scientific thinking and the
search for understanding causation [21,22]. Looking to
other methodologies that are less concerned with causa-tion and more focused on explanatory understanding andaction (such as realist evaluation) [33] may limit reduc-tionism, and provide enlightening findings about theinteractions and complexities involved in knowledge
translation activity [23]. However, we still need to be
mindful of the relationship between the theory and thesubsequent methodology and consider their fit with eachother and with philosophical perspectives.
An additional set of definitional challenges that Sabatier
and Ostrom's typology raises is their definition of models.
Ostrom describes models as precise assumptions about alimited set of parameters and variables [31]. Logic, exper-imentation, and a variety of simulations can be used toexplore systematically the consequences of these assump-tions in a limited set of outcomes. Multiple models arecompatible with most theories and frameworks.
So, for example, in this typology, we could set up an
experiment that would test the model of audit and feed-back as a precise intervention. The theoretical underpin-ning of the model could be decision theory or learningorganisation theory, both embedded within the bigger
conceptual framework of evidence, context, and facilita-
tion. The challenge then is to draw sufficiently cogent par-adigmatic boundaries around the framework so that itdoes not become a catchall of ideas and conjectures. Howwe do this is where the real scientific discipline comes intofocus and where logical coherence and consistency of
terms and relationships are set out for scrutiny, and it is
where causal processes seek to explain how certain pat-terns of phenomena have come about. And, of course, thisrequires the ability to measure the variables under scru-tiny. Our deliberations over the years as to how we movethe PARiHS framework from a conceptual artefact to
becoming a measure of knowledge translation has led us
down the path of whether we have to disaggregate the ele-ments because there is no conceptual coherence orwhether we dissect the elements in different ways. Thenotion that the framework becomes a diagnostic and eval-uative measure on the evidence and context axes andinforms the facilitation or intervention process has been
an important development.
From conceptual framework to measurement and 
evaluation
Estabrooks et al. have outlined the challenges of measur-
ing knowledge utilisation in health care [36]. These
include a lack of underpinning theory, construct clarity,
measurement theory, psychometric assessment, and a pre-sumption of linearity. Additionally Rich claimed thatthere tends to be a bias to measure things that are easy tocapture [37]. These measurement challenges reflect the
general complexity of research implementation. As
described above, the purpose of the PARiHS framework isto provide a map to enable others to make sense of thiscomplexity, and the elements that require attention ifimplementation is more likely to be successful. The nextstep is to consider whether the PARiHS conceptual frame-
work lends itself to guiding the development of diagnostic
and evaluative approaches and instruments, which couldbe used by both researchers and practitioners. Our emerg-ing hypothesis is that the PARiHS framework will guidemeasurement development, and there is growing evi-dence to support this [10-14]. Given that more theoretical
work needs to be conducted on the PARiHS framework,
these ideas are at an early stage.
To this end, a briefing summary – PARiHS Framework:
stages of refinement – [See Additional File 1] shows some
draft questions, which may begin to facilitate the identifi-cation of those elements within 'evidence' and 'context'
that require development work, and active intervention(s)
('facilitation') to be successfully introduced within spe-cific implementation projects. The questions developed inthe tool could enable individuals and teams to test theirappreciation and understanding of evidence, context andfacilitation. For example, using the four sub-elements of
'evidence', the tool enables the development of a better
understanding of assumptions and perceptions about theresearch base, how this conflicts with and/or supportsclinical experience, professional judgement, and patientpreferences, and whether routine information is suffi-ciently robust to be able to offer data on current practices
as well as what needs to change. Similarly, the questions
about 'context' encourage an evaluation of the prepared-ness of the context to embrace and sustain implementa-tion. These questions could be answered individuallyand/or through a facilitated dialogue where each teammembers' assumptions, prejudices, views about existing
practice, and the proposed change are discussed and
debated. Through this process the team would come to anagreed ranking of the 'readiness' of the team to embracethe new practice, evidence, or innovation.
We suggest one way of testing this state of readiness is to
aggregate responses to the questions, and then translate
them onto a grid that plots the position the team judges
themselves to be in before they embark upon the imple-mentation process. An example of this is presented in Fig-ure 1 – The PARiHS diagnostic and evaluative grid . At this
stage, the location on the grid enables an assessment ofthe type of facilitation support that would most effectively
lead to the successful implementation of evidence, likely
requiring changes in behaviour and working patterns. Thediagnosis identifies the position of the team. The trajecto-
Implementation Science  2008, 3:1 http://www.implementatio nscience.com/content/3/1/1
Page 9 of 12
(page number not for citation purposes)ries in Figure 1 illustrate examples of three possible posi-
tions:
1. F1 = facilitation method for transforming weak context
and strong evidence into a highly receptive context
2. F2 = facilitation method to manage weak context and
weak evidence situation – most challenging and possibly
involves issues of safety, basic competence needs to be
managed
3. F3 = facilitation method to manage strong context and
weak evidence situation – issues of routine and power
involved
Whilst it is likely that many sources of information will be
required to decide on an appropriate course of action, the
diagnostic score may provide an indication of the starting
point. Facilitation, as the intervention, can then combine
a range of approaches ranging from task focused ( e.g.,
project management, resource identification) to more
enabling processes ( e.g., personal development, action
learning). The role of the facilitator then is concerned with
assessment of the situation, assessment of individual,
team and workplace readiness, development of change
and evaluation strategies, support of the implementation
process, and coaching and mentoring the team though the
change.
The final task is to evaluate and check whether the self-
assessment scores have migrated further towards the top
right hand quadrant. By considering the evaluation ques-tions, both individuals and teams can evaluate their
implementation efforts. These could be administered as
both process and summative evaluation opportunities,
and progress mapped.
Using PARiHS as the basis for a tool may shift thinking
away from conventional, arguably narrow, notions of
measurement to more wide ranging and eclectic
approaches to evaluation. Given that we predict so much
variation in appreciation of evidence and context, the way
to test the measurement tool has to accommodate variety
and multiple interpretations. Similar messages are com-
ing through from other research teams [15,18,20]. This is
why we wish to set up networks of researchers and practi-
tioners who are willing to work together to test out these
assumptions and ideas.
Facilitation as an intervention
The concept of facilitation, defined as "a technique by
which one person makes things easier for others", contin-
ues to be central to the PARiHS framework [6]. Facilita-
tion is part of a range of roles that have been reviewed in
the literature [38,39] which tend to demonstrate that
effective implementation of knowledge into practice is a
multifaceted process, requires flexibility, and has more to
do with the ability to combine a range of different tech-
niques than rigidly prescribing a discrete intervention.
From Harvey et al. 's concept analysis the following posi-
tions have emerged [6]:
1. Facilitation is a process that depends upon the person
(the facilitator) carrying out the role with the appropriate
skills, personal attributes, and knowledge
2. The purpose of facilitation varies from providing help
and support to achieve a goal to enabling individuals and
teams to analyse, reflect, and change their own attitudes,
behaviours, and ways of working.
3. A "facilitation continuum" has been described, which
distinguishes between a "doing for others" role (more dis-
crete, practical, technical and task driven) on the one side
to an "enabling and empowering" role which is more
developmental, seeking to mentor, guide and support the
staff within the system to take control of their own learn-
ing and change processes.
4. Facilitation skills are developed through experiential
learning [40], and more recently through the acquisition
of key facilitation competencies [41].
5. Facilitation as a discrete intervention has been
described in the practice development movement in nurs-
ing [42-44] and in the quality improvement literature
[34].The PARiHS Diagnostic and Evaluative Grid Figure 1
The PARiHS Diagnostic and Evaluative Grid.

Implementation Science  2008, 3:1 http://www.implementatio nscience.com/content/3/1/1
Page 10 of 12
(page number not for citation purposes)As a key dimension of the PARiHS framework, facilitation
needs to be further refined and tested. Our deliberations
have led us to propose that facilitation will be more effec-tive following a diagnosis of the context (C) into whichthe new knowledge is being introduced and an assessmentof practitioners' understanding of and acceptance of theevidence/new knowledge itself (E). The diagnostic should
provide data to determine the most appropriate facilita-
tion approach – which, consistent with the evidence,should lead to a multi-faceted, flexible, tailor-made inter-vention being constructed. Information on individual andteams' understanding of and receptiveness to the new evi-dence will help determine how much new learning and
change is needed. An assessment of the readiness for
change from a contextual perspective will cover the PAR-iHS framework sub- elements of context, culture, leader-ship, and evaluation [11,14].
The role of the appropriately prepared facilitator, along
with the team(s) they are working with, is to construct a
programme of change that meets the individual and
team's learning needs. The actual ingredients making upthis intervention could draw from a whole range of meth-ods – from very task based, planned change programmeapproaches to much more experiential, action learningapproaches.
What we are proposing is consistent with the early obser-
vations of Havelock and colleagues, where they argued forgreater alignment or linkage between those who generateand implement new evidence and those who are expectedto be involved in its application [16]. Equally, Van de Ven
and colleagues' work on the management of innovation
demonstrates the importance of flexibility and skilledsupport in achieving successful implementation through-out the length of the implementation process [45]. Also,Greenhalgh et al. recommend much greater involvement
of practitioners in determining the nature of interventions
at local level [18], a perspective that is consistent with the
emerging interest in such theoretical perspectives as real-istic synthesis [46]. In this interpretivist approach, theresearch interest in interventions is not so much abouttheir generalisability and standardisation but more aboutunderstanding the mechanisms that connect events in away that changes them (either in the desired direction or
in an unexpected way) within a particular context involv-
ing particular participants.
What are the next practical steps for developing a series of
studies that would begin to test the hypotheses outlinedabove? First obvious steps are to refine the diagnostic
process and associated measures, and the second step is to
agree the content of a facilitation training programme thatwould equip appropriately (and consistently) trainedfacilitators to work with a number of practice areas wish-
ing to engage in knowledge translation activities.
We argue that more careful theoretical work, modelling,
and testing of the concept of facilitation is requiredbecause it is the process by which individuals and teamsfirst interact and engage with evidence (either as guide-
lines, research reports, or any new innovation entering the
system) and then try to negotiate its adoption/acceptanceinto their organisation.
These conclusions would lead one to surmise that the
future direction of travel will be around the development
of much more complex and bespoke interventions that fit
local contexts. Whether this is different from what thePARiHS framework terms "facilitation" is an appropriatequestion to ask.
Concluding remarks
There is a small, but growing body of evidence from
research and practice that shows the PARiHS framework
has conceptual integrity, face and concept validity.
However, there are major challenges ahead if the frame-
work is to help in the systematic exploration of these com-plexities around the art and science of implementation.
The three challenges outlined include the need to inte-
grate theoretical perspectives into the framework in a waythat enables us to make sense of the complexities and toconstruct appropriate models to explore what works inknowledge translation. PARiHS was developed induc-
tively, which points to an interpretive lens on theory
application and development. However, using Ostrom'shelpful analytical approach it may be more helpful tobegin to see the framework as being populated by varioustheoretical positions, which some would view as strength,some as a weakness. These issues have yet to be debated in
the knowledge translation literature generally, and in rela-
tion to the PARiHS framework specifically.
A second area of investigation is the development and
testing of diagnostic and evaluative methodologies andassociated instruments based on the elements and sub-elements of the PARiHS framework. What seems to be
emerging is the need for a high level set of principles (con-
ceptual framework) that can help people on the groundunderstand what they can do. The principles can offer aframework within which a number of approaches orattempts at implementation and evaluation of the effec-tiveness of the intervention can be made by both the play-
ers on the ground and any researchers involved with
them.
Implementation Science  2008, 3:1 http://www.implementatio nscience.com/content/3/1/1
Page 11 of 12
(page number not for citation purposes)Thus, it would seem that the current knowledge base
around successful implementation of innovations into
practice emphasises processes of engaging local practi-tioners as well as outlining a set of key principles that helpguide the activity.
Whilst there are some studies underway [32], to date there
have been few, if any, systematic investigations of facilita-
tion as an intervention. We believe that much more con-ceptual clarification is needed before the science around itcan improve. Equally, the arguments put forward here,that future implementation tools ought to have both diag-nostic and evaluative properties also need to be tested.
Our proposal to create communities of researchers, prac-
titioners, and other stakeholders undertaking pieces ofwork to test the whole framework is presented as a way ofmoving the agenda forward. We see the need for this col-laborative approach, not only between researchers butalso between research teams and those practitioners at thelocal level who actually have the task of implementing
evidence into practice. This need for greater alignment of
these two groups has been reinforced by Greenhalgh et
al.'s work [18], where they broaden out the notion of
implementation of evidence to include innovations ingeneral and by practice development researchers [46]. Wealso note the semantic and conceptual shift in the dis-
course and seminal work of Van de Ven and colleagues
[47] who had, two decades earlier, tried to measure thesevery same complexities. Their elegantly designed studiescould help us to construct more appropriate studies thattake account of the multiple elements at work.
Lastly, we suggested the analogy of a chess game as a way
of trying to understand the task in hand. We have a boardin front of us (metaphorically speaking) with game pieces(PARiHS elements and sub-elements) whose moves weneed to test. Once we know what these pieces do, we canset up the games, i.e. the particular interventions, to see
what happens. Our research endeavours will, if we are
lucky, be able to produce guiding principles for the movesthat practitioners can use to successfully implementresearch into practice. However, we acknowledge the sig-nificant work that practitioners will always have to do totransform the principles into effective actions in their ownworkplaces.
Summary
1. The PARiHS framework is a useful practical and concep-tual heuristic for research implementation but it remainslargely untested, hence there is not an evidence base todiscount or refine it.
2. The paper summarises the conceptual and theoretical
thinking around the use of the framework, inviting col-leagues who have or are using it to comment on its utility
and effectiveness.
3. The first stages of developing diagnostic and evaluative
methodologies based on the framework are presented.
4. Alternative perspectives for thinking about theory use
and development are offered.
An implementation science collaborative, working on var-
ious elements of the framework is proposed to acceleratethe production and testing of its evidence base.
Competing interests
The author(s) declare that they have no competing inter-ests.
Authors' contributions
ALK is the lead author and co-ordinator of the paper. JR-M co-wrote and re-drafted the paper. GH, BM, KS, and AT
offered ideas contained within the paper, commenting on
drafts, reading and approving the final draft of the manu-script. All authors have contributed to the development ofthe PARiHS Framework, refined the different stages of itsdevelopment and are responsible for the further refiningand testing of the framework.
Additional material
Acknowledgements
Nina Monahan for drafting and formatting earlier versions of the paper.
References
1. Grandos A, Jonsson E, Banta HD, Be ro L, Bonari A, Cochet C, Free-
mantle N, Grilli R, Grimshaw J, Harvey E, Levi R, Marshall D, OxmanA, Pasart L, Raisanen V, Rius E, Espinas JA: EUR-ASSESS Project
Subgroup Report on Dissemination and Impact.   International
Journal of Technology Assessment in Health Care  1997, 13(2): 220-86.
2. Grimshaw J, Eccles M, Tetroe J: Implementing Clinical Guide-
lines: Current Evidence a nd Future Implications.   Journal of
Continuing Educ Health Prof  2004, 24:S31-S37.
3. Dopson S, Fitzgerald L, (Eds): Knowledge to Action? Evidence-based
health care in context  Oxford: Oxford University Press; 2005. 
4. Kitson A, Harvey G, McCormack B: Enabling the implementa-
tion of evidence-based prac tice: a conceptual framework.
Quality in Health Care  1998, 7(3): 149-158.
5. Rycroft-Malone J, Kitson A, Harvey G, McCormack B, Seers K,
Titchen A, Eastbrooks C: Ingredients for Change: Revisiting a
conceptual model.   Qual. Saf. Health Care  2002, 11:174-180.
6. Harvey G, Loftus-Hills A, Rycroft-Malone J, Titchen A, Kitson A,
McCormack B, Seers K: Getting evidence into practice: TheAdditional file 1
PARiHS Framework: St ages of Refinement . A table outlining the devel-
opment of the diagnostic  and evaluative measures
Click here for file
[http://www.biomedcentral.co m/content/supplementary/1748-
5908-3-1-S1.doc]
Publish with BioMed Central   and  every 
scientist can read your work free of charge
"BioMed Central will be the most significant development for 
disseminating the results of biomedical research in our lifetime."
Sir Paul Nurse, Cancer Research UK
Your research papers will be:
available free of charge to the entire biomedical community
peer reviewed and published immediately upon acceptance
cited in PubMed and archived on PubMed Central 
yours — you keep the copyright
Submit your manuscript here:
http://www.biomedcentral.com/info/publishing_adv.aspBioMed centralImplementation Science  2008, 3:1 http://www.implementatio nscience.com/content/3/1/1
Page 12 of 12
(page number not for citation purposes)role and function of facilitation.   Journal of Advanced Nursing  2002,
37(6): 577-588.
7. McCormack B, Kitson A, Hervey G, Rycroft-Malone J, Titchen A,
Seers K: Getting Evidence into Prac tice: The Meaning of Con-
text.   J. Adv. Nurs  2002, 38:94-104.
8. Rycroft-Malone J, Harvey G, Seers K, Kitson A, McCormack B,
Titchen A: An exploration of the factors that influence the
implementation of ev idence into practice.   Journal of Clinical
Nursing  2004, 13:913-924.
9. Rycroft-Malone J, Seers K, Titchen A, Harvey G, Kitson A, McCor-
mack B: What counts as evidence in evidence-based practice?
Journal of Advanced Nursing  2004, 47(1): 81-90.
10. Meijers JM, Janssen MAP, Cummings GG, Wallin L, Estabrooks CA,
Halfens RYG: Assessing the relationsh ips between contextual
factors and research utilization in nursing: a systematic liter-
ature review.   Journal of Advanced Nursing  2006, 55:622-635.
11. Wallin L, Estabrooks CA, Midodzi WK, Cummings GG: Develop-
ment and validation of a derived measure of research utiliza-
tion by nurses.   Nursing Research  2006, 55(3): 149-160.
12. Ellis I, Howard P, Larson A, Robertson J: From workshop to work
practice: An exploration of context and facilitation in the
development of eviden ce-based practice.   Worldviews on Evi-
dence-Based Nursing  2005, 2(2): 84-93.
13. Brown D, McCormack B: Developing postoperative pain man-
agement: Utilising the Promoti ng Action on Research
Implementation in Health Services (PARIHS) framework.Worldviews on Evidence-Based Nursing  2005, 2(3): 131-141.
14. Wright J, McCormack B, Coffey A, McCarthy G, Slater P: Evaluating
the context within which cont inence care is provided in
rehabilitation units for older people.   International Journal of Older
People Nursing  2007:1.
15. Graham ID, Logan J, Harrison MB, Straus S, Tetroe J, Caswell W,
Robinson N: Lost in Translation: Time for a Map?   The Journal of
Continuing Education in the Health Professions  2006, 26(1): 3-24.
16. Havelock RG: Planning for Innovation thro ugh Dissemination and Utilisa-
tion of Knowledge  Ann Arbor, MI: Center for Research on Utilisation
of Scientific Knowledge; 1969. 
17. Rogers EM: Diffusion of Innovations  5th edition. New York: Free Press;
2003. 
18. Greenhalgh T, Robert G, McFarlane F, Bate P, Kyriakidou O: Diffu-
sion of Innovations in Serv ice Organisations: Systematic
Review and Recommendations.   The Millbank Quarterly  2004,
82(4): 581-629.
19. Tiffany C: Analysis of planned change theories.   Nurse Manage
1994, 25:54-59.
20. Estabrooks CA, Thompson DS, Lovely JE, Hofmeyer A: A Guide to
Knowledge Translation Theory.   The Journal of Continuing Educa-
tion in the Health Professions  2006, 26(1): 25-36.
21. ICEBeRG Group: Designing theoretically-informed implemen-
tation interventions.   Implementation Science  2006, 1:4: [http://
www.implementationscience.com/content/1/1/4 ].
22. Eccles M, Grimshaw J, Walker A, Johnston M, Pitts N: Changing the
behaviour of healthcare profe ssionals: the use of theory in
promoting the uptake of  research findings.   Journal of Clinical
Epidemiology  2005, 58:107-112.
23. Rycroft-Malone J: Theory and knowledge translation: Setting
some co-ordinates?   Nursing Research  56(4, S1): 578-585.
24. Mittman BS, Tonesk X, Jacobson PD: Implementing clinical prac-
tice guidelines: Social influe nce strategies and practitioner
behaviour change.   QRB Qual Rev Bull  1992, 18:413-422.
25. Logan J, Harrison MB, Graham  I, Dunn K, Bissonette J: Evidence-
based pressure ulcer practice: The Ottawa Model ofResearch Use.   Can J Nurs Res  1999, 31:37-52.
26. Stetler CB: Updating the Stetler Mode l of research utilisation
to facilitate evidence-based practice.   Nurs Outlook  2001,
49:272-279.
27. Titler MG, Kleiber C, Steelman VJ,  et al. : The Iowa Model of Evi-
dence Based Practice to promote quality care.   Crit. Care Nurse
Clin North Am  2001, 13:497-509.
28. Prochaska JO, Velicer WF: The transtheoretical model of health
behaviour change.   Am J Health Promot  1997, 12:38-48.
29. Sabatier PA: Theories of the Policy Process  Colorado: Westview Press;
1999. 
30. Ostrom E: An agenda for the study of Institutions.   Public Choice
1986, 48:3-25.31. Ostrom E: Institutional Rational Choice: An Assessment of
the Institutional Analysis and Development Framework.   In
Theories of the Policy Process  Edited by: Sabatier PA. Colorado: West-
view Press; 1999. 
32. Kuhn TS: The Structure of Scie ntific Revolutions  Chicago: University of
Chicago Press; 1970. 
33. Pawson R, Greenhalgh T, Harvey G, Walshe K: Realist Review – a
new method of systematic review designed for complex pol-
icy interventions.   J Health Serv Res Policy  2005, 10:1: 21-34.
34. Stetler CB, Legro M, Rycroft-Malone J: The key role of "facilita-
tion" in the implementation of  research findings: a qualita-
tive evaluation of facilitatio n experiences in the Veterans
Health Administration.   Implementation Science  2006, 1:23:  [http:/
/www.implementationscience.com/content/1/1/23 ].
35. Milner M, Estabrooks CA, Myrisk F: Research utilization and clin-
ical nurse educators: a systematic review.   Journal of Evaluation
in Clinical Practice  2006, 12(6): 639-655.
36. Estabrooks CA, Wallin L, Milner M: Measuring knowledge utiliza-
tion in health care.   International Journal of Policy Evaluation & Man-
agement  2003, 1(1): 3-36.
37. Rich RF: Measuring knowledge utilization processes and out-
comes.   Knowledge and Policy: International Journal of Knowledge Trans-
fer and Utilization  1997, 3:11-24.
38. Oxman A: No Magic Bullets: A Systematic Review of 102 Tri-
als of Interventions to help Ca re Professionals Deliver Serv-
ices More Effectively and Efficiently.   North East Thames Regional
Health Authority. London  1994.
39. Bero LA, Grilli R, Grimshaw JM , Harvey E, Oxman AD, Thompson
AT: Closing the gap between research and practice: an over-
view of systematic reviews of interventions to promote the
implementation of research findings.   British Medical Journal
1998, 317:465-468.
40. Loftus-Hills A, Harvey G: A review of the role of the facilitator in changing
professional healthcare practice  RCN Institute. Oxford; 2000. 
41. Royal College of Nursing: Becoming an RCN Ac credited Facilitator  Royal
College of Nursing. London; 2004. 
42. Titchen A, McGinley M: Facilitating practi tioner-research
through critical companionship.   NTResearch  2003,
8(2): 115-131.
43. McCormack B, Manley K, Garbett R: Practice Developm ent in Nursing
Oxford: Blackwell Publishing; 2004. 
44. Titchen A, Manley K: Spiralling towards transformational
action research: philosophic al and practical journeys.   Educa-
tional Action Research: an International Journal  2006, 14(3): 333-356.
45. Van de Ven AH, Polley DE, Garud R, Venkataraman S: The Innovation
Journey  Oxford University Press Oxford; 1999. 
46. Manley K, Hardy S, Titchen A, Garbett R, McCormack B: Changing
Patients' Worlds through Nursing Practice Expertise: A Research Report
London: Royal College of Nursing; 2005. 
47. Van de Ven AH, Angle HL, Poole MS: Research on the Management of
Innovation  Oxford: Oxford University Press; 2000. 
