Implementation
ScienceHanbury et al.  Implementation Science  2010, 5:37
http://www.implementationsc ience.com/content/5/1/37
Open Access STUDY PROTOCOL
BioMed CentralÂ© 2010 Hanbury et al; licensee BioMed Central Ltd. This is an Open Access article distributed under the terms of the Creative C ommons
Attribution License (http://creativecommons.org/licenses/by/2.0), which permits unrestri cted use, distributi on, and reproductio n in
any medium, provided the original work is properly cited.Study protocolTranslating research into practice in Leeds and 
Bradford (TRiPLaB): a protocol for a programme of 
research
Andria Hanbury1, Carl Thompson1, Paul M Wilson*2, Kate Farley1, Duncan Chambers2, Erica Warren3, John Bibby3, 
Russell Mannion4, Ian S Watt1 and Simon Gilbody1
Abstract
Background: The National Institute for Health Research (NIHR) has funded nine Collaborations for Leadership in 
Applied Health Research and Care (CLAHRCs). Each CLAHRC  is a partnership between hi gher education institutions 
(HEIs) and the NHS in nine UK regional health economies. The CLAHRC for Leeds, York, and Bradford comprises two 'research themes' and three 'implementation themes.' One of  these implementation themes is Translating Research 
into Practice in Leeds and Bradford (TRiPLaB). TRiPLaB aims  to develop, implement, and evaluate methods for inducing 
and sustaining the uptake of research knowledge into practice in order to improve the quality of health services for the people of Leeds and Bradford.
Methods: TRiPLaB is built around a three-stage, sequential, approach using separate, longitudinal case studies 
conducted with collaborating NHS organisations, TRiPLaB wi ll select robust innovation s to implement, conduct a 
theory-informed exploration of the local context using a variety of data collection and analytic methods, and 
synthesise the information collected to identify the key factors influencing the uptake and adoption of targeted 
innovations. This synthesis will inform the development of tailored, multifaceted, interventions designed to increase 
the translation of research findings into practice. Mixed research methods, including time series analysis, quasi-
experimental comparison, and qualitative process evaluation, will be used to evaluate the impact of the implementation strategies deployed.
Conclusion: TRiPLaB is a theory-informed, system atic, mixed methods approach to developing and evaluating tailored 
implementation strategies aimed at increa sing the translation of research-based fi ndings into practice in one UK health 
economy. Through active collaboration with its local NHS, TRiP LaB aims to improve the quality of health services for the 
people of Leeds and Bradford and to contribute to resear ch knowledge regarding the interaction between context and 
adoption behaviour in health services.
Background
In response to the recommendation of the Chief Medical
Officer's Clinical Effectiv eness Group that the NHS
should better utilise higher education to support initia-tives to enhance the effectiveness and efficiency of clini-cal care [1], the National Institute for Health Research(NIHR) announced a strategy of increasing partnershipsbetween higher education and the NHS in local healtheconomies. One means of developing these partnershipsis Collaborations in Leadership and Applied Health
Research and Care or CLAHRCs. The NIHR has fundednine CLAHRCs, each with an emphasis on research thatmakes an impact locally and with a strong, disciplined,and strategic approach to implementing that research.The NIHR CLAHRC for Leeds, York and Bradford(LYBRA) comprises two 'research' programmes (Improv-ing Vascular Prevention in Cardiac and Stroke Care(IMPROVE-PC), Improving the Quantity and Quality ofLife in People with Addictions) and three 'implementa-tion' programmes (Outcome Driven Stroke Care, Mater-nal and Child Health, and the focus of this protocol,
* Correspondence: pmw7@york.ac.uk
2 Centre for Reviews and Dissemination, University of York, York, YO10 5DD, UK
Full list of author information is available at the end of the article
Hanbury et al.  Implementation Science  2010, 5:37
http://www.implementationsc ience.com/content/5/1/37Page 2 of 6
Translating Research into Prac tice in Leeds and Bradford,
or TRiPLaB).
The aim of TRiPLaB is to develop, implement, and
evaluate methods of inducing and sustaining the uptakeof research into practice in order to improve the qualityof health services for the people of Leeds and Bradford.Research implementation is a complex process, highlydependent on context, and interactions between multi-ple, interconnected, factors at the level of individuals,groups, organisations and wider health systems [2-6].Despite this complexity, or perhaps because of it, imple-mentation research has often focused on individualbehaviour change without reflecting on, or paying atten-tion to, the characteristics of health technologies, theprocesses by which health technologies are adopted andsustained, or a workable understanding of the particularcontext in which implementation occurs [7].
Successive reviews of the evid ence for successful trans-
lation of research findings into healthcare practice revealthat a range of implementation strategies can be success-ful. However, why strategies work in some circumstancesbut not others remains unclear [3,6,8].
Using theory to guide the exploration of the local con-
text for implementation can help [6]. First, relevant theo-ries enable the tailoring of strategies to the mostsignificant barriers to translat ing research into practice in
a given context. Second, theories enable researchers tobuild on existing knowledge and increase the transferabil-ity of findings to settings and contexts other than theimmediate research environment [9].
TRiPLaB will use theory to guide its exploration of con-
text in our collaborating healthcare organisations. Thisexploration will in turn inform the development of tai-lored implementation strategies for innovation delivery.The synthesis of research findings by Greenhalgh et al .
[5] on the dissemination and implementation of research-based innovations provides the theoretical framework forTRiPLaB. Their analysis proposes that successful innova-tion adoption requires analysis of the characteristics ofthe innovation itself, the perceptions of those individualstasked with adopting the innovation, and the widerorganisational cultures in place in the setting for adop-tion. Shaped by diffusion of innovation theory [10],Greenhalgh et al . also acknowledge the influence of chan-
nels of communication, or social networks, betweenpractitioners as important influences on whether, andhow quickly, an innovation is adopted. In adopting thisparticular theoretical framework, TRiPLaB will explorethe relative influence of these often overlooked butimportant elements at individual, team and organisa-tional levels in our NHS partners [2-6]. This theory-informed exploration will form our 'diagnostic analysis'[3] of the local context in each of the NHS healthcareorganisations that make up our case study series.Methods
Ethical approval for this study was given by YorkResearch Ethics Committee (REC 10/H1311/1).
The Develop, IMplement, Evaluate (DIME) approach of 
TRiPLaB
TRiPLaB is a multisite, longitudinal, mixed methods case
study. Currently, we are working with NHS Bradford andAiredale (an NHS commissioning and community pro-vider organisation) to translate research-based findingsinto practice in the areas of maternal mental health andstroke care, and with Leeds Partnership Foundation Trust(a provider of mental health services) to enhance theimplementation of recent and relevant NICE guidance.
Each case study will have three sequential phases (see
Figure 1): the findings from the development phase(phase one) lead into the implementation phase (phasetwo), and the outcomes of this are assessed in the evalua-tion phase (phase three). The three-phase approach hasbeen informed by the Medical Research Council's frame-work [11] for developing and evaluating complex inter-ventions, acknowledges the need to use theory inplanning and analysis, recognises the importance of localcontext, piloting, and evaluating intervention compo-nents, and the use of multiple outcome measures to eval-uate intervention effectiveness. The three phases aresummarised below.
Phase one is a development phase in which the innova-
tion that is the focus of each case study will be selectedand its key characteristics mapped. Theory-informed fac-tors hypothesised as influential in health professionals'adoption of the selected innovation into routine practiceare explored and mapped.
Phase two is an implementation phase in which tailored
behaviour-change interventions are developed pilotedand delivered using personnel from TRiPLaB and itspartner organisations.
Phase Three is an evaluation phase in which changes in
structure, process, and outcome are described and evalu-a t e d .  W e  w i l l  b e  l o o k i n g  a t  c h a n g e  b o t h  w i t h i n  a n d ,towards the end of the programme, between case studies.
TRiPLaB will use the resources of the Centre for
Reviews and Dissemination (CRD) to increase the acces-sibility of research evidence to decision makers (particu-larly commissioners) in the NHS. Primarily, we will dothis by using tailored briefings relating research evidenceto specific decision problems and context in Bradford andLeeds. These 'evidence briefings' will be based on existingsources of synthesised and quality assessed evidence - forexample, CRD's databases of systematic reviews (DARE)and economic evaluations (NHS EED). We will developand implement methods for producing and disseminatingevidence briefings and evaluate their perceived useful-ness, costs, and use by decision makers.
Hanbury et al.  Implementation Science  2010, 5:37
http://www.implementationsc ience.com/content/5/1/37Page 3 of 6
Development phase (phase one)
Selecting the innovation
At the start of each case study, the specific innovation to
be targeted will be selected. The selection will be based
on the results of: a qualitative stakeholder consultation
designed to identify key topics; a conjoint analysis survey
of commissioners and practitioners designed to explore
those characteristics of innovations likely to influence
individuals' prioritisation of them; and a mapping exer-
cise exploring how each of the stakeholder short-listed
topics 'scores' against the characteristics measured in the
conjoint analysis survey (for example, local capacity and
expertise for implementation, cost/impact on local bud-
gets). We will also consider pragmatic issues, such as the
presence or absence of routine data sources to aid the
measurement of innovation adoption.
Stakeholder consultations will focus on identifying key
topics in the relevant clinical area. For example, in NHS
Bradford and Airedale, stakeh older consultation in the
area of child and maternal health care with a range of
commissioners and practitioners revealed the impor-
tance of maternal mental health as a focus for activity.
The conjoint survey will reveal the characteristics [6]
that influence an individual's decision to prioritise one
innovation over another. The factors that make up the
conjoint profiles to be evaluated will include characteris-t i c s  s u c h  a s  t h e  s t r e n g t h  o f  s u p p o r t i n g  e v i d e n c e  b a s e
behind an innovation and its economic costs. By conjoint
analysing the characteristics of potential innovations, we
will be able to 'plug in' future innovations and inform the
organisation's understanding the likelihood of successful
implementation. This has the obvious advantage of not
having to ask the healthcare workforce or consumers to
rank or rate innovations on multiple occasions. The con-
joint analysis also reduces the likelihood of the TRiPLaB
team targeting respondents (for example, as change
agents) who may not favour the innovation eventually
selected.
The mapping exercise will score short-listed innova-
tions against characteristics measured in the conjoint
analysis survey. For example, the strength of supporting
evidence base for each of the short listed innovations
from the stakeholder consultation will be explored
through reference to published systematic reviews. The
outcome of this process will be summarised in a matrix.
Finally, the pragmatic factors to be considered will
include whether suitable process of care and health out-
come measures are available through routinely collected
data to evaluate the impact of the implementation strate-
gies, or whether tailor-made, repeatable, audits have to be
established.Figure 1 The Develop, Implement, Evaluate model of TRiPLaB .
 
Hanbury et al.  Implementation Science  2010, 5:37
http://www.implementationsc ience.com/content/5/1/37Page 4 of 6
The selected innovation for each case study will be one
that has been identified as a key topic from the stake-holder consultation that scores highly on those character-i s t i c s  i d e n t i f i e d  f r o m  t h e  c o n j o i n t  a n a l y s i s  s u r v e y  a sinfluential in commissioners' and practitioners' prioritisa-tion of innovations, and can be monitored through tailor-made audits or, preferably, via routinely collected data. Insum, the combination of stakeholder consultation, theconjoint survey of practitioner and commissioner prefer-ences, and the mapping exercise will enable us to select arobust but feasible innovation to target in each case site.
Exploring the local context
Following selection of the innovation to be targeted, we
will undertake a diagnostic analysis [3] in which we willadminister a second survey in each case site to measurehealth professionals' attitudes towards the innovation,health care team innovation culture (using the Team Cli-mate Inventory [12]), and the social networks/communi-cation channels between health professionals withregards to the innovation. A series of semi-structuredinterviews will also be conducted with a sample of thehealth professionals to further explore perceived barriersto implementation, and to gain a richer understanding ofthe influence of health care teams and social networks inthe uptake and adoption of new innovations into practice.
Quantitative survey data will be synthesised using mul-
tilevel modelling (MLM) approaches to identify the hier-archical level most likely to be responsive to theimplementation strategies developed. For example, if theMLM identifies healthcare team culture to be particularlyinfluential, a multifaceted intervention specifically target-ing a team's culture towards innovation might ( a priori )
be more successful than an intervention targeting onlyindividual attitudes towards the innovation. This focus isdeliberate given the current dearth of implementationresearch examining the influence of factors at differenthierarchical levels in the health care system, and recom-mendations for further research in this area [13]. Thequalitative data collected from the semi-structured inter-views will be analysed using thematic analysis and com-bined with the outcome of the MLM to gain a richerunderstanding of the local context and to help tailor theimplementation strategies.
Implementation phase (phase two)
Development of the intervention will be systematic, spec-ifying intervention objectives, developing specific imple-mentation strategies to satisfy these objectives, andpiloting strategies to assess their likely impact and testh o w  t h e y  w i l l  b e  r e c e i v e d  b y  t h e  h e a l t h  p r o f e s s i o n a l s .This piloting and modelling prior to rolling out imple-mentation strategies/behaviour-change interventions is anecessary prerequisite stage [11]. The objectives anddesign of the intervention will be determined by the out-come of the development phase, in particular the results
of the planned multilevel modelling. The selection anddesign of the actual intervention components will beinformed by existing systematic, and other, reviews of therelevant literature.
Having decided on the innovation in phase one and
possible implementation strategies in phase two, we willmake the final choice on our implementation approachwith reference to the idea of 'policy' cost effectiveness[14]. Summary data on: the innovation from Phase One(net cost per patient and likely health gain per patient);the implementation strategies under consideration (netcost of planned implementation and likely change inadoption/adherence); and local scale factors (for example,the number of NHS organisational units involved andnumber of patients targeted) will be combined to arrive ata policy cost effectiveness figure for each option. Thecombination with the highest cost effectiveness will bethe option pursued.
The failure to adequately de scribe interventions in the
context of research and the commensurate reduction inothers' ability to then use successful programs -- or con-versely, avoid making the same mistakes as unsuccessfulones -- is common in healthcare research [15]. For eachof the case studies in the TRiPLaB program we willdescribe: the intervention and its component parts in suf-ficient detail that others could reproduce it; why the spe-cific intervention was chosen; and a fidelity measure ofhow well the intervention was delivered. For example, ifwe undertake educational outreach or training as a com-ponent of an intervention, we will detail how many ses-sions each unit of analysis receive, and when and wherethe training took place.
Evaluation phase (phase three)
Following the recommendation to conduct exploratorytrials prior to embarking on more definitive randomisedcontrolled trials [11], TRiPLa B will employ three different
methods to evaluate the impact of the tailored implemen-t a t i o n  s t r a t e g i e s  d e l i v e r e d  i n  e a c h  c a s e  s t u d y .  T h e  f i n d -ings from these evaluation measures will inform (ifworthwhile) later randomised controlled trials. The threemethods to be used are: interrupted time series analysisof either tailor-made audit data or routinely collecteddata to estimate the impact of the intervention upon suit-able process of care and outcome measures; comparisonof pre- and post-intervention scores of survey-gatheredmeasures of individual attitudes, team culture, andchanging nature, composition, and size of social net-works; and a qualitative process evaluation of why theintervention worked (or did not work).
Alongside these three primary evaluation methods we
will also collect cost data on the resources used in thedelivery of implementation approaches. The micro costs
Hanbury et al.  Implementation Science  2010, 5:37
http://www.implementationsc ience.com/content/5/1/37Page 5 of 6
[16] associated with each strategy will be estimated
alongside the extent of behavioural change achieved toarrive at summary estimates of implementation costeffectiveness [14] for each of the case studies in the pro-gramme.
Interrupted time series analysis
Interrupted time series designs compare multiple 'beforeand after' (the introduction of a change strategy) mea-sures to detect whether an intervention has had an effectover and above any underlying trend in the data [17].T i m e  s e r i e s  a n a l y s i s  h a s  b e e n  u s e d  a s  a  t e c h n i q u e  f o revaluating the effectiveness of health care interventions[18]. In the case studies, routinely collected process(health professionals' adoption of the innovation) andhealth outcome measures (dependent on the innovationselected) will provide the multiple time points necessaryto perform a time series analysis. Time, possible seasonaltrend, and possible upward trend, commonly occurringfollowing the introduction of a new innovation [10], willbe modelled into the analysis. This will be the primaryoutcome measure for each case study.
Comparison of pre- and post-intervention scores
The interrupted time series analysis will estimate theimpact of the intervention upon process of care andhealth outcome measures; however, a comparison of pre-and post-intervention scores is  also necessary to estimate
whether the intervention succ essfully changed the factors
(for example, individual attitudes, social networks andteam culture) in the underlying theoretical frameworkthat it was designed to target (based on the data synthesisthrough multilevel modelling in TRiPLaB's developmentphase in each site). This 'meditational analysis' [9] is criti-cal when evaluating the theory used to develop changeinterventions, as it will inform our understanding of whyan intervention either works or fails to work in the wayswe intended.
Qualitative process evaluation
Qualitative interviews with health professionals receivingthe intervention will enable an exploration of their per-ceptions of what worked and what did not work in theintervention, providing insight into the 'black box' ofintervention effectiveness [19]. In combination with themeasure of fidelity taken during the implementationphase, these qualitative interviews comprise a processevaluation of the intervention, addressing recommenda-tions to monitor intervention delivery and receipt by par-ticipants [11,20]. The data will be analysed using aframework approach [21]: familiarisation with the data,identification of a thematic framework, indexing, chart-ing, and finally, mapping and interpretation with refer-ence to the overall aim of TRiPLaB as well as the themesrevealed by the data.Conclusion
TRiPLaB is a theory-informed, systematic, mixed meth-ods approach to developing and evaluating tailoredimplementation strategies aimed at increasing the trans-lation of research findings into clinical and service prac-tice. TRiPLaB aims to play a part in improving the qualityof health services for the people of Leeds and Bradford.By working alongside multiple healthcare organisationsin a series of longitudinal case studies, the TRiPLaB pro-gramme will develop a richer understanding of key issuesinfluencing the adoption of innovations in the NHS andthe promotion of quality improvement in routine prac-tice.
Competing interests
The authors declare that they have no competing interests.
Authors' contributions
The programme protocol was originally developed by CT, PMW, RM, ISW, JB,and SG. The protocol was further develo ped by AH, KF, DC, and EW. All of the
authors contributed to the development and completion of the manuscript.All authors read and approved the final manuscript.
Acknowledgements
This article presents inde pendent research funded by the National Institute for 
Health Research (NIHR) through the Leeds York Bradford Collaboration for 
Leadership in Applied Health Research and Care. The views expressed in this 
publication are those of the authors and not necessarily those of the NHS, the NIHR or the Department of Health.
Author Details
1Department of Health Sciences, University of York, York, YO10 5DD UK, 
2Centre for Reviews and Dissemination, University of York, York, YO10 5DD, UK, 
3NHS Bradford and Airedale, Douglas Mill, Bradford, BD5 7JR, UK and 4Health 
Services Management Centre, Universi ty of Birmingham, Birmingham, B15 2RT, 
UK
References
1. Tooke JC: Report of the High Level Group on Clinical Effectiveness. A 
report to Sir Liam Donaldson Chief Medical Officer .  London: 
Department of Health; 2007. 
2. Lomas J: Retailing research: Increasing the role of evidence in clinical 
services for childbirth .  Milbank Quarterly  1993, 71:439-475.
3. Centre for Reviews and Dissemination: Getting evidence into practice .  
Effective Health Care  1999, 5:1.
4. Ferlie EB, Shortell SM: Improving the quality of health care in the United 
Kingdom and the United States: a framework for change .  Milbank 
Quarterly  2001, 79:281-315.
5. Greenhalgh T, Robert G, MacFarlane F, Bate P, Kyriakidou O: Diffusion of 
innovations in service organiza tions: systematic review and 
recommendations .  Milbank Quarterly  2004, 82:581-629.
6. Grimshaw JM, Thomas RE, MacLennan G, Fraser C, Ramsay CR, Vale L, 
Whitty P, Eccles MP, Matowe L, Shi rran L, Wensing M, Dijkstra R, 
Donaldson C: Effectiveness and efficiency of guideline dissemination 
and implementation strategies .  Health Technology Assess  2004, 8(6): iii-iv. 
1-72
7. Grol R, Grimshaw J: From best evidence to best practice: effective 
implementation of change in patients' care .  Lancet  2003, 
362: 1225-1230.
8. Oxman AD, Thomson MA, Davis DA, Haynes RB: No magic bullets: a 
systematic review of 102 trials of i nterventions to improve professional 
practice .  CMAJ  1995, 153: 1423-1431.Received: 18 March 2010 Accepted: 21 May 2010 
Published: 21 May 2010
This article is available from: http://www.implementationscience.com/content/5/1/37Â© 2010 Hanbury et al; licensee BioMed Central Ltd. This is an Open Access article distributed under the terms of the Creative Commons Attribution License (http://creativecommons. org/licenses/by/2.0 ), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. Implementation Science  2010, 5:37
Hanbury et al.  Implementation Science  2010, 5:37
http://www.implementationsc ience.com/content/5/1/37Page 6 of 6
9. Michie S, Abraham C: Interventions to change health behaviours: 
evidence based or evidence inspired?   Psychology and Health  2004, 
19:29-49.
10. Rogers EM: Diffusion of innovations .  5th edition. New York, NY; London: 
Free Press; 2003. 
11. Craig P, Dieppe P, Macintyre S, Michie S, Nazareth I, Pettigrew M: 
Developing and evaluating comp lex interventions: new guidance .  
London: Medical Research Council; 2008. 
12. Anderson NR, West MA: Measuring climate for work group innovation: 
development and validation of the team climate inventory .  Journal of 
Organizational Behaviour  1998, 19:235-258.
13. Baker R, Camosso-Stefinovi c J, Gillies C, Shaw EJ, Cheater F, Flottorp S, 
Robertson N: Tailored interventions to overcome identified barriers to 
change: effects on professional practice and health care outcomes .  
Cochrane Database of Systematic Reviews  2010:CD005470. Doi: 10.1002/
14651858.CD005470
14. Mason J, Freemantle N, Nazareth I, Eccles M, Haines A, Drummond M: 
When is it cost effective to change the behaviour of health professionals?   JAMA  2001, 286: 2988-2992.
15. Glasziou P, Heneghan C: A spotters guide to study designs .  Evidence 
Based Medicine  2009, 14:37-38.
16. Tan SS, Rutten FF, van Ineveld BM, Redekop WK, Hakkaart-van Roijen L: 
Comparing methodologies for the cost  estimation of hospital services .  
European Journal of Health Economics  2009, 10:39-45.
17. Cook TD, Campbell DT: Quasi-Experimentation: Design and Analysis 
Issues for Field Settings .  Chicago: Rand McNally; 1979. 
18. Ramsey CR, Matowe L, Grilli R, Grimshaw JM, Thomas RE: Interrupted time 
series designs in health technology assessment: lessons from two systematic reviews of behaviour change strategies .  International 
Journal of Technology Assessment in Health Care  2003, 19:613-623.
19. Hulscher MEJL, Laurant MGH, Grol RPTM: Process evaluation on quality 
improvement interventions .  Quality and Safety in Health Care  2003, 
12:40-46.
20. Hardeman W, Michie S, Fanshawe T,  Prevost AT, McLou ghlin K, Kinmouth 
AL: Fidelity and delivery of a physical activity intervention: predictors 
and consequences .  Psychology and Health  2008, 23:11-24.
21. Pope C, Ziebland S, Mays N: 
Qualitative research in health care: 
analysing qualitative data .  British Medical Journal  2000, 320: 114-120.
doi: 10.1186/1748-5908-5-37
Cite this article as: Hanbury et al. , Translating research into practice in Leeds 
and Bradford (TRiPLaB): a protocol for a programme of research Implementa-
tion Science  2010, 5:37
